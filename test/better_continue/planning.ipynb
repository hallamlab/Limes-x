{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1 solutions',\n",
       " [{precog}->{db-cog} || (a000:precog) >> (l000:db-cog),\n",
       "  {dna}->{asm-annable-contigs} || (c000:dna) >> (m000:asm-annable-contigs),\n",
       "  {dna},{asm-contigs}->{bin-annable-contigs} || (c000:dna),(m000:asm-annable-contigs) >> (n000:bin-annable-contigs),\n",
       "  {db},{annable}->{ann} || (l000:db-cog),(m000:asm-annable-contigs) >> (q000:ann),\n",
       "  {db},{annable}->{ann} || (b000:db-kegg),(m000:asm-annable-contigs) >> (o000:ann),\n",
       "  {annable},{db-cog},{ann},{db-kegg},{ann}->{table} || (m000:asm-annable-contigs),(l000:db-cog),(q000:ann),(b000:db-kegg),(o000:ann) >> (s000:table),\n",
       "  {db},{annable}->{ann} || (l000:db-cog),(n000:bin-annable-contigs) >> (r000:ann),\n",
       "  {db},{annable}->{ann} || (b000:db-kegg),(n000:bin-annable-contigs) >> (p000:ann),\n",
       "  {annable},{db-cog},{ann},{db-kegg},{ann}->{table} || (n000:bin-annable-contigs),(l000:db-cog),(r000:ann),(b000:db-kegg),(p000:ann) >> (t000:table),\n",
       "  {db-cog},{db-kegg},{asm-contigs},{bin-contigs},{table},{table}->{figure} || (l000:db-cog),(b000:db-kegg),(m000:asm-annable-contigs),(n000:bin-annable-contigs),(s000:table),(t000:table) >> (u000:figure),\n",
       "  {figure}-> || (u000:figure) >> ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "import os, sys\n",
    "from typing import Any, Generator, Iterable, Literal\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import deque\n",
    "\n",
    "from limes_x.utils import KeyGenerator\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self) -> None:\n",
    "        self.node_signatures: dict[int, str] = {}\n",
    "        self._last_k: int = 0\n",
    "        self._kg = KeyGenerator(True)\n",
    "        self._KLEN = 4\n",
    "        self._MAX_K = len(self._kg.vocab)**self._KLEN\n",
    "\n",
    "    def NewKey(self):\n",
    "        self._last_k += 1\n",
    "        assert self._last_k < self._MAX_K\n",
    "        return self._last_k, self._kg.FromInt(self._last_k, self._KLEN)\n",
    "\n",
    "class Hashable:\n",
    "    def __init__(self, ns: Namespace) -> None:\n",
    "        self.namespace = ns\n",
    "        self.hash, self.key = ns.NewKey()\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return self.hash\n",
    "    \n",
    "    def __eq__(self, __value: object) -> bool:\n",
    "        K = \"key\"\n",
    "        return hasattr(__value, K) and self.key == getattr(__value, K)\n",
    "\n",
    "class Node(Hashable):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ns: Namespace,\n",
    "        properties: set[str],\n",
    "        parents: set[Node],\n",
    "    ) -> None:\n",
    "        super().__init__(ns)\n",
    "        self.namespace = ns\n",
    "        self.properties = properties\n",
    "        self.parents = parents\n",
    "        self._sig: str|None = None\n",
    "        # self._diffs = set()\n",
    "        # self._sames = set()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"({self.key}:{'-'.join(self.properties)})\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self}\"\n",
    "    \n",
    "    def IsA(self, other: Node) -> bool:\n",
    "        # if other.key in self._diffs: return False\n",
    "        # if other.key in self._sames: return True\n",
    "        if not other.properties.issubset(self.properties):\n",
    "            # self._diffs.add(other.key)\n",
    "            return False\n",
    "        # self._sames.add(other.key)\n",
    "        # if compare_lineage: return  other.parents.issubset(self.parents)\n",
    "        return True\n",
    "\n",
    "    def Signature(self):\n",
    "        if self._sig is None:\n",
    "            psig = \",\".join(sorted(p.Signature() for p in self.parents))\n",
    "            sig = \",\".join(sorted(self.properties))\n",
    "            self._sig = f'{sig}:[{psig}]' if len(self.parents)>0 else sig\n",
    "        return self._sig\n",
    "\n",
    "class Dependency(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: set[Node]) -> None:\n",
    "        super().__init__(namespace, properties, parents)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"(D:{'-'.join(self.properties)})\"\n",
    "    \n",
    "class Endpoint(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: dict[Endpoint, Node]=dict()) -> None:\n",
    "        super().__init__(namespace, properties, set(parents))\n",
    "        self._parent_map = parents # real, proto\n",
    "\n",
    "    def Iterparents(self):\n",
    "        \"\"\"real, prototype\"\"\"\n",
    "        for e, p in self._parent_map.items():\n",
    "            yield e, p\n",
    "\n",
    "class Transform(Hashable):\n",
    "    def __init__(self, ns: Namespace) -> None:\n",
    "        super().__init__(ns)\n",
    "        self.requires: list[Dependency] = list()\n",
    "        self.produces: list[Dependency] = list()\n",
    "        self._ns = ns\n",
    "        self._input_group_map: dict[int, list[Dependency]] = {}\n",
    "        self._key = ns.NewKey()\n",
    "        self._seen: set[str] = set()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        def _props(d: Dependency):\n",
    "            return \"{\"+\"-\".join(d.properties)+\"}\"\n",
    "        return f\"{','.join(_props(r) for r in self.requires)}->{','.join(_props(p) for p in self.produces)}\"\n",
    "\n",
    "    def __repr__(self): return f\"{self}\"\n",
    "\n",
    "    def AddRequirement(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.requires, properties, parents)\n",
    "\n",
    "    def AddProduct(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.produces, properties, parents)\n",
    "\n",
    "    def _add_dependency(self, destination: list[Dependency], properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        _parents: Any = parents\n",
    "        _dep = Dependency(properties=set(properties), parents=_parents, namespace=self._ns)\n",
    "        # assert not any(e.IsA(_dep) for e in destination), f\"prev. dep ⊆ new dep\"\n",
    "        # assert not any(_dep.IsA(e) for e in destination), f\"new dep ⊆ prev. dep \"\n",
    "        # destination.add(_dep)\n",
    "        destination.append(_dep)\n",
    "        if destination == self.requires:\n",
    "            i = len(self.requires)-1\n",
    "            for p in _parents:\n",
    "                assert p in self.requires, f\"{p} not added as a requirement\"\n",
    "            self._input_group_map[i] = self._input_group_map.get(i, [])+list(_parents)\n",
    "        return _dep\n",
    "\n",
    "    def _sig(self, endpoints: Iterable[Endpoint]):\n",
    "        # return \"\".join(e.key for e in endpoints)\n",
    "        return self.key+\"-\"+ \"\".join(e.key for e in endpoints)\n",
    "\n",
    "    # just all possibilities regardless of lineage\n",
    "    def Possibilities(self, have: set[Endpoint], constraints: dict[Dependency, Endpoint]=dict()) -> Generator[list[Endpoint], Any, None]:\n",
    "        matches: list[list[Endpoint]] = []\n",
    "        constraints_used = False\n",
    "        for req in self.requires:\n",
    "            if req in constraints:\n",
    "                must_use = constraints[req]\n",
    "                _m = [must_use]\n",
    "            else:\n",
    "                _m = [m for m in have if m.IsA(req)]\n",
    "            if len(_m) == 0: return None\n",
    "            matches.append(_m)\n",
    "        if len(constraints)>0 and not constraints_used: return None\n",
    "\n",
    "        indexes = [0]*len(matches)\n",
    "        indexes[0] = -1\n",
    "        def _advance():\n",
    "            i = 0\n",
    "            while True:\n",
    "                indexes[i] += 1\n",
    "                if indexes[i] < len(matches[i]): return True\n",
    "                indexes[i] = 0\n",
    "                i += 1\n",
    "                if i >= len(matches): return False\n",
    "        while _advance():\n",
    "            yield [matches[i][j] for i, j in enumerate(indexes)]\n",
    "    \n",
    "    # filter possibilities based on correct lineage\n",
    "    def Valids(self, matches: Iterable[list[Endpoint]]):\n",
    "        black_list: set[tuple[int, Endpoint]] = set()\n",
    "        white_list: set[tuple[int, Endpoint]] = set()\n",
    "\n",
    "        choosen: list[Endpoint] = []\n",
    "        for config in matches:\n",
    "            ok = True\n",
    "            for i, (e, r) in enumerate(zip(config, self.requires)):\n",
    "                k = (i, e)\n",
    "                if k in black_list: ok=False; break\n",
    "                if k in white_list: continue\n",
    "                \n",
    "                parents = self._input_group_map.get(i, [])\n",
    "                if len(parents) == 0: # no lineage req.\n",
    "                    white_list.add(k)\n",
    "                    continue\n",
    "                \n",
    "                for prototype in parents:\n",
    "                    # parent must already be in choosen, since it must have been added\n",
    "                    # as a req. before being used as a parent during setup\n",
    "                    found = False\n",
    "                    for p in choosen:\n",
    "                        if not p.IsA(prototype): continue\n",
    "                        if p in e.parents: found=True; break\n",
    "                    if not found: black_list.add(k); ok=False; break\n",
    "                if not ok: break\n",
    "            if ok: yield config\n",
    "\n",
    "    def Apply(self, inputs: Iterable[tuple[Endpoint, Node]]):\n",
    "        for r, (e, e_proto) in zip(self.requires, inputs):\n",
    "            assert e.IsA(r), f\"{e_proto}, {e}, {r}\"\n",
    "\n",
    "        inputs_dict = dict(inputs)\n",
    "        parent_dict: dict[Any, Any] = {}\n",
    "        for e, _ in inputs_dict.items():\n",
    "            for p, pproto in e.Iterparents():\n",
    "                if p in parent_dict: continue\n",
    "                parent_dict[p] = pproto\n",
    "        for e, eproto in inputs_dict.items():\n",
    "            parent_dict[e] = eproto\n",
    "        produced = {\n",
    "            Endpoint(\n",
    "                namespace=self._ns,\n",
    "                properties=out.properties,\n",
    "                parents=parent_dict\n",
    "            ):out\n",
    "        for out in self.produces}\n",
    "        return Application(self, inputs_dict, produced)\n",
    "\n",
    "@dataclass\n",
    "class Application:\n",
    "    transform: Transform\n",
    "    used: dict[Endpoint, Node]\n",
    "    produced: dict[Endpoint, Dependency]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.transform} || {','.join(str(e) for e in self.used.keys())} >> {','.join(str(e) for e in self.produced)}\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self}\"\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    steps: int\n",
    "\n",
    "@dataclass\n",
    "class TrResult(Result):\n",
    "    application: Application\n",
    "    dependency_plan: list[Application]\n",
    "    \n",
    "@dataclass\n",
    "class DepResult(Result):\n",
    "    plan: list[Application]\n",
    "    endpoint: Endpoint\n",
    "\n",
    "def Solve(given: Iterable[Endpoint], target: Transform, transforms: Iterable[Transform]):\n",
    "    @dataclass\n",
    "    class State:\n",
    "        have: dict[Endpoint, Dependency]\n",
    "        target: Dependency|Transform\n",
    "        lineage_requirements: dict[Node, Endpoint]\n",
    "        seen_signatures: set[str]\n",
    "        depth: int\n",
    "\n",
    "    def _get_producers_of(target: Dependency):\n",
    "        for tr in transforms:\n",
    "            for p in tr.produces:\n",
    "                if p.IsA(target):\n",
    "                    yield tr\n",
    "                    break\n",
    "\n",
    "    # if DEBUG: debug_print = lambda *args: None\n",
    "    # if DEBUG: debug_print = lambda *args: None\n",
    "    # DEBUG = True\n",
    "    DEBUG = False\n",
    "    log = open(\"./cache/debug_log.txt\", \"w\")\n",
    "    debug_print = lambda *args: log.write(\" \".join(str(a) for a in args)+\"\\n\") if args[0] != \"END\" else log.close()\n",
    "\n",
    "    _apply_cache: dict[str, Application] = {}\n",
    "    def _apply(target: Transform, inputs: Iterable[tuple[Endpoint, Node]]):\n",
    "        sig  = \"\".join(e.key+d.key for e, d in inputs)\n",
    "        if sig in _apply_cache:\n",
    "            return _apply_cache[sig]\n",
    "        appl = target.Apply(inputs)\n",
    "        _apply_cache[sig] = appl\n",
    "        return appl\n",
    "\n",
    "    def _satisfies_lineage(tproto: Dependency, candidate: Endpoint):\n",
    "        for tp_proto in tproto.parents:\n",
    "            if all(not p.IsA(tp_proto) for p, _ in candidate.Iterparents()):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    HORIZON=64\n",
    "    def _solve_dep(s: State) -> list[DepResult]:\n",
    "        if s.depth >= HORIZON:\n",
    "            if DEBUG: debug_print(f\" <-  HORIZON\", s.depth)\n",
    "            return []\n",
    "        target: Any = s.target\n",
    "        assert isinstance(target, Dependency), f\"{s.target}, not dep\"\n",
    "        if DEBUG: debug_print(f\" ->\", s.target, s.lineage_requirements)\n",
    "        if DEBUG: debug_print(f\"   \", s.have.keys())\n",
    "\n",
    "        candidates:list[DepResult] = []\n",
    "        for e, eproto in s.have.items():\n",
    "            if not e.IsA(target): continue\n",
    "            acceptable = True\n",
    "            for rproto, r in s.lineage_requirements.items():\n",
    "                if e == r: continue\n",
    "                if eproto.IsA(rproto): # e is protype, but explicitly breaks lineage\n",
    "                    acceptable=False; break\n",
    "\n",
    "                for p, pproto in e.Iterparents():\n",
    "                    if rproto.IsA(pproto):\n",
    "                        if p != r:\n",
    "                            acceptable=False; break\n",
    "\n",
    "            if not acceptable:\n",
    "                continue\n",
    "            else:\n",
    "                if DEBUG: debug_print(f\"    ^candidate\", e, eproto, e.parents)\n",
    "                if DEBUG: debug_print(f\"    ^reqs.    \", s.lineage_requirements)\n",
    "                candidates.append(DepResult(0, [], e))\n",
    "            # elif quality == 2:\n",
    "            #     if DEBUG: debug_print(f\" <-\", s.target, e, \"DIRECT\")\n",
    "            #     return [DepResult(0, [], e)]\n",
    "\n",
    "        def _add_result(res: TrResult):\n",
    "            ep: Endpoint|None = None\n",
    "            for e in res.application.produced:\n",
    "                if e.IsA(target):\n",
    "                    ep = e; break\n",
    "            assert isinstance(ep, Endpoint)\n",
    "            if not _satisfies_lineage(target, ep): return\n",
    "            candidates.append(DepResult(\n",
    "                res.steps,\n",
    "                res.dependency_plan+[res.application],\n",
    "                ep,\n",
    "            ))\n",
    "\n",
    "        for tr in _get_producers_of(target):\n",
    "            results = _solve_tr(State(s.have, tr, s.lineage_requirements, s.seen_signatures, s.depth))\n",
    "            for res in results:\n",
    "                _add_result(res)\n",
    "\n",
    "        if DEBUG: debug_print(f\" <-\", s.target, f\"{len(candidates)} sol.\", candidates[0].endpoint if len(candidates)>0 else None)\n",
    "        return candidates\n",
    "\n",
    "    _transform_cache: dict[str, list[TrResult]] = {}\n",
    "    def _solve_tr(s: State) -> list[TrResult]:\n",
    "        assert isinstance(s.target, Transform), f\"{s.target} not tr\"\n",
    "        target: Transform = s.target\n",
    "        if DEBUG: debug_print(f\">>>{s.depth:02}\", s.target, s.lineage_requirements)\n",
    "        for h in s.have:\n",
    "            if DEBUG: debug_print(f\"      \", h)\n",
    "\n",
    "        # memoization\n",
    "        sig = \"\".join(e.key for e in s.have)\n",
    "        sig += f\":{s.target.key}\"\n",
    "        sig += \":\"+\"\".join(e.key for e in s.lineage_requirements.values())\n",
    "        if sig in _transform_cache:\n",
    "            if DEBUG: debug_print(f\"<<<{s.depth:02} CACHED: {len(_transform_cache[sig])} solutions\")\n",
    "            return _transform_cache[sig]\n",
    "        if sig in s.seen_signatures:\n",
    "            if DEBUG: debug_print(f\"<<<{s.depth:02} FAIL: is loop\")\n",
    "            return []\n",
    "\n",
    "        plans: list[list[DepResult]] = []\n",
    "        for i, req in enumerate(s.target.requires):\n",
    "            req_p = {}\n",
    "            for proto, e in s.lineage_requirements.items():\n",
    "                if req.IsA(proto): continue\n",
    "                req_p[proto] = e\n",
    "\n",
    "            results = _solve_dep(State(s.have, req, req_p, s.seen_signatures|{sig}, s.depth+1))\n",
    "            \n",
    "            if len(results) == 0:\n",
    "                if DEBUG: debug_print(f\"<<< FAIL\", s.target, req)\n",
    "                return []\n",
    "            else:\n",
    "                plans.append(results)\n",
    "\n",
    "        def _gather_valid_inputs():\n",
    "            valids: list[list[DepResult]] = []\n",
    "            ii = 0\n",
    "            def _gather(req_i: int, req: Dependency, res: DepResult, deps: dict, used: set[Endpoint], inputs: list[DepResult]):\n",
    "                nonlocal ii; ii += 1         \n",
    "                if DEBUG: debug_print(f\"          \", deps)\n",
    "                if DEBUG: debug_print(f\"    ___\", req, req.parents)\n",
    "                if DEBUG: debug_print(f\"        __\", res.endpoint, list(res.endpoint.Iterparents()))\n",
    "                if res.endpoint in used:\n",
    "                    if DEBUG: debug_print(f\"    ___ FAIL: duplicate input\", res.endpoint)\n",
    "                    return\n",
    "                # used.add(res.endpoint)\n",
    "\n",
    "                if not _satisfies_lineage(req, res.endpoint):\n",
    "                    if DEBUG: debug_print(f\"    ___ FAIL: unsatisfied lineage\", req)\n",
    "                    return\n",
    "\n",
    "                for rproto in req.parents:\n",
    "                    r = deps[rproto]\n",
    "                    # if all(not p.IsA(rproto) for p, pproto in res.endpoint.Iterparents()):\n",
    "                    #     if DEBUG: debug_print(f\"    ___ FAIL: unsatisfied lineage\", rproto)\n",
    "                    #     _fail=True; break\n",
    "                    res_parents = list(res.endpoint.Iterparents())\n",
    "                    res_parents.reverse()\n",
    "                    for p, pproto in res_parents:\n",
    "                        if not p.IsA(rproto): continue\n",
    "                        if p!=r:\n",
    "                            if DEBUG: debug_print(f\"    ___ FAIL: lineage mismatch\", p, r)\n",
    "                            return\n",
    "                        else:\n",
    "                            break # in the case of asm -> bin, the closest ancestor takes priority\n",
    "                # deps[req] = res.endpoint\n",
    "\n",
    "                if req_i >= len(target.requires)-1:\n",
    "                    valids.append(inputs+[res])\n",
    "                else:\n",
    "                    req_i += 1\n",
    "                    for i, next_res in enumerate(plans[req_i]):\n",
    "                        _gather(req_i, target.requires[req_i], next_res, deps|{req:res.endpoint}, used|{res.endpoint}, inputs+[res])\n",
    "            req_i = 0\n",
    "            for i, next_res in enumerate(plans[req_i]):\n",
    "                _gather(0, target.requires[req_i], next_res, {}, set(), [])\n",
    "            total = 1\n",
    "            for s in plans:\n",
    "                total *= len(s)\n",
    "            if DEBUG: debug_print(f\"    ## {ii} visited, {total} combos\")\n",
    "            return valids\n",
    "\n",
    "        if DEBUG: debug_print(f\"<<<{s.depth:02}\", s.target, s.lineage_requirements)\n",
    "        if DEBUG: debug_print(f\"     \", [len(x) for x in plans])\n",
    "        solutions: list[TrResult] = []\n",
    "        # for inputs in _iter_satisfies():\n",
    "        for inputs in _gather_valid_inputs():\n",
    "            my_appl = _apply(s.target, [(res.endpoint, req) for req, res in zip(s.target.requires, inputs)])\n",
    "            consolidated_plan: list[Application] = []\n",
    "            produced_sigs: set[str] = {p.Signature() for p in my_appl.produced}\n",
    "            # if DEBUG: debug_print(f\"   __\", my_appl)\n",
    "            for res in inputs:\n",
    "                for appl in res.plan:\n",
    "                    if all(p.Signature() in produced_sigs for p in appl.produced): continue\n",
    "                    consolidated_plan.append(appl)\n",
    "                    produced_sigs = produced_sigs.union(p.Signature() for p in appl.produced)\n",
    "            solutions.append(TrResult(\n",
    "                len(consolidated_plan),\n",
    "                my_appl,\n",
    "                consolidated_plan,\n",
    "            ))\n",
    "            # if DEBUG: debug_print(f\"    *\", my_appl)\n",
    "            # if DEBUG: debug_print(f\"     \", [res.endpoint for res in inputs])\n",
    "            # if DEBUG: debug_print(f\"    .\", target.requires)\n",
    "            # for appl in consolidated_plan:\n",
    "            #     if DEBUG: debug_print(f\"    __\", appl)\n",
    "        if DEBUG: debug_print(f\"     \", f\"{len(solutions)} sol.\", solutions[0].application.produced if len(solutions)>0 else None)\n",
    "        solutions = sorted(solutions, key=lambda s: s.steps)\n",
    "        _transform_cache[sig] = solutions\n",
    "        return solutions\n",
    "\n",
    "    input_tr = Transform(target._ns)\n",
    "    given_dict = {g:input_tr.AddProduct(g.properties) for g in given}\n",
    "    res = _solve_tr(State(given_dict, target, {}, set(), 0))\n",
    "    if DEBUG: debug_print(\"END\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def _set(s: str):\n",
    "    return set(s.split(\", \"))\n",
    " \n",
    "transforms = []\n",
    "NS = Namespace()\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"dna\"))\n",
    "t.AddProduct(_set(\"contigs, asm, annable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "r = t.AddRequirement(_set(\"dna\"))\n",
    "t.AddRequirement(_set(\"contigs, asm\"), {r})\n",
    "t.AddProduct(_set(\"contigs, bin, annable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"db\"))\n",
    "t.AddRequirement(_set(\"annable\"))\n",
    "t.AddProduct(_set(\"ann\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "ann = t.AddRequirement(_set(\"annable\"))\n",
    "r = t.AddRequirement(_set(\"db, cog\"))\n",
    "t.AddRequirement(_set(\"ann\"), {r, ann})\n",
    "r = t.AddRequirement(_set(\"db, kegg\"))\n",
    "t.AddRequirement(_set(\"ann\"), {r, ann})\n",
    "t.AddProduct(_set(\"table\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "db1 = t.AddRequirement(_set(\"db, cog\"))\n",
    "db2 = t.AddRequirement(_set(\"db, kegg\"))\n",
    "asm = t.AddRequirement(_set(\"contigs, asm\"))\n",
    "bin = t.AddRequirement(_set(\"contigs, bin\"))\n",
    "# t.AddRequirement(_set(\"ann\"), {asm, db1})\n",
    "# t.AddRequirement(_set(\"ann\"), {asm, db2})\n",
    "# t.AddRequirement(_set(\"ann\"), {bin, db1})\n",
    "# t.AddRequirement(_set(\"ann\"), {bin, db2})\n",
    "t.AddRequirement(_set(\"table\"), {asm, db1, db2})\n",
    "t.AddRequirement(_set(\"table\"), {bin, db1, db2})\n",
    "t.AddProduct(_set(\"figure\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"precog\"))\n",
    "t.AddProduct(_set(\"db, cog\"))\n",
    "transforms.append(t)\n",
    "\n",
    "# t = Transform(NS)\n",
    "# t.AddRequirement(_set(\"prekegg\"))\n",
    "# t.AddProduct(_set(\"db, kegg\"))\n",
    "# transforms.append(t)\n",
    "\n",
    "\n",
    "haves = [Endpoint(NS, _set(r)) for r in [\n",
    "    \"precog\",\n",
    "    # \"db, cog\",\n",
    "    \"db, kegg\",\n",
    "    \"dna\",\n",
    "]]\n",
    "\n",
    "target = Transform(NS)\n",
    "# r = target.AddRequirement(_set(\"bin\"))\n",
    "# db = target.AddRequirement(_set(\"cog\"))\n",
    "# target.AddRequirement(_set(\"ann\"), {db, r})\n",
    "# target.AddRequirement(_set(\"ann\"), {db})\n",
    "\n",
    "# r = target.AddRequirement(_set(\"bin\"))\n",
    "# target.AddRequirement(_set(\"table\"), {r})\n",
    "\n",
    "target.AddRequirement(_set(\"figure\"))\n",
    "\n",
    "solutions = None\n",
    "def _test():\n",
    "    global solutions\n",
    "    solutions = Solve(haves, target, transforms)\n",
    "    for res in solutions:\n",
    "        print(res.steps)\n",
    "        return f\"{len(solutions)} solutions\", res.dependency_plan+[res.application]\n",
    "    # if res is not None:\n",
    "_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{precog}->{db-cog} || (a000:precog) >> (l000:db-cog)\n",
      "{dna}->{asm-annable-contigs} || (c000:dna) >> (m000:asm-annable-contigs)\n",
      "{dna},{asm-contigs}->{bin-annable-contigs} || (c000:dna),(m000:asm-annable-contigs) >> (n000:bin-annable-contigs)\n",
      "{db},{annable}->{ann} || (l000:db-cog),(m000:asm-annable-contigs) >> (q000:ann)\n",
      "{db},{annable}->{ann} || (b000:db-kegg),(m000:asm-annable-contigs) >> (o000:ann)\n",
      "{annable},{db-cog},{ann},{db-kegg},{ann}->{table} || (m000:asm-annable-contigs),(l000:db-cog),(q000:ann),(b000:db-kegg),(o000:ann) >> (s000:table)\n",
      "{db},{annable}->{ann} || (l000:db-cog),(n000:bin-annable-contigs) >> (r000:ann)\n",
      "{db},{annable}->{ann} || (b000:db-kegg),(n000:bin-annable-contigs) >> (p000:ann)\n",
      "{annable},{db-cog},{ann},{db-kegg},{ann}->{table} || (n000:bin-annable-contigs),(l000:db-cog),(r000:ann),(b000:db-kegg),(p000:ann) >> (t000:table)\n",
      "{db-cog},{db-kegg},{asm-contigs},{bin-contigs},{table},{table}->{figure} || (l000:db-cog),(b000:db-kegg),(m000:asm-annable-contigs),(n000:bin-annable-contigs),(s000:table),(t000:table) >> (u000:figure)\n",
      "{figure}-> || (u000:figure) >> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for res in solutions:\n",
    "    for a in res.dependency_plan:\n",
    "        print(a)\n",
    "    print(res.application)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = []\n",
    "NS = Namespace()\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement({\"dna\", \"raw reads\"})\n",
    "t.AddProduct({\"assembly\", \"contigs\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "reads = t.AddRequirement({\"dna\", \"raw reads\"})\n",
    "t.AddRequirement({\"contigs\", \"assembly\"}, parents={reads})\n",
    "t.AddProduct({\"binned\", \"contigs\"})\n",
    "transforms.append(t)\n",
    "\n",
    "\n",
    "have = [\n",
    "    Endpoint(NS, {\"dna\", \"raw reads\", \"sra\", \"metagenomic\"}),\n",
    "]\n",
    "\n",
    "target = Transform(NS)\n",
    "target.AddRequirement({\"binned\", \"contigs\"})\n",
    "\n",
    "plan = Solve(have, target, transforms)[0] # first solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "{raw reads-dna}->{assembly-contigs}\n",
      "used\n",
      "  (A000:sra-raw reads-metagenomic-dna)\n",
      "produced\n",
      "  (H000:assembly-contigs)\n",
      "\n",
      "step 2\n",
      "{raw reads-dna},{assembly-contigs}->{binned-contigs}\n",
      "used\n",
      "  (A000:sra-raw reads-metagenomic-dna)\n",
      "  (H000:assembly-contigs)\n",
      "produced\n",
      "  (I000:binned-contigs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _print_sol(plan: TrResult):\n",
    "    for i, step in enumerate(plan.dependency_plan):\n",
    "        print(f\"step {i+1}\")\n",
    "        print(step.transform)\n",
    "        print(\"used\")\n",
    "        for x in step.used:\n",
    "            print(\" \", x)\n",
    "        print(\"produced\")\n",
    "        for x in step.produced:\n",
    "            print(\" \", x)\n",
    "        print()\n",
    "\n",
    "_print_sol(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "{genomic-contigs}->{orfs}\n",
      "used\n",
      "  (A000:genomic-contigs)\n",
      "produced\n",
      "  (Q000:orfs)\n",
      "\n",
      "step 2\n",
      "{protein reference},{orfs}->{annotations}\n",
      "used\n",
      "  (B000:KEGG-protein reference)\n",
      "  (Q000:orfs)\n",
      "produced\n",
      "  (R000:annotations)\n",
      "\n",
      "step 3\n",
      "{protein reference},{orfs}->{annotations}\n",
      "used\n",
      "  (D000:metacyc-protein reference)\n",
      "  (Q000:orfs)\n",
      "produced\n",
      "  (T000:annotations)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transforms = []\n",
    "NS = Namespace()\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement({\"genomic\", \"contigs\"})\n",
    "t.AddProduct({\"orfs\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement({\"protein reference\"})\n",
    "t.AddRequirement({\"orfs\"})\n",
    "t.AddProduct({\"annotations\"})\n",
    "transforms.append(t)\n",
    "\n",
    "have = [\n",
    "    Endpoint(NS, {\"genomic\", \"contigs\"}),\n",
    "    Endpoint(NS, {\"protein reference\", \"KEGG\"}),\n",
    "    Endpoint(NS, {\"protein reference\", \"COG\"}),\n",
    "    Endpoint(NS, {\"protein reference\", \"metacyc\"}),\n",
    "]\n",
    "\n",
    "target = Transform(NS)\n",
    "kegg = target.AddRequirement({\"protein reference\", \"KEGG\"})\n",
    "metacyc = target.AddRequirement({\"protein reference\", \"metacyc\"})\n",
    "target.AddRequirement({\"annotations\"}, {kegg})\n",
    "target.AddRequirement({\"annotations\"}, {metacyc})\n",
    "\n",
    "plan = Solve(have, target, transforms)[0]\n",
    "_print_sol(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "{dna}->{assembly-genomic-contigs}\n",
      "used\n",
      "  (W000:raw reads-dna)\n",
      "produced\n",
      "  (h000:assembly-genomic-contigs)\n",
      "\n",
      "step 2\n",
      "{dna},{assembly-contigs}->{bin-genomic-contigs}\n",
      "used\n",
      "  (W000:raw reads-dna)\n",
      "  (h000:assembly-genomic-contigs)\n",
      "produced\n",
      "  (i000:bin-genomic-contigs)\n",
      "\n",
      "step 3\n",
      "{reference},{genomic}->{annotation}\n",
      "used\n",
      "  (X000:reference-COG)\n",
      "  (h000:assembly-genomic-contigs)\n",
      "produced\n",
      "  (j000:annotation)\n",
      "\n",
      "step 4\n",
      "{reference},{genomic}->{annotation}\n",
      "used\n",
      "  (Y000:reference-KEGG)\n",
      "  (h000:assembly-genomic-contigs)\n",
      "produced\n",
      "  (l000:annotation)\n",
      "\n",
      "step 5\n",
      "{genomic},{reference-COG},{annotation},{reference-KEGG},{annotation}->{table}\n",
      "used\n",
      "  (h000:assembly-genomic-contigs)\n",
      "  (X000:reference-COG)\n",
      "  (j000:annotation)\n",
      "  (Y000:reference-KEGG)\n",
      "  (l000:annotation)\n",
      "produced\n",
      "  (n000:table)\n",
      "\n",
      "step 6\n",
      "{reference},{genomic}->{annotation}\n",
      "used\n",
      "  (X000:reference-COG)\n",
      "  (i000:bin-genomic-contigs)\n",
      "produced\n",
      "  (k000:annotation)\n",
      "\n",
      "step 7\n",
      "{reference},{genomic}->{annotation}\n",
      "used\n",
      "  (Y000:reference-KEGG)\n",
      "  (i000:bin-genomic-contigs)\n",
      "produced\n",
      "  (m000:annotation)\n",
      "\n",
      "step 8\n",
      "{genomic},{reference-COG},{annotation},{reference-KEGG},{annotation}->{table}\n",
      "used\n",
      "  (i000:bin-genomic-contigs)\n",
      "  (X000:reference-COG)\n",
      "  (k000:annotation)\n",
      "  (Y000:reference-KEGG)\n",
      "  (m000:annotation)\n",
      "produced\n",
      "  (o000:table)\n",
      "\n",
      "step 9\n",
      "{reference-COG},{reference-KEGG},{assembly-contigs},{bin-contigs},{table},{table}->{summary figure}\n",
      "used\n",
      "  (X000:reference-COG)\n",
      "  (Y000:reference-KEGG)\n",
      "  (h000:assembly-genomic-contigs)\n",
      "  (i000:bin-genomic-contigs)\n",
      "  (n000:table)\n",
      "  (o000:table)\n",
      "produced\n",
      "  (p000:summary figure)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transforms = []\n",
    "NS = Namespace()\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"dna\"))\n",
    "t.AddProduct(_set(\"contigs, assembly, genomic\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "r = t.AddRequirement(_set(\"dna\"))\n",
    "t.AddRequirement(_set(\"contigs, assembly\"), {r})\n",
    "t.AddProduct(_set(\"contigs, bin, genomic\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"reference\"))\n",
    "t.AddRequirement(_set(\"genomic\"))\n",
    "t.AddProduct(_set(\"annotation\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "genome = t.AddRequirement(_set(\"genomic\"))\n",
    "ref_cog = t.AddRequirement(_set(\"reference, COG\"))\n",
    "t.AddRequirement(_set(\"annotation\"), {ref_cog, genome})\n",
    "ref_kegg = t.AddRequirement(_set(\"reference, KEGG\"))\n",
    "t.AddRequirement(_set(\"annotation\"), {ref_kegg, genome})\n",
    "t.AddProduct(_set(\"table\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "ref_cog = t.AddRequirement(_set(\"reference, COG\"))\n",
    "ref_kegg = t.AddRequirement(_set(\"reference, KEGG\"))\n",
    "asm_genome = t.AddRequirement(_set(\"contigs, assembly\"))\n",
    "bin_genome = t.AddRequirement(_set(\"contigs, bin\"))\n",
    "t.AddRequirement(_set(\"table\"), {asm_genome, ref_cog, ref_kegg})\n",
    "t.AddRequirement(_set(\"table\"), {bin_genome, ref_cog, ref_kegg})\n",
    "t.AddProduct(_set(\"summary figure\"))\n",
    "transforms.append(t)\n",
    "\n",
    "have = [\n",
    "    Endpoint(NS, {\"dna\", \"raw reads\"}),\n",
    "    Endpoint(NS, {\"reference\", \"COG\"}),\n",
    "    Endpoint(NS, {\"reference\", \"KEGG\"}),\n",
    "]\n",
    "\n",
    "target = Transform(NS)\n",
    "target.AddRequirement({\"summary figure\"})\n",
    "\n",
    "plan = Solve(have, target, transforms)[0]\n",
    "_print_sol(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "{raw reads-dna}->{assembly-contigs}\n",
      "used\n",
      "  (U000:metagenomic-raw reads-dna)\n",
      "produced\n",
      "  (c000:assembly-contigs)\n",
      "\n",
      "step 2\n",
      "{assembly-contigs}->{orfs},{annotations-metapathways}\n",
      "used\n",
      "  (c000:assembly-contigs)\n",
      "produced\n",
      "  (d000:orfs)\n",
      "  (e000:annotations-metapathways)\n",
      "\n",
      "step 3\n",
      "{contigs}->{taxonomy-GTDB-TK}\n",
      "used\n",
      "  (c000:assembly-contigs)\n",
      "produced\n",
      "  (j000:taxonomy-GTDB-TK)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transforms = []\n",
    "NS = Namespace()\n",
    "\n",
    "t = Transform(NS) # assembly\n",
    "t.AddRequirement({\"dna\", \"raw reads\"})\n",
    "t.AddProduct({\"assembly\", \"contigs\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS) # fosmid assembly\n",
    "t.AddRequirement({\"dna\", \"raw reads\", \"fosmid\"})\n",
    "t.AddRequirement({\"dna\", \"end seq.\"})\n",
    "t.AddProduct({\"fosmids\", \"assembly\", \"contigs\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS) # binning\n",
    "reads = t.AddRequirement({\"dna\", \"raw reads\"})\n",
    "t.AddRequirement({\"contigs\", \"assembly\"}, parents={reads})\n",
    "t.AddProduct({\"binned\", \"contigs\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS) # genomeQC\n",
    "t.AddRequirement({\"binned\", \"contigs\"})\n",
    "t.AddProduct({\"binned\", \"contigs\", \"med quality\"})\n",
    "t.AddProduct({\"taxonomy\", \"GTDB-TK\"})\n",
    "t.AddProduct({\"table\", \"checkM stats\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS) # annotation\n",
    "t.AddRequirement({\"assembly\", \"contigs\"})\n",
    "t.AddProduct({\"orfs\"})\n",
    "t.AddProduct({\"annotations\", \"metapathways\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS) # taxonomy\n",
    "t.AddRequirement({\"contigs\"})\n",
    "t.AddProduct({\"taxonomy\", \"GTDB-TK\"})\n",
    "transforms.append(t)\n",
    "\n",
    "have = [\n",
    "    Endpoint(NS, {\"dna\", \"raw reads\", \"metagenomic\"}),\n",
    "]\n",
    "\n",
    "target = Transform(NS)\n",
    "target.AddRequirement({\"annotations\", \"metapathways\"})\n",
    "target.AddRequirement({\"taxonomy\", \"GTDB-TK\"})\n",
    "\n",
    "plan = Solve(have, target, transforms)[0]\n",
    "_print_sol(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "{annotation}->{ORFs}\n",
      "used\n",
      "  (f000:annotation)\n",
      "produced\n",
      "  (n000:ORFs)\n",
      "\n",
      "step 2\n",
      "{ORFs}->{contigs}\n",
      "used\n",
      "  (n000:ORFs)\n",
      "produced\n",
      "  (o000:contigs)\n",
      "\n",
      "step 3\n",
      "{contigs}->{bins}\n",
      "used\n",
      "  (o000:contigs)\n",
      "produced\n",
      "  (p000:bins)\n",
      "\n",
      "step 4\n",
      "{bins}->{tax}\n",
      "used\n",
      "  (p000:bins)\n",
      "produced\n",
      "  (t000:tax)\n",
      "\n",
      "step 5\n",
      "{tax}->{bins}\n",
      "used\n",
      "  (t000:tax)\n",
      "produced\n",
      "  (u000:bins)\n",
      "\n",
      "step 6\n",
      "{bins}->{contigs}\n",
      "used\n",
      "  (u000:bins)\n",
      "produced\n",
      "  (x000:contigs)\n",
      "\n",
      "step 7\n",
      "{contigs}->{ORFs}\n",
      "used\n",
      "  (x000:contigs)\n",
      "produced\n",
      "  (0100:ORFs)\n",
      "\n",
      "step 8\n",
      "{ORFs}->{annotation}\n",
      "used\n",
      "  (0100:ORFs)\n",
      "produced\n",
      "  (6100:annotation)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NS = Namespace()\n",
    "transforms = []\n",
    "\n",
    "t = Transform(NS) # assembly <-> bins\n",
    "t.AddRequirement({\"assembly\"})\n",
    "t.AddProduct({\"bins\"})\n",
    "transforms.append(t)\n",
    "t = Transform(NS)\n",
    "t.AddRequirement({\"bins\"})\n",
    "t.AddProduct({\"assembly\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS) # bins <-> tax\n",
    "t.AddRequirement({\"bins\"})\n",
    "t.AddProduct({\"tax\"})\n",
    "transforms.append(t)\n",
    "t = Transform(NS)\n",
    "t.AddRequirement({\"tax\"})\n",
    "t.AddProduct({\"bins\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS) # bins <-> contigs\n",
    "t.AddRequirement({\"bins\"})\n",
    "t.AddProduct({\"contigs\"})\n",
    "transforms.append(t)\n",
    "t = Transform(NS)\n",
    "t.AddRequirement({\"contigs\"})\n",
    "t.AddProduct({\"bins\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS) # contigs <-> ORFs\n",
    "t.AddRequirement({\"contigs\"})\n",
    "t.AddProduct({\"ORFs\"})\n",
    "transforms.append(t)\n",
    "t = Transform(NS)\n",
    "t.AddRequirement({\"ORFs\"})\n",
    "t.AddProduct({\"contigs\"})\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS) # ORFs <-> annotation\n",
    "t.AddRequirement({\"ORFs\"})\n",
    "t.AddProduct({\"annotation\"})\n",
    "transforms.append(t)\n",
    "t = Transform(NS) \n",
    "t.AddRequirement({\"annotation\"})\n",
    "t.AddProduct({\"ORFs\"})\n",
    "transforms.append(t)\n",
    "\n",
    "\n",
    "have = [\n",
    "    Endpoint(NS, {\"annotation\"}),\n",
    "]\n",
    "\n",
    "target = Transform(NS)\n",
    "tax = target.AddRequirement({\"tax\"})\n",
    "target.AddRequirement({\"annotation\"}, {tax})\n",
    "\n",
    "plan = Solve(have, target, transforms)[0]\n",
    "_print_sol(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1474012 function calls (1439310 primitive calls) in 0.375 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "33536/513    0.097    0.000    0.253    0.000 4135461766.py:366(_gather)\n",
      "   180864    0.052    0.000    0.117    0.000 4135461766.py:270(<genexpr>)\n",
      "   282240    0.046    0.000    0.052    0.000 4135461766.py:87(Iterparents)\n",
      "   217240    0.042    0.000    0.056    0.000 4135461766.py:58(IsA)\n",
      "    50560    0.034    0.000    0.168    0.000 4135461766.py:268(_satisfies_lineage)\n",
      "    50944    0.015    0.000    0.130    0.000 {built-in method builtins.all}\n",
      "   217240    0.015    0.000    0.015    0.000 {method 'issubset' of 'set' objects}\n",
      "    17024    0.011    0.000    0.086    0.000 4135461766.py:308(_add_result)\n",
      "    32896    0.011    0.000    0.016    0.000 4135461766.py:33(__eq__)\n",
      "   137598    0.011    0.000    0.011    0.000 4135461766.py:30(__hash__)\n",
      "  262/256    0.009    0.000    0.366    0.001 4135461766.py:275(_solve_dep)\n",
      "    85263    0.006    0.000    0.006    0.000 {method 'items' of 'dict' objects}\n",
      "    134/1    0.004    0.000    0.373    0.373 4135461766.py:330(_solve_tr)\n",
      "    32900    0.002    0.000    0.002    0.000 {built-in method builtins.hasattr}\n",
      "      513    0.002    0.000    0.006    0.000 4135461766.py:189(Apply)\n",
      "    32927    0.002    0.000    0.002    0.000 {built-in method builtins.getattr}\n",
      "    32896    0.002    0.000    0.002    0.000 {method 'reverse' of 'list' objects}\n",
      "     2716    0.002    0.000    0.003    0.000 {method 'join' of 'str' objects}\n",
      "    17286    0.001    0.000    0.001    0.000 4135461766.py:338(<genexpr>)\n",
      "      642    0.001    0.000    0.001    0.000 utils.py:32(FromInt)\n",
      "    17497    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "4224/3072    0.001    0.000    0.002    0.000 4135461766.py:68(Signature)\n",
      "     1152    0.001    0.000    0.001    0.000 {method 'union' of 'set' objects}\n",
      "     2816    0.001    0.000    0.001    0.000 4135461766.py:422(<genexpr>)\n",
      "1285/1029    0.000    0.000    0.001    0.000 {built-in method builtins.sorted}\n",
      "      513    0.000    0.000    0.002    0.000 4135461766.py:201(<dictcomp>)\n",
      "      513    0.000    0.000    0.007    0.000 4135461766.py:260(_apply)\n",
      "     2304    0.000    0.000    0.000    0.000 4135461766.py:424(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "      642    0.000    0.000    0.002    0.000 4135461766.py:20(NewKey)\n",
      "1792/1664    0.000    0.000    0.001    0.000 4135461766.py:70(<genexpr>)\n",
      "      395    0.000    0.000    0.001    0.000 4135461766.py:245(_get_producers_of)\n",
      "        5    0.000    0.000    0.253    0.051 4135461766.py:363(_gather_valid_inputs)\n",
      "     5269    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "     3613    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "      4/1    0.000    0.000    0.375    0.375 {built-in method builtins.exec}\n",
      "      640    0.000    0.000    0.002    0.000 4135461766.py:38(__init__)\n",
      "     1537    0.000    0.000    0.000    0.000 4135461766.py:261(<genexpr>)\n",
      "      512    0.000    0.000    0.002    0.000 4135461766.py:83(__init__)\n",
      "      641    0.000    0.000    0.002    0.000 4135461766.py:26(__init__)\n",
      "      513    0.000    0.000    0.002    0.000 4135461766.py:418(<setcomp>)\n",
      "      513    0.000    0.000    0.000    0.000 4135461766.py:416(<listcomp>)\n",
      "      128    0.000    0.000    0.001    0.000 4135461766.py:115(_add_dependency)\n",
      "      396    0.000    0.000    0.000    0.000 <string>:2(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 dataclasses.py:885(_process_class)\n",
      "        1    0.000    0.000    0.001    0.001 4135461766.py:441(<dictcomp>)\n",
      "      128    0.000    0.000    0.001    0.000 4135461766.py:76(__init__)\n",
      "      128    0.000    0.000    0.001    0.000 4135461766.py:112(AddProduct)\n",
      "      2/1    0.000    0.000    0.000    0.000 inspect.py:2422(_signature_from_callable)\n",
      "        1    0.000    0.000    0.375    0.375 4135461766.py:236(Solve)\n",
      "      513    0.000    0.000    0.000    0.000 4135461766.py:436(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2327(_signature_from_function)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:724(_get_field)\n",
      "       15    0.000    0.000    0.000    0.000 dataclasses.py:665(_is_type)\n",
      "      134    0.000    0.000    0.000    0.000 4135461766.py:340(<genexpr>)\n",
      "        1    0.000    0.000    0.001    0.001 dataclasses.py:1210(wrap)\n",
      "      136    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:413(_create_fn)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:530(_init_fn)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3016(from_callable)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:2676(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:2962(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 enum.py:669(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3224(__str__)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        5    0.000    0.000    0.000    0.000 inspect.py:2763(__str__)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:1449(formatannotation)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:394(_recursive_repr)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2042(_signature_bound_method)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:735(unwrap)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:371(_fields_in_init_order)\n",
      "       42    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 4135461766.py:93(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:828(_set_new_attribute)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:267(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:589(_repr_fn)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:347(field)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:451(_field_init)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2068(_signature_is_builtin)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:647(_is_classvar)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:821(_set_qualname)\n",
      "       30    0.000    0.000    0.000    0.000 {method 'group' of 're.Match' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 interactiveshell.py:273(_modified_open)\n",
      "        7    0.000    0.000    0.000    0.000 inspect.py:3011(<genexpr>)\n",
      "       12    0.000    0.000    0.000    0.000 dataclasses.py:427(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:380(_tuple_str)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3270(signature)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:574(<listcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:655(_is_initvar)\n",
      "        1    0.000    0.000    0.001    0.001 dataclasses.py:1193(dataclass)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:167(get_annotations)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:550(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:325(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 4135461766.py:237(State)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:661(_is_kw_only)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.repr}\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:511(_init_param)\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:389(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:439(_field_assign)\n",
      "        3    0.000    0.000    0.000    0.000 inspect.py:1950(_signature_get_user_defined_method)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1018(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3032(replace)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2080(_signature_is_functionlike)\n",
      "        6    0.000    0.000    0.000    0.000 enum.py:1074(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:625(_cmp_fn)\n",
      "       17    0.000    0.000    0.000    0.000 inspect.py:2741(kind)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:593(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:186(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        6    0.000    0.000    0.000    0.000 dataclasses.py:375(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1044(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 inspect.py:378(isfunction)\n",
      "       11    0.000    0.000    0.000    0.000 inspect.py:2729(name)\n",
      "        6    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
      "        6    0.000    0.000    0.000    0.000 dataclasses.py:1102(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:755(_is_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1047(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:292(isclass)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:376(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1053(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:505(isbuiltin)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:310(ismethoddescriptor)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        5    0.000    0.000    0.000    0.000 inspect.py:2733(default)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen abc>:146(update_abstractmethods)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(__create_fn__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:3024(parameters)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:3028(return_annotation)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:843(_hash_set_none)"
     ]
    }
   ],
   "source": [
    "\n",
    "NS = Namespace()\n",
    "transforms = []\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"reads\"))\n",
    "t.AddProduct(_set(\"annable, taxable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"annable\"))\n",
    "t.AddProduct(_set(\"ann\"))\n",
    "transforms.append(t)\n",
    "\n",
    "# t = Transform(NS)\n",
    "# t.AddRequirement(_set(\"ann\"))\n",
    "# t.AddProduct(_set(\"annable\"))\n",
    "# transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"taxable\"))\n",
    "t.AddProduct(_set(\"tax\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "d_parent = t.AddRequirement(_set(\"annable, taxable\"))\n",
    "d_ann = t.AddRequirement(_set(\"ann\"), {d_parent})\n",
    "d_tax = t.AddRequirement(_set(\"tax\"), {d_parent})\n",
    "t.AddProduct(_set(\"sum\"))\n",
    "transforms.append(t)\n",
    "\n",
    "# M, N = 2, 1\n",
    "# M, N = 2, 2\n",
    "# M, N = 50, 2\n",
    "# M, N = 64, 64\n",
    "M, N = 128, 128\n",
    "haves = [Endpoint(NS, _set(f\"{i+1}, reads\")) for i in range(M)]\n",
    "\n",
    "target = Transform(NS)\n",
    "# for e in haves[-N:]:\n",
    "for e in haves[:N]:\n",
    "    de = target.AddRequirement(e.properties)\n",
    "    target.AddRequirement(_set(\"sum\"), {de})\n",
    "    # target.AddRequirement(_set(\"sum\"))\n",
    "\n",
    "print(\"Start\")\n",
    "# %prun r = Solve(haves, target, transforms)\n",
    "%prun solutions = Solve(haves, target, transforms)\n",
    "# f\"input size [{N}], states checked [{r.steps}], {r.message}, {len(target.requires)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "512\n",
      "{reads}->{taxable-annable} || (J000:reads-1) >> (N800:taxable-annable)\n",
      "{annable}->{ann} || (N800:taxable-annable) >> (NA00:ann)\n",
      "{taxable}->{tax} || (N800:taxable-annable) >> (NC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (N800:taxable-annable),(NA00:ann),(NC00:tax) >> (NE00:sum)\n",
      "{reads}->{taxable-annable} || (K000:2-reads) >> (O800:taxable-annable)\n",
      "{annable}->{ann} || (O800:taxable-annable) >> (OA00:ann)\n",
      "{taxable}->{tax} || (O800:taxable-annable) >> (OC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (O800:taxable-annable),(OA00:ann),(OC00:tax) >> (OE00:sum)\n",
      "{reads}->{taxable-annable} || (L000:reads-3) >> (P800:taxable-annable)\n",
      "{annable}->{ann} || (P800:taxable-annable) >> (PA00:ann)\n",
      "{taxable}->{tax} || (P800:taxable-annable) >> (PC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (P800:taxable-annable),(PA00:ann),(PC00:tax) >> (PE00:sum)\n",
      "{reads}->{taxable-annable} || (M000:4-reads) >> (Q800:taxable-annable)\n",
      "{annable}->{ann} || (Q800:taxable-annable) >> (QA00:ann)\n",
      "{taxable}->{tax} || (Q800:taxable-annable) >> (QC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (Q800:taxable-annable),(QA00:ann),(QC00:tax) >> (QE00:sum)\n",
      "{reads}->{taxable-annable} || (N000:5-reads) >> (R800:taxable-annable)\n",
      "{annable}->{ann} || (R800:taxable-annable) >> (RA00:ann)\n",
      "{taxable}->{tax} || (R800:taxable-annable) >> (RC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (R800:taxable-annable),(RA00:ann),(RC00:tax) >> (RE00:sum)\n",
      "{reads}->{taxable-annable} || (O000:reads-6) >> (S800:taxable-annable)\n",
      "{annable}->{ann} || (S800:taxable-annable) >> (SA00:ann)\n",
      "{taxable}->{tax} || (S800:taxable-annable) >> (SC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (S800:taxable-annable),(SA00:ann),(SC00:tax) >> (SE00:sum)\n",
      "{reads}->{taxable-annable} || (P000:7-reads) >> (T800:taxable-annable)\n",
      "{annable}->{ann} || (T800:taxable-annable) >> (TA00:ann)\n",
      "{taxable}->{tax} || (T800:taxable-annable) >> (TC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (T800:taxable-annable),(TA00:ann),(TC00:tax) >> (TE00:sum)\n",
      "{reads}->{taxable-annable} || (Q000:8-reads) >> (U800:taxable-annable)\n",
      "{annable}->{ann} || (U800:taxable-annable) >> (UA00:ann)\n",
      "{taxable}->{tax} || (U800:taxable-annable) >> (UC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (U800:taxable-annable),(UA00:ann),(UC00:tax) >> (UE00:sum)\n",
      "{reads}->{taxable-annable} || (R000:9-reads) >> (V800:taxable-annable)\n",
      "{annable}->{ann} || (V800:taxable-annable) >> (VA00:ann)\n",
      "{taxable}->{tax} || (V800:taxable-annable) >> (VC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (V800:taxable-annable),(VA00:ann),(VC00:tax) >> (VE00:sum)\n",
      "{reads}->{taxable-annable} || (S000:10-reads) >> (W800:taxable-annable)\n",
      "{annable}->{ann} || (W800:taxable-annable) >> (WA00:ann)\n",
      "{taxable}->{tax} || (W800:taxable-annable) >> (WC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (W800:taxable-annable),(WA00:ann),(WC00:tax) >> (WE00:sum)\n",
      "{reads}->{taxable-annable} || (T000:11-reads) >> (X800:taxable-annable)\n",
      "{annable}->{ann} || (X800:taxable-annable) >> (XA00:ann)\n",
      "{taxable}->{tax} || (X800:taxable-annable) >> (XC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (X800:taxable-annable),(XA00:ann),(XC00:tax) >> (XE00:sum)\n",
      "{reads}->{taxable-annable} || (U000:12-reads) >> (Y800:taxable-annable)\n",
      "{annable}->{ann} || (Y800:taxable-annable) >> (YA00:ann)\n",
      "{taxable}->{tax} || (Y800:taxable-annable) >> (YC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (Y800:taxable-annable),(YA00:ann),(YC00:tax) >> (YE00:sum)\n",
      "{reads}->{taxable-annable} || (V000:13-reads) >> (Z800:taxable-annable)\n",
      "{annable}->{ann} || (Z800:taxable-annable) >> (ZA00:ann)\n",
      "{taxable}->{tax} || (Z800:taxable-annable) >> (ZC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (Z800:taxable-annable),(ZA00:ann),(ZC00:tax) >> (ZE00:sum)\n",
      "{reads}->{taxable-annable} || (W000:reads-14) >> (a800:taxable-annable)\n",
      "{annable}->{ann} || (a800:taxable-annable) >> (aA00:ann)\n",
      "{taxable}->{tax} || (a800:taxable-annable) >> (aC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (a800:taxable-annable),(aA00:ann),(aC00:tax) >> (aE00:sum)\n",
      "{reads}->{taxable-annable} || (X000:15-reads) >> (b800:taxable-annable)\n",
      "{annable}->{ann} || (b800:taxable-annable) >> (bA00:ann)\n",
      "{taxable}->{tax} || (b800:taxable-annable) >> (bC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (b800:taxable-annable),(bA00:ann),(bC00:tax) >> (bE00:sum)\n",
      "{reads}->{taxable-annable} || (Y000:reads-16) >> (c800:taxable-annable)\n",
      "{annable}->{ann} || (c800:taxable-annable) >> (cA00:ann)\n",
      "{taxable}->{tax} || (c800:taxable-annable) >> (cC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (c800:taxable-annable),(cA00:ann),(cC00:tax) >> (cE00:sum)\n",
      "{reads}->{taxable-annable} || (Z000:17-reads) >> (d800:taxable-annable)\n",
      "{annable}->{ann} || (d800:taxable-annable) >> (dA00:ann)\n",
      "{taxable}->{tax} || (d800:taxable-annable) >> (dC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (d800:taxable-annable),(dA00:ann),(dC00:tax) >> (dE00:sum)\n",
      "{reads}->{taxable-annable} || (a000:18-reads) >> (e800:taxable-annable)\n",
      "{annable}->{ann} || (e800:taxable-annable) >> (eA00:ann)\n",
      "{taxable}->{tax} || (e800:taxable-annable) >> (eC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (e800:taxable-annable),(eA00:ann),(eC00:tax) >> (eE00:sum)\n",
      "{reads}->{taxable-annable} || (b000:19-reads) >> (f800:taxable-annable)\n",
      "{annable}->{ann} || (f800:taxable-annable) >> (fA00:ann)\n",
      "{taxable}->{tax} || (f800:taxable-annable) >> (fC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (f800:taxable-annable),(fA00:ann),(fC00:tax) >> (fE00:sum)\n",
      "{reads}->{taxable-annable} || (c000:20-reads) >> (g800:taxable-annable)\n",
      "{annable}->{ann} || (g800:taxable-annable) >> (gA00:ann)\n",
      "{taxable}->{tax} || (g800:taxable-annable) >> (gC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (g800:taxable-annable),(gA00:ann),(gC00:tax) >> (gE00:sum)\n",
      "{reads}->{taxable-annable} || (d000:21-reads) >> (h800:taxable-annable)\n",
      "{annable}->{ann} || (h800:taxable-annable) >> (hA00:ann)\n",
      "{taxable}->{tax} || (h800:taxable-annable) >> (hC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (h800:taxable-annable),(hA00:ann),(hC00:tax) >> (hE00:sum)\n",
      "{reads}->{taxable-annable} || (e000:22-reads) >> (i800:taxable-annable)\n",
      "{annable}->{ann} || (i800:taxable-annable) >> (iA00:ann)\n",
      "{taxable}->{tax} || (i800:taxable-annable) >> (iC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (i800:taxable-annable),(iA00:ann),(iC00:tax) >> (iE00:sum)\n",
      "{reads}->{taxable-annable} || (f000:reads-23) >> (j800:taxable-annable)\n",
      "{annable}->{ann} || (j800:taxable-annable) >> (jA00:ann)\n",
      "{taxable}->{tax} || (j800:taxable-annable) >> (jC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (j800:taxable-annable),(jA00:ann),(jC00:tax) >> (jE00:sum)\n",
      "{reads}->{taxable-annable} || (g000:24-reads) >> (k800:taxable-annable)\n",
      "{annable}->{ann} || (k800:taxable-annable) >> (kA00:ann)\n",
      "{taxable}->{tax} || (k800:taxable-annable) >> (kC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (k800:taxable-annable),(kA00:ann),(kC00:tax) >> (kE00:sum)\n",
      "{reads}->{taxable-annable} || (h000:25-reads) >> (l800:taxable-annable)\n",
      "{annable}->{ann} || (l800:taxable-annable) >> (lA00:ann)\n",
      "{taxable}->{tax} || (l800:taxable-annable) >> (lC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (l800:taxable-annable),(lA00:ann),(lC00:tax) >> (lE00:sum)\n",
      "{reads}->{taxable-annable} || (i000:26-reads) >> (m800:taxable-annable)\n",
      "{annable}->{ann} || (m800:taxable-annable) >> (mA00:ann)\n",
      "{taxable}->{tax} || (m800:taxable-annable) >> (mC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (m800:taxable-annable),(mA00:ann),(mC00:tax) >> (mE00:sum)\n",
      "{reads}->{taxable-annable} || (j000:27-reads) >> (n800:taxable-annable)\n",
      "{annable}->{ann} || (n800:taxable-annable) >> (nA00:ann)\n",
      "{taxable}->{tax} || (n800:taxable-annable) >> (nC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (n800:taxable-annable),(nA00:ann),(nC00:tax) >> (nE00:sum)\n",
      "{reads}->{taxable-annable} || (k000:28-reads) >> (o800:taxable-annable)\n",
      "{annable}->{ann} || (o800:taxable-annable) >> (oA00:ann)\n",
      "{taxable}->{tax} || (o800:taxable-annable) >> (oC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (o800:taxable-annable),(oA00:ann),(oC00:tax) >> (oE00:sum)\n",
      "{reads}->{taxable-annable} || (l000:29-reads) >> (p800:taxable-annable)\n",
      "{annable}->{ann} || (p800:taxable-annable) >> (pA00:ann)\n",
      "{taxable}->{tax} || (p800:taxable-annable) >> (pC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (p800:taxable-annable),(pA00:ann),(pC00:tax) >> (pE00:sum)\n",
      "{reads}->{taxable-annable} || (m000:30-reads) >> (q800:taxable-annable)\n",
      "{annable}->{ann} || (q800:taxable-annable) >> (qA00:ann)\n",
      "{taxable}->{tax} || (q800:taxable-annable) >> (qC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (q800:taxable-annable),(qA00:ann),(qC00:tax) >> (qE00:sum)\n",
      "{reads}->{taxable-annable} || (n000:31-reads) >> (r800:taxable-annable)\n",
      "{annable}->{ann} || (r800:taxable-annable) >> (rA00:ann)\n",
      "{taxable}->{tax} || (r800:taxable-annable) >> (rC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (r800:taxable-annable),(rA00:ann),(rC00:tax) >> (rE00:sum)\n",
      "{reads}->{taxable-annable} || (o000:reads-32) >> (s800:taxable-annable)\n",
      "{annable}->{ann} || (s800:taxable-annable) >> (sA00:ann)\n",
      "{taxable}->{tax} || (s800:taxable-annable) >> (sC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (s800:taxable-annable),(sA00:ann),(sC00:tax) >> (sE00:sum)\n",
      "{reads}->{taxable-annable} || (p000:33-reads) >> (t800:taxable-annable)\n",
      "{annable}->{ann} || (t800:taxable-annable) >> (tA00:ann)\n",
      "{taxable}->{tax} || (t800:taxable-annable) >> (tC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (t800:taxable-annable),(tA00:ann),(tC00:tax) >> (tE00:sum)\n",
      "{reads}->{taxable-annable} || (q000:reads-34) >> (u800:taxable-annable)\n",
      "{annable}->{ann} || (u800:taxable-annable) >> (uA00:ann)\n",
      "{taxable}->{tax} || (u800:taxable-annable) >> (uC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (u800:taxable-annable),(uA00:ann),(uC00:tax) >> (uE00:sum)\n",
      "{reads}->{taxable-annable} || (r000:35-reads) >> (v800:taxable-annable)\n",
      "{annable}->{ann} || (v800:taxable-annable) >> (vA00:ann)\n",
      "{taxable}->{tax} || (v800:taxable-annable) >> (vC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (v800:taxable-annable),(vA00:ann),(vC00:tax) >> (vE00:sum)\n",
      "{reads}->{taxable-annable} || (s000:36-reads) >> (w800:taxable-annable)\n",
      "{annable}->{ann} || (w800:taxable-annable) >> (wA00:ann)\n",
      "{taxable}->{tax} || (w800:taxable-annable) >> (wC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (w800:taxable-annable),(wA00:ann),(wC00:tax) >> (wE00:sum)\n",
      "{reads}->{taxable-annable} || (t000:37-reads) >> (x800:taxable-annable)\n",
      "{annable}->{ann} || (x800:taxable-annable) >> (xA00:ann)\n",
      "{taxable}->{tax} || (x800:taxable-annable) >> (xC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (x800:taxable-annable),(xA00:ann),(xC00:tax) >> (xE00:sum)\n",
      "{reads}->{taxable-annable} || (u000:38-reads) >> (y800:taxable-annable)\n",
      "{annable}->{ann} || (y800:taxable-annable) >> (yA00:ann)\n",
      "{taxable}->{tax} || (y800:taxable-annable) >> (yC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (y800:taxable-annable),(yA00:ann),(yC00:tax) >> (yE00:sum)\n",
      "{reads}->{taxable-annable} || (v000:39-reads) >> (z800:taxable-annable)\n",
      "{annable}->{ann} || (z800:taxable-annable) >> (zA00:ann)\n",
      "{taxable}->{tax} || (z800:taxable-annable) >> (zC00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (z800:taxable-annable),(zA00:ann),(zC00:tax) >> (zE00:sum)\n",
      "{reads}->{taxable-annable} || (w000:40-reads) >> (+800:taxable-annable)\n",
      "{annable}->{ann} || (+800:taxable-annable) >> (+A00:ann)\n",
      "{taxable}->{tax} || (+800:taxable-annable) >> (+C00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (+800:taxable-annable),(+A00:ann),(+C00:tax) >> (+E00:sum)\n",
      "{reads}->{taxable-annable} || (x000:41-reads) >> (=800:taxable-annable)\n",
      "{annable}->{ann} || (=800:taxable-annable) >> (=A00:ann)\n",
      "{taxable}->{tax} || (=800:taxable-annable) >> (=C00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (=800:taxable-annable),(=A00:ann),(=C00:tax) >> (=E00:sum)\n",
      "{reads}->{taxable-annable} || (y000:42-reads) >> (0900:taxable-annable)\n",
      "{annable}->{ann} || (0900:taxable-annable) >> (0B00:ann)\n",
      "{taxable}->{tax} || (0900:taxable-annable) >> (0D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (0900:taxable-annable),(0B00:ann),(0D00:tax) >> (0F00:sum)\n",
      "{reads}->{taxable-annable} || (z000:43-reads) >> (1900:taxable-annable)\n",
      "{annable}->{ann} || (1900:taxable-annable) >> (1B00:ann)\n",
      "{taxable}->{tax} || (1900:taxable-annable) >> (1D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (1900:taxable-annable),(1B00:ann),(1D00:tax) >> (1F00:sum)\n",
      "{reads}->{taxable-annable} || (+000:44-reads) >> (2900:taxable-annable)\n",
      "{annable}->{ann} || (2900:taxable-annable) >> (2B00:ann)\n",
      "{taxable}->{tax} || (2900:taxable-annable) >> (2D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (2900:taxable-annable),(2B00:ann),(2D00:tax) >> (2F00:sum)\n",
      "{reads}->{taxable-annable} || (=000:45-reads) >> (3900:taxable-annable)\n",
      "{annable}->{ann} || (3900:taxable-annable) >> (3B00:ann)\n",
      "{taxable}->{tax} || (3900:taxable-annable) >> (3D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (3900:taxable-annable),(3B00:ann),(3D00:tax) >> (3F00:sum)\n",
      "{reads}->{taxable-annable} || (0100:46-reads) >> (4900:taxable-annable)\n",
      "{annable}->{ann} || (4900:taxable-annable) >> (4B00:ann)\n",
      "{taxable}->{tax} || (4900:taxable-annable) >> (4D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (4900:taxable-annable),(4B00:ann),(4D00:tax) >> (4F00:sum)\n",
      "{reads}->{taxable-annable} || (1100:reads-47) >> (5900:taxable-annable)\n",
      "{annable}->{ann} || (5900:taxable-annable) >> (5B00:ann)\n",
      "{taxable}->{tax} || (5900:taxable-annable) >> (5D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (5900:taxable-annable),(5B00:ann),(5D00:tax) >> (5F00:sum)\n",
      "{reads}->{taxable-annable} || (2100:48-reads) >> (6900:taxable-annable)\n",
      "{annable}->{ann} || (6900:taxable-annable) >> (6B00:ann)\n",
      "{taxable}->{tax} || (6900:taxable-annable) >> (6D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (6900:taxable-annable),(6B00:ann),(6D00:tax) >> (6F00:sum)\n",
      "{reads}->{taxable-annable} || (3100:49-reads) >> (7900:taxable-annable)\n",
      "{annable}->{ann} || (7900:taxable-annable) >> (7B00:ann)\n",
      "{taxable}->{tax} || (7900:taxable-annable) >> (7D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (7900:taxable-annable),(7B00:ann),(7D00:tax) >> (7F00:sum)\n",
      "{reads}->{taxable-annable} || (4100:50-reads) >> (8900:taxable-annable)\n",
      "{annable}->{ann} || (8900:taxable-annable) >> (8B00:ann)\n",
      "{taxable}->{tax} || (8900:taxable-annable) >> (8D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (8900:taxable-annable),(8B00:ann),(8D00:tax) >> (8F00:sum)\n",
      "{reads}->{taxable-annable} || (5100:51-reads) >> (9900:taxable-annable)\n",
      "{annable}->{ann} || (9900:taxable-annable) >> (9B00:ann)\n",
      "{taxable}->{tax} || (9900:taxable-annable) >> (9D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (9900:taxable-annable),(9B00:ann),(9D00:tax) >> (9F00:sum)\n",
      "{reads}->{taxable-annable} || (6100:52-reads) >> (A900:taxable-annable)\n",
      "{annable}->{ann} || (A900:taxable-annable) >> (AB00:ann)\n",
      "{taxable}->{tax} || (A900:taxable-annable) >> (AD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (A900:taxable-annable),(AB00:ann),(AD00:tax) >> (AF00:sum)\n",
      "{reads}->{taxable-annable} || (7100:53-reads) >> (B900:taxable-annable)\n",
      "{annable}->{ann} || (B900:taxable-annable) >> (BB00:ann)\n",
      "{taxable}->{tax} || (B900:taxable-annable) >> (BD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (B900:taxable-annable),(BB00:ann),(BD00:tax) >> (BF00:sum)\n",
      "{reads}->{taxable-annable} || (8100:reads-54) >> (C900:taxable-annable)\n",
      "{annable}->{ann} || (C900:taxable-annable) >> (CB00:ann)\n",
      "{taxable}->{tax} || (C900:taxable-annable) >> (CD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (C900:taxable-annable),(CB00:ann),(CD00:tax) >> (CF00:sum)\n",
      "{reads}->{taxable-annable} || (9100:55-reads) >> (D900:taxable-annable)\n",
      "{annable}->{ann} || (D900:taxable-annable) >> (DB00:ann)\n",
      "{taxable}->{tax} || (D900:taxable-annable) >> (DD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (D900:taxable-annable),(DB00:ann),(DD00:tax) >> (DF00:sum)\n",
      "{reads}->{taxable-annable} || (A100:56-reads) >> (E900:taxable-annable)\n",
      "{annable}->{ann} || (E900:taxable-annable) >> (EB00:ann)\n",
      "{taxable}->{tax} || (E900:taxable-annable) >> (ED00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (E900:taxable-annable),(EB00:ann),(ED00:tax) >> (EF00:sum)\n",
      "{reads}->{taxable-annable} || (B100:57-reads) >> (F900:taxable-annable)\n",
      "{annable}->{ann} || (F900:taxable-annable) >> (FB00:ann)\n",
      "{taxable}->{tax} || (F900:taxable-annable) >> (FD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (F900:taxable-annable),(FB00:ann),(FD00:tax) >> (FF00:sum)\n",
      "{reads}->{taxable-annable} || (C100:58-reads) >> (G900:taxable-annable)\n",
      "{annable}->{ann} || (G900:taxable-annable) >> (GB00:ann)\n",
      "{taxable}->{tax} || (G900:taxable-annable) >> (GD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (G900:taxable-annable),(GB00:ann),(GD00:tax) >> (GF00:sum)\n",
      "{reads}->{taxable-annable} || (D100:59-reads) >> (H900:taxable-annable)\n",
      "{annable}->{ann} || (H900:taxable-annable) >> (HB00:ann)\n",
      "{taxable}->{tax} || (H900:taxable-annable) >> (HD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (H900:taxable-annable),(HB00:ann),(HD00:tax) >> (HF00:sum)\n",
      "{reads}->{taxable-annable} || (E100:60-reads) >> (I900:taxable-annable)\n",
      "{annable}->{ann} || (I900:taxable-annable) >> (IB00:ann)\n",
      "{taxable}->{tax} || (I900:taxable-annable) >> (ID00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (I900:taxable-annable),(IB00:ann),(ID00:tax) >> (IF00:sum)\n",
      "{reads}->{taxable-annable} || (F100:61-reads) >> (J900:taxable-annable)\n",
      "{annable}->{ann} || (J900:taxable-annable) >> (JB00:ann)\n",
      "{taxable}->{tax} || (J900:taxable-annable) >> (JD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (J900:taxable-annable),(JB00:ann),(JD00:tax) >> (JF00:sum)\n",
      "{reads}->{taxable-annable} || (G100:62-reads) >> (K900:taxable-annable)\n",
      "{annable}->{ann} || (K900:taxable-annable) >> (KB00:ann)\n",
      "{taxable}->{tax} || (K900:taxable-annable) >> (KD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (K900:taxable-annable),(KB00:ann),(KD00:tax) >> (KF00:sum)\n",
      "{reads}->{taxable-annable} || (H100:63-reads) >> (L900:taxable-annable)\n",
      "{annable}->{ann} || (L900:taxable-annable) >> (LB00:ann)\n",
      "{taxable}->{tax} || (L900:taxable-annable) >> (LD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (L900:taxable-annable),(LB00:ann),(LD00:tax) >> (LF00:sum)\n",
      "{reads}->{taxable-annable} || (I100:64-reads) >> (M900:taxable-annable)\n",
      "{annable}->{ann} || (M900:taxable-annable) >> (MB00:ann)\n",
      "{taxable}->{tax} || (M900:taxable-annable) >> (MD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (M900:taxable-annable),(MB00:ann),(MD00:tax) >> (MF00:sum)\n",
      "{reads}->{taxable-annable} || (J100:65-reads) >> (N900:taxable-annable)\n",
      "{annable}->{ann} || (N900:taxable-annable) >> (NB00:ann)\n",
      "{taxable}->{tax} || (N900:taxable-annable) >> (ND00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (N900:taxable-annable),(NB00:ann),(ND00:tax) >> (NF00:sum)\n",
      "{reads}->{taxable-annable} || (K100:66-reads) >> (O900:taxable-annable)\n",
      "{annable}->{ann} || (O900:taxable-annable) >> (OB00:ann)\n",
      "{taxable}->{tax} || (O900:taxable-annable) >> (OD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (O900:taxable-annable),(OB00:ann),(OD00:tax) >> (OF00:sum)\n",
      "{reads}->{taxable-annable} || (L100:reads-67) >> (P900:taxable-annable)\n",
      "{annable}->{ann} || (P900:taxable-annable) >> (PB00:ann)\n",
      "{taxable}->{tax} || (P900:taxable-annable) >> (PD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (P900:taxable-annable),(PB00:ann),(PD00:tax) >> (PF00:sum)\n",
      "{reads}->{taxable-annable} || (M100:68-reads) >> (Q900:taxable-annable)\n",
      "{annable}->{ann} || (Q900:taxable-annable) >> (QB00:ann)\n",
      "{taxable}->{tax} || (Q900:taxable-annable) >> (QD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (Q900:taxable-annable),(QB00:ann),(QD00:tax) >> (QF00:sum)\n",
      "{reads}->{taxable-annable} || (N100:69-reads) >> (R900:taxable-annable)\n",
      "{annable}->{ann} || (R900:taxable-annable) >> (RB00:ann)\n",
      "{taxable}->{tax} || (R900:taxable-annable) >> (RD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (R900:taxable-annable),(RB00:ann),(RD00:tax) >> (RF00:sum)\n",
      "{reads}->{taxable-annable} || (O100:70-reads) >> (S900:taxable-annable)\n",
      "{annable}->{ann} || (S900:taxable-annable) >> (SB00:ann)\n",
      "{taxable}->{tax} || (S900:taxable-annable) >> (SD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (S900:taxable-annable),(SB00:ann),(SD00:tax) >> (SF00:sum)\n",
      "{reads}->{taxable-annable} || (P100:71-reads) >> (T900:taxable-annable)\n",
      "{annable}->{ann} || (T900:taxable-annable) >> (TB00:ann)\n",
      "{taxable}->{tax} || (T900:taxable-annable) >> (TD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (T900:taxable-annable),(TB00:ann),(TD00:tax) >> (TF00:sum)\n",
      "{reads}->{taxable-annable} || (Q100:72-reads) >> (U900:taxable-annable)\n",
      "{annable}->{ann} || (U900:taxable-annable) >> (UB00:ann)\n",
      "{taxable}->{tax} || (U900:taxable-annable) >> (UD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (U900:taxable-annable),(UB00:ann),(UD00:tax) >> (UF00:sum)\n",
      "{reads}->{taxable-annable} || (R100:73-reads) >> (V900:taxable-annable)\n",
      "{annable}->{ann} || (V900:taxable-annable) >> (VB00:ann)\n",
      "{taxable}->{tax} || (V900:taxable-annable) >> (VD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (V900:taxable-annable),(VB00:ann),(VD00:tax) >> (VF00:sum)\n",
      "{reads}->{taxable-annable} || (S100:74-reads) >> (W900:taxable-annable)\n",
      "{annable}->{ann} || (W900:taxable-annable) >> (WB00:ann)\n",
      "{taxable}->{tax} || (W900:taxable-annable) >> (WD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (W900:taxable-annable),(WB00:ann),(WD00:tax) >> (WF00:sum)\n",
      "{reads}->{taxable-annable} || (T100:75-reads) >> (X900:taxable-annable)\n",
      "{annable}->{ann} || (X900:taxable-annable) >> (XB00:ann)\n",
      "{taxable}->{tax} || (X900:taxable-annable) >> (XD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (X900:taxable-annable),(XB00:ann),(XD00:tax) >> (XF00:sum)\n",
      "{reads}->{taxable-annable} || (U100:76-reads) >> (Y900:taxable-annable)\n",
      "{annable}->{ann} || (Y900:taxable-annable) >> (YB00:ann)\n",
      "{taxable}->{tax} || (Y900:taxable-annable) >> (YD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (Y900:taxable-annable),(YB00:ann),(YD00:tax) >> (YF00:sum)\n",
      "{reads}->{taxable-annable} || (V100:77-reads) >> (Z900:taxable-annable)\n",
      "{annable}->{ann} || (Z900:taxable-annable) >> (ZB00:ann)\n",
      "{taxable}->{tax} || (Z900:taxable-annable) >> (ZD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (Z900:taxable-annable),(ZB00:ann),(ZD00:tax) >> (ZF00:sum)\n",
      "{reads}->{taxable-annable} || (W100:78-reads) >> (a900:taxable-annable)\n",
      "{annable}->{ann} || (a900:taxable-annable) >> (aB00:ann)\n",
      "{taxable}->{tax} || (a900:taxable-annable) >> (aD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (a900:taxable-annable),(aB00:ann),(aD00:tax) >> (aF00:sum)\n",
      "{reads}->{taxable-annable} || (X100:79-reads) >> (b900:taxable-annable)\n",
      "{annable}->{ann} || (b900:taxable-annable) >> (bB00:ann)\n",
      "{taxable}->{tax} || (b900:taxable-annable) >> (bD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (b900:taxable-annable),(bB00:ann),(bD00:tax) >> (bF00:sum)\n",
      "{reads}->{taxable-annable} || (Y100:80-reads) >> (c900:taxable-annable)\n",
      "{annable}->{ann} || (c900:taxable-annable) >> (cB00:ann)\n",
      "{taxable}->{tax} || (c900:taxable-annable) >> (cD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (c900:taxable-annable),(cB00:ann),(cD00:tax) >> (cF00:sum)\n",
      "{reads}->{taxable-annable} || (Z100:81-reads) >> (d900:taxable-annable)\n",
      "{annable}->{ann} || (d900:taxable-annable) >> (dB00:ann)\n",
      "{taxable}->{tax} || (d900:taxable-annable) >> (dD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (d900:taxable-annable),(dB00:ann),(dD00:tax) >> (dF00:sum)\n",
      "{reads}->{taxable-annable} || (a100:82-reads) >> (e900:taxable-annable)\n",
      "{annable}->{ann} || (e900:taxable-annable) >> (eB00:ann)\n",
      "{taxable}->{tax} || (e900:taxable-annable) >> (eD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (e900:taxable-annable),(eB00:ann),(eD00:tax) >> (eF00:sum)\n",
      "{reads}->{taxable-annable} || (b100:83-reads) >> (f900:taxable-annable)\n",
      "{annable}->{ann} || (f900:taxable-annable) >> (fB00:ann)\n",
      "{taxable}->{tax} || (f900:taxable-annable) >> (fD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (f900:taxable-annable),(fB00:ann),(fD00:tax) >> (fF00:sum)\n",
      "{reads}->{taxable-annable} || (c100:84-reads) >> (g900:taxable-annable)\n",
      "{annable}->{ann} || (g900:taxable-annable) >> (gB00:ann)\n",
      "{taxable}->{tax} || (g900:taxable-annable) >> (gD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (g900:taxable-annable),(gB00:ann),(gD00:tax) >> (gF00:sum)\n",
      "{reads}->{taxable-annable} || (d100:85-reads) >> (h900:taxable-annable)\n",
      "{annable}->{ann} || (h900:taxable-annable) >> (hB00:ann)\n",
      "{taxable}->{tax} || (h900:taxable-annable) >> (hD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (h900:taxable-annable),(hB00:ann),(hD00:tax) >> (hF00:sum)\n",
      "{reads}->{taxable-annable} || (e100:reads-86) >> (i900:taxable-annable)\n",
      "{annable}->{ann} || (i900:taxable-annable) >> (iB00:ann)\n",
      "{taxable}->{tax} || (i900:taxable-annable) >> (iD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (i900:taxable-annable),(iB00:ann),(iD00:tax) >> (iF00:sum)\n",
      "{reads}->{taxable-annable} || (f100:87-reads) >> (j900:taxable-annable)\n",
      "{annable}->{ann} || (j900:taxable-annable) >> (jB00:ann)\n",
      "{taxable}->{tax} || (j900:taxable-annable) >> (jD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (j900:taxable-annable),(jB00:ann),(jD00:tax) >> (jF00:sum)\n",
      "{reads}->{taxable-annable} || (g100:88-reads) >> (k900:taxable-annable)\n",
      "{annable}->{ann} || (k900:taxable-annable) >> (kB00:ann)\n",
      "{taxable}->{tax} || (k900:taxable-annable) >> (kD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (k900:taxable-annable),(kB00:ann),(kD00:tax) >> (kF00:sum)\n",
      "{reads}->{taxable-annable} || (h100:89-reads) >> (l900:taxable-annable)\n",
      "{annable}->{ann} || (l900:taxable-annable) >> (lB00:ann)\n",
      "{taxable}->{tax} || (l900:taxable-annable) >> (lD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (l900:taxable-annable),(lB00:ann),(lD00:tax) >> (lF00:sum)\n",
      "{reads}->{taxable-annable} || (i100:90-reads) >> (m900:taxable-annable)\n",
      "{annable}->{ann} || (m900:taxable-annable) >> (mB00:ann)\n",
      "{taxable}->{tax} || (m900:taxable-annable) >> (mD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (m900:taxable-annable),(mB00:ann),(mD00:tax) >> (mF00:sum)\n",
      "{reads}->{taxable-annable} || (j100:91-reads) >> (n900:taxable-annable)\n",
      "{annable}->{ann} || (n900:taxable-annable) >> (nB00:ann)\n",
      "{taxable}->{tax} || (n900:taxable-annable) >> (nD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (n900:taxable-annable),(nB00:ann),(nD00:tax) >> (nF00:sum)\n",
      "{reads}->{taxable-annable} || (k100:92-reads) >> (o900:taxable-annable)\n",
      "{annable}->{ann} || (o900:taxable-annable) >> (oB00:ann)\n",
      "{taxable}->{tax} || (o900:taxable-annable) >> (oD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (o900:taxable-annable),(oB00:ann),(oD00:tax) >> (oF00:sum)\n",
      "{reads}->{taxable-annable} || (l100:93-reads) >> (p900:taxable-annable)\n",
      "{annable}->{ann} || (p900:taxable-annable) >> (pB00:ann)\n",
      "{taxable}->{tax} || (p900:taxable-annable) >> (pD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (p900:taxable-annable),(pB00:ann),(pD00:tax) >> (pF00:sum)\n",
      "{reads}->{taxable-annable} || (m100:94-reads) >> (q900:taxable-annable)\n",
      "{annable}->{ann} || (q900:taxable-annable) >> (qB00:ann)\n",
      "{taxable}->{tax} || (q900:taxable-annable) >> (qD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (q900:taxable-annable),(qB00:ann),(qD00:tax) >> (qF00:sum)\n",
      "{reads}->{taxable-annable} || (n100:95-reads) >> (r900:taxable-annable)\n",
      "{annable}->{ann} || (r900:taxable-annable) >> (rB00:ann)\n",
      "{taxable}->{tax} || (r900:taxable-annable) >> (rD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (r900:taxable-annable),(rB00:ann),(rD00:tax) >> (rF00:sum)\n",
      "{reads}->{taxable-annable} || (o100:96-reads) >> (s900:taxable-annable)\n",
      "{annable}->{ann} || (s900:taxable-annable) >> (sB00:ann)\n",
      "{taxable}->{tax} || (s900:taxable-annable) >> (sD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (s900:taxable-annable),(sB00:ann),(sD00:tax) >> (sF00:sum)\n",
      "{reads}->{taxable-annable} || (p100:reads-97) >> (t900:taxable-annable)\n",
      "{annable}->{ann} || (t900:taxable-annable) >> (tB00:ann)\n",
      "{taxable}->{tax} || (t900:taxable-annable) >> (tD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (t900:taxable-annable),(tB00:ann),(tD00:tax) >> (tF00:sum)\n",
      "{reads}->{taxable-annable} || (q100:98-reads) >> (u900:taxable-annable)\n",
      "{annable}->{ann} || (u900:taxable-annable) >> (uB00:ann)\n",
      "{taxable}->{tax} || (u900:taxable-annable) >> (uD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (u900:taxable-annable),(uB00:ann),(uD00:tax) >> (uF00:sum)\n",
      "{reads}->{taxable-annable} || (r100:99-reads) >> (v900:taxable-annable)\n",
      "{annable}->{ann} || (v900:taxable-annable) >> (vB00:ann)\n",
      "{taxable}->{tax} || (v900:taxable-annable) >> (vD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (v900:taxable-annable),(vB00:ann),(vD00:tax) >> (vF00:sum)\n",
      "{reads}->{taxable-annable} || (s100:100-reads) >> (w900:taxable-annable)\n",
      "{annable}->{ann} || (w900:taxable-annable) >> (wB00:ann)\n",
      "{taxable}->{tax} || (w900:taxable-annable) >> (wD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (w900:taxable-annable),(wB00:ann),(wD00:tax) >> (wF00:sum)\n",
      "{reads}->{taxable-annable} || (t100:101-reads) >> (x900:taxable-annable)\n",
      "{annable}->{ann} || (x900:taxable-annable) >> (xB00:ann)\n",
      "{taxable}->{tax} || (x900:taxable-annable) >> (xD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (x900:taxable-annable),(xB00:ann),(xD00:tax) >> (xF00:sum)\n",
      "{reads}->{taxable-annable} || (u100:102-reads) >> (y900:taxable-annable)\n",
      "{annable}->{ann} || (y900:taxable-annable) >> (yB00:ann)\n",
      "{taxable}->{tax} || (y900:taxable-annable) >> (yD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (y900:taxable-annable),(yB00:ann),(yD00:tax) >> (yF00:sum)\n",
      "{reads}->{taxable-annable} || (v100:reads-103) >> (z900:taxable-annable)\n",
      "{annable}->{ann} || (z900:taxable-annable) >> (zB00:ann)\n",
      "{taxable}->{tax} || (z900:taxable-annable) >> (zD00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (z900:taxable-annable),(zB00:ann),(zD00:tax) >> (zF00:sum)\n",
      "{reads}->{taxable-annable} || (w100:104-reads) >> (+900:taxable-annable)\n",
      "{annable}->{ann} || (+900:taxable-annable) >> (+B00:ann)\n",
      "{taxable}->{tax} || (+900:taxable-annable) >> (+D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (+900:taxable-annable),(+B00:ann),(+D00:tax) >> (+F00:sum)\n",
      "{reads}->{taxable-annable} || (x100:105-reads) >> (=900:taxable-annable)\n",
      "{annable}->{ann} || (=900:taxable-annable) >> (=B00:ann)\n",
      "{taxable}->{tax} || (=900:taxable-annable) >> (=D00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (=900:taxable-annable),(=B00:ann),(=D00:tax) >> (=F00:sum)\n",
      "{reads}->{taxable-annable} || (y100:106-reads) >> (0A00:taxable-annable)\n",
      "{annable}->{ann} || (0A00:taxable-annable) >> (0C00:ann)\n",
      "{taxable}->{tax} || (0A00:taxable-annable) >> (0E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (0A00:taxable-annable),(0C00:ann),(0E00:tax) >> (0G00:sum)\n",
      "{reads}->{taxable-annable} || (z100:107-reads) >> (1A00:taxable-annable)\n",
      "{annable}->{ann} || (1A00:taxable-annable) >> (1C00:ann)\n",
      "{taxable}->{tax} || (1A00:taxable-annable) >> (1E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (1A00:taxable-annable),(1C00:ann),(1E00:tax) >> (1G00:sum)\n",
      "{reads}->{taxable-annable} || (+100:108-reads) >> (2A00:taxable-annable)\n",
      "{annable}->{ann} || (2A00:taxable-annable) >> (2C00:ann)\n",
      "{taxable}->{tax} || (2A00:taxable-annable) >> (2E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (2A00:taxable-annable),(2C00:ann),(2E00:tax) >> (2G00:sum)\n",
      "{reads}->{taxable-annable} || (=100:109-reads) >> (3A00:taxable-annable)\n",
      "{annable}->{ann} || (3A00:taxable-annable) >> (3C00:ann)\n",
      "{taxable}->{tax} || (3A00:taxable-annable) >> (3E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (3A00:taxable-annable),(3C00:ann),(3E00:tax) >> (3G00:sum)\n",
      "{reads}->{taxable-annable} || (0200:110-reads) >> (4A00:taxable-annable)\n",
      "{annable}->{ann} || (4A00:taxable-annable) >> (4C00:ann)\n",
      "{taxable}->{tax} || (4A00:taxable-annable) >> (4E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (4A00:taxable-annable),(4C00:ann),(4E00:tax) >> (4G00:sum)\n",
      "{reads}->{taxable-annable} || (1200:reads-111) >> (5A00:taxable-annable)\n",
      "{annable}->{ann} || (5A00:taxable-annable) >> (5C00:ann)\n",
      "{taxable}->{tax} || (5A00:taxable-annable) >> (5E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (5A00:taxable-annable),(5C00:ann),(5E00:tax) >> (5G00:sum)\n",
      "{reads}->{taxable-annable} || (2200:reads-112) >> (6A00:taxable-annable)\n",
      "{annable}->{ann} || (6A00:taxable-annable) >> (6C00:ann)\n",
      "{taxable}->{tax} || (6A00:taxable-annable) >> (6E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (6A00:taxable-annable),(6C00:ann),(6E00:tax) >> (6G00:sum)\n",
      "{reads}->{taxable-annable} || (3200:113-reads) >> (7A00:taxable-annable)\n",
      "{annable}->{ann} || (7A00:taxable-annable) >> (7C00:ann)\n",
      "{taxable}->{tax} || (7A00:taxable-annable) >> (7E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (7A00:taxable-annable),(7C00:ann),(7E00:tax) >> (7G00:sum)\n",
      "{reads}->{taxable-annable} || (4200:114-reads) >> (8A00:taxable-annable)\n",
      "{annable}->{ann} || (8A00:taxable-annable) >> (8C00:ann)\n",
      "{taxable}->{tax} || (8A00:taxable-annable) >> (8E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (8A00:taxable-annable),(8C00:ann),(8E00:tax) >> (8G00:sum)\n",
      "{reads}->{taxable-annable} || (5200:reads-115) >> (9A00:taxable-annable)\n",
      "{annable}->{ann} || (9A00:taxable-annable) >> (9C00:ann)\n",
      "{taxable}->{tax} || (9A00:taxable-annable) >> (9E00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (9A00:taxable-annable),(9C00:ann),(9E00:tax) >> (9G00:sum)\n",
      "{reads}->{taxable-annable} || (6200:reads-116) >> (AA00:taxable-annable)\n",
      "{annable}->{ann} || (AA00:taxable-annable) >> (AC00:ann)\n",
      "{taxable}->{tax} || (AA00:taxable-annable) >> (AE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (AA00:taxable-annable),(AC00:ann),(AE00:tax) >> (AG00:sum)\n",
      "{reads}->{taxable-annable} || (7200:117-reads) >> (BA00:taxable-annable)\n",
      "{annable}->{ann} || (BA00:taxable-annable) >> (BC00:ann)\n",
      "{taxable}->{tax} || (BA00:taxable-annable) >> (BE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (BA00:taxable-annable),(BC00:ann),(BE00:tax) >> (BG00:sum)\n",
      "{reads}->{taxable-annable} || (8200:118-reads) >> (CA00:taxable-annable)\n",
      "{annable}->{ann} || (CA00:taxable-annable) >> (CC00:ann)\n",
      "{taxable}->{tax} || (CA00:taxable-annable) >> (CE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (CA00:taxable-annable),(CC00:ann),(CE00:tax) >> (CG00:sum)\n",
      "{reads}->{taxable-annable} || (9200:119-reads) >> (DA00:taxable-annable)\n",
      "{annable}->{ann} || (DA00:taxable-annable) >> (DC00:ann)\n",
      "{taxable}->{tax} || (DA00:taxable-annable) >> (DE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (DA00:taxable-annable),(DC00:ann),(DE00:tax) >> (DG00:sum)\n",
      "{reads}->{taxable-annable} || (A200:120-reads) >> (EA00:taxable-annable)\n",
      "{annable}->{ann} || (EA00:taxable-annable) >> (EC00:ann)\n",
      "{taxable}->{tax} || (EA00:taxable-annable) >> (EE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (EA00:taxable-annable),(EC00:ann),(EE00:tax) >> (EG00:sum)\n",
      "{reads}->{taxable-annable} || (B200:121-reads) >> (FA00:taxable-annable)\n",
      "{annable}->{ann} || (FA00:taxable-annable) >> (FC00:ann)\n",
      "{taxable}->{tax} || (FA00:taxable-annable) >> (FE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (FA00:taxable-annable),(FC00:ann),(FE00:tax) >> (FG00:sum)\n",
      "{reads}->{taxable-annable} || (C200:122-reads) >> (GA00:taxable-annable)\n",
      "{annable}->{ann} || (GA00:taxable-annable) >> (GC00:ann)\n",
      "{taxable}->{tax} || (GA00:taxable-annable) >> (GE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (GA00:taxable-annable),(GC00:ann),(GE00:tax) >> (GG00:sum)\n",
      "{reads}->{taxable-annable} || (D200:123-reads) >> (HA00:taxable-annable)\n",
      "{annable}->{ann} || (HA00:taxable-annable) >> (HC00:ann)\n",
      "{taxable}->{tax} || (HA00:taxable-annable) >> (HE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (HA00:taxable-annable),(HC00:ann),(HE00:tax) >> (HG00:sum)\n",
      "{reads}->{taxable-annable} || (E200:124-reads) >> (IA00:taxable-annable)\n",
      "{annable}->{ann} || (IA00:taxable-annable) >> (IC00:ann)\n",
      "{taxable}->{tax} || (IA00:taxable-annable) >> (IE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (IA00:taxable-annable),(IC00:ann),(IE00:tax) >> (IG00:sum)\n",
      "{reads}->{taxable-annable} || (F200:reads-125) >> (JA00:taxable-annable)\n",
      "{annable}->{ann} || (JA00:taxable-annable) >> (JC00:ann)\n",
      "{taxable}->{tax} || (JA00:taxable-annable) >> (JE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (JA00:taxable-annable),(JC00:ann),(JE00:tax) >> (JG00:sum)\n",
      "{reads}->{taxable-annable} || (G200:126-reads) >> (KA00:taxable-annable)\n",
      "{annable}->{ann} || (KA00:taxable-annable) >> (KC00:ann)\n",
      "{taxable}->{tax} || (KA00:taxable-annable) >> (KE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (KA00:taxable-annable),(KC00:ann),(KE00:tax) >> (KG00:sum)\n",
      "{reads}->{taxable-annable} || (H200:127-reads) >> (LA00:taxable-annable)\n",
      "{annable}->{ann} || (LA00:taxable-annable) >> (LC00:ann)\n",
      "{taxable}->{tax} || (LA00:taxable-annable) >> (LE00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (LA00:taxable-annable),(LC00:ann),(LE00:tax) >> (LG00:sum)\n",
      "{reads}->{taxable-annable} || (I200:128-reads) >> (MA00:taxable-annable)\n",
      "{annable}->{ann} || (MA00:taxable-annable) >> (MC00:ann)\n",
      "{taxable}->{tax} || (MA00:taxable-annable) >> (ME00:tax)\n",
      "{taxable-annable},{ann},{tax}->{sum} || (MA00:taxable-annable),(MC00:ann),(ME00:tax) >> (MG00:sum)\n",
      "{reads-1},{sum},{2-reads},{sum},{reads-3},{sum},{4-reads},{sum},{5-reads},{sum},{reads-6},{sum},{7-reads},{sum},{8-reads},{sum},{9-reads},{sum},{10-reads},{sum},{11-reads},{sum},{12-reads},{sum},{13-reads},{sum},{reads-14},{sum},{15-reads},{sum},{reads-16},{sum},{17-reads},{sum},{18-reads},{sum},{19-reads},{sum},{20-reads},{sum},{21-reads},{sum},{22-reads},{sum},{reads-23},{sum},{24-reads},{sum},{25-reads},{sum},{26-reads},{sum},{27-reads},{sum},{28-reads},{sum},{29-reads},{sum},{30-reads},{sum},{31-reads},{sum},{reads-32},{sum},{33-reads},{sum},{reads-34},{sum},{35-reads},{sum},{36-reads},{sum},{37-reads},{sum},{38-reads},{sum},{39-reads},{sum},{40-reads},{sum},{41-reads},{sum},{42-reads},{sum},{43-reads},{sum},{44-reads},{sum},{45-reads},{sum},{46-reads},{sum},{reads-47},{sum},{48-reads},{sum},{49-reads},{sum},{50-reads},{sum},{51-reads},{sum},{52-reads},{sum},{53-reads},{sum},{reads-54},{sum},{55-reads},{sum},{56-reads},{sum},{57-reads},{sum},{58-reads},{sum},{59-reads},{sum},{60-reads},{sum},{61-reads},{sum},{62-reads},{sum},{63-reads},{sum},{64-reads},{sum},{65-reads},{sum},{66-reads},{sum},{reads-67},{sum},{68-reads},{sum},{69-reads},{sum},{70-reads},{sum},{71-reads},{sum},{72-reads},{sum},{73-reads},{sum},{74-reads},{sum},{75-reads},{sum},{76-reads},{sum},{77-reads},{sum},{78-reads},{sum},{79-reads},{sum},{80-reads},{sum},{81-reads},{sum},{82-reads},{sum},{83-reads},{sum},{84-reads},{sum},{85-reads},{sum},{reads-86},{sum},{87-reads},{sum},{88-reads},{sum},{89-reads},{sum},{90-reads},{sum},{91-reads},{sum},{92-reads},{sum},{93-reads},{sum},{94-reads},{sum},{95-reads},{sum},{96-reads},{sum},{reads-97},{sum},{98-reads},{sum},{99-reads},{sum},{100-reads},{sum},{101-reads},{sum},{102-reads},{sum},{reads-103},{sum},{104-reads},{sum},{105-reads},{sum},{106-reads},{sum},{107-reads},{sum},{108-reads},{sum},{109-reads},{sum},{110-reads},{sum},{reads-111},{sum},{reads-112},{sum},{113-reads},{sum},{114-reads},{sum},{reads-115},{sum},{reads-116},{sum},{117-reads},{sum},{118-reads},{sum},{119-reads},{sum},{120-reads},{sum},{121-reads},{sum},{122-reads},{sum},{123-reads},{sum},{124-reads},{sum},{reads-125},{sum},{126-reads},{sum},{127-reads},{sum},{128-reads},{sum}-> || (J000:reads-1),(NE00:sum),(K000:2-reads),(OE00:sum),(L000:reads-3),(PE00:sum),(M000:4-reads),(QE00:sum),(N000:5-reads),(RE00:sum),(O000:reads-6),(SE00:sum),(P000:7-reads),(TE00:sum),(Q000:8-reads),(UE00:sum),(R000:9-reads),(VE00:sum),(S000:10-reads),(WE00:sum),(T000:11-reads),(XE00:sum),(U000:12-reads),(YE00:sum),(V000:13-reads),(ZE00:sum),(W000:reads-14),(aE00:sum),(X000:15-reads),(bE00:sum),(Y000:reads-16),(cE00:sum),(Z000:17-reads),(dE00:sum),(a000:18-reads),(eE00:sum),(b000:19-reads),(fE00:sum),(c000:20-reads),(gE00:sum),(d000:21-reads),(hE00:sum),(e000:22-reads),(iE00:sum),(f000:reads-23),(jE00:sum),(g000:24-reads),(kE00:sum),(h000:25-reads),(lE00:sum),(i000:26-reads),(mE00:sum),(j000:27-reads),(nE00:sum),(k000:28-reads),(oE00:sum),(l000:29-reads),(pE00:sum),(m000:30-reads),(qE00:sum),(n000:31-reads),(rE00:sum),(o000:reads-32),(sE00:sum),(p000:33-reads),(tE00:sum),(q000:reads-34),(uE00:sum),(r000:35-reads),(vE00:sum),(s000:36-reads),(wE00:sum),(t000:37-reads),(xE00:sum),(u000:38-reads),(yE00:sum),(v000:39-reads),(zE00:sum),(w000:40-reads),(+E00:sum),(x000:41-reads),(=E00:sum),(y000:42-reads),(0F00:sum),(z000:43-reads),(1F00:sum),(+000:44-reads),(2F00:sum),(=000:45-reads),(3F00:sum),(0100:46-reads),(4F00:sum),(1100:reads-47),(5F00:sum),(2100:48-reads),(6F00:sum),(3100:49-reads),(7F00:sum),(4100:50-reads),(8F00:sum),(5100:51-reads),(9F00:sum),(6100:52-reads),(AF00:sum),(7100:53-reads),(BF00:sum),(8100:reads-54),(CF00:sum),(9100:55-reads),(DF00:sum),(A100:56-reads),(EF00:sum),(B100:57-reads),(FF00:sum),(C100:58-reads),(GF00:sum),(D100:59-reads),(HF00:sum),(E100:60-reads),(IF00:sum),(F100:61-reads),(JF00:sum),(G100:62-reads),(KF00:sum),(H100:63-reads),(LF00:sum),(I100:64-reads),(MF00:sum),(J100:65-reads),(NF00:sum),(K100:66-reads),(OF00:sum),(L100:reads-67),(PF00:sum),(M100:68-reads),(QF00:sum),(N100:69-reads),(RF00:sum),(O100:70-reads),(SF00:sum),(P100:71-reads),(TF00:sum),(Q100:72-reads),(UF00:sum),(R100:73-reads),(VF00:sum),(S100:74-reads),(WF00:sum),(T100:75-reads),(XF00:sum),(U100:76-reads),(YF00:sum),(V100:77-reads),(ZF00:sum),(W100:78-reads),(aF00:sum),(X100:79-reads),(bF00:sum),(Y100:80-reads),(cF00:sum),(Z100:81-reads),(dF00:sum),(a100:82-reads),(eF00:sum),(b100:83-reads),(fF00:sum),(c100:84-reads),(gF00:sum),(d100:85-reads),(hF00:sum),(e100:reads-86),(iF00:sum),(f100:87-reads),(jF00:sum),(g100:88-reads),(kF00:sum),(h100:89-reads),(lF00:sum),(i100:90-reads),(mF00:sum),(j100:91-reads),(nF00:sum),(k100:92-reads),(oF00:sum),(l100:93-reads),(pF00:sum),(m100:94-reads),(qF00:sum),(n100:95-reads),(rF00:sum),(o100:96-reads),(sF00:sum),(p100:reads-97),(tF00:sum),(q100:98-reads),(uF00:sum),(r100:99-reads),(vF00:sum),(s100:100-reads),(wF00:sum),(t100:101-reads),(xF00:sum),(u100:102-reads),(yF00:sum),(v100:reads-103),(zF00:sum),(w100:104-reads),(+F00:sum),(x100:105-reads),(=F00:sum),(y100:106-reads),(0G00:sum),(z100:107-reads),(1G00:sum),(+100:108-reads),(2G00:sum),(=100:109-reads),(3G00:sum),(0200:110-reads),(4G00:sum),(1200:reads-111),(5G00:sum),(2200:reads-112),(6G00:sum),(3200:113-reads),(7G00:sum),(4200:114-reads),(8G00:sum),(5200:reads-115),(9G00:sum),(6200:reads-116),(AG00:sum),(7200:117-reads),(BG00:sum),(8200:118-reads),(CG00:sum),(9200:119-reads),(DG00:sum),(A200:120-reads),(EG00:sum),(B200:121-reads),(FG00:sum),(C200:122-reads),(GG00:sum),(D200:123-reads),(HG00:sum),(E200:124-reads),(IG00:sum),(F200:reads-125),(JG00:sum),(G200:126-reads),(KG00:sum),(H200:127-reads),(LG00:sum),(I200:128-reads),(MG00:sum) >> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(solutions))\n",
    "for i, res in enumerate(solutions):\n",
    "    print(res.steps)\n",
    "    for a in res.dependency_plan:\n",
    "        print(a)\n",
    "    print(res.application)\n",
    "    print()\n",
    "    if i > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        # todo: deque[Dependency] = deque()\n",
    "        # loop_marker: Dependency|None = None\n",
    "        # # check here for lineage constraints\n",
    "        # while len(todo)>0:\n",
    "        #     req = todo.popleft()\n",
    "        #     if req == loop_marker:\n",
    "        #         if DEBUG: debug_print(f\"<<< FAIL\", s.target, req)\n",
    "        #         return\n",
    "\n",
    "        #     req_p = {}\n",
    "        #     for proto, e in s.required_parents.items():\n",
    "        #         if req.IsA(proto): continue\n",
    "        #         # if already satisfied by other req and lineage not specified for this req: skip\n",
    "        #         # if e in satisfied_lineages and all(not pproto.IsA(proto) for pproto in req.parents): continue\n",
    "        #         req_p[proto] = e\n",
    "        #     if any(p not in deps for p in req.parents):\n",
    "        #         res = None # requirements of node not satisfied yet\n",
    "        #     else:\n",
    "        #         rreq = {p:deps[p] for p in req.parents}\n",
    "        #         res = _solve_dep(State(_have, req, req_p|rreq, s.steps+1, s.depth+1))\n",
    "        #         # if res is None:\n",
    "\n",
    "\n",
    "        #     if res is None:\n",
    "        #         todo.append(req)\n",
    "        #         if loop_marker is None: loop_marker = req\n",
    "        #         continue\n",
    "        #     loop_marker = None\n",
    "\n",
    "        #     if res.endpoint in plans: continue # for duplicate reqs...\n",
    "        #     plans[res.endpoint] = res.plan\n",
    "        #     deps[req] = res.endpoint\n",
    "        #     steps += res.steps\n",
    "        #     for appl in res.plan:\n",
    "        #         _have |= appl.produced\n",
    "        #     satisfied_lineages[res.endpoint] = req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # reqs = deque()\n",
    "    # for r in target.requires:\n",
    "    #     reqs.append(r)\n",
    "\n",
    "    # todo: deque[State] = deque()\n",
    "    # todo.append(State(set(given), [], target, [], reqs))\n",
    "    # steps, MAX_S = 0, 5\n",
    "    # while len(todo)>0:\n",
    "    #     steps += 1\n",
    "    #     if steps>MAX_S: \n",
    "    #         print(\"step limit\")\n",
    "    #         return\n",
    "\n",
    "    #     s = todo.popleft()\n",
    "        \n",
    "    #     print(s.target)\n",
    "    #     # print(s.have)\n",
    "    #     for x in s.plan:\n",
    "    #         print(x)\n",
    "    #     print()\n",
    "\n",
    "    #     if len(s.requirements) == 0: return s\n",
    "\n",
    "    #     if isinstance(s.target, Dependency):\n",
    "    #         for e in s.have:\n",
    "    #             if not e.IsA(s.target): continue\n",
    "    #             todo.append(State(\n",
    "    #                 s.have,\n",
    "    #                 [],\n",
    "    #                 s.requirements.popleft(),\n",
    "    #                 s.all_plans+[s.plan+[e]],\n",
    "    #                 s.requirements,\n",
    "    #             ))\n",
    "            \n",
    "    #         for tr in _get_producers_of(s.target):\n",
    "    #             todo.append(State(\n",
    "    #                 s.have,\n",
    "    #                 s.plan + [tr],\n",
    "    #                 tr,\n",
    "    #                 s.all_plans,\n",
    "    #                 s.requirements,\n",
    "    #             ))\n",
    "    #     else:\n",
    "    #         for req in target.requires:\n",
    "    #             if len(req.parents)>0:\n",
    "    #                 continue # figure out later\n",
    "    #             todo.append(State(\n",
    "    #                 s.have,\n",
    "    #                 s.plan + [req],\n",
    "    #                 req,\n",
    "    #                 s.all_plans,\n",
    "    #                 s.requirements\n",
    "    #             ))\n",
    "\n",
    "    # # @dataclass\n",
    "    # # class State:\n",
    "    # #     target: Transform\n",
    "    # #     have: set[Endpoint]\n",
    "    # #     constraints: dict[Dependency, Endpoint]\n",
    "    # #     plan: list[Transform]\n",
    "\n",
    "    # # todo: deque[State] = deque()\n",
    "    # # todo.append(State(target, set(given), {}, []))\n",
    "    # # while len(todo)>0:\n",
    "    # #     s = todo.popleft()\n",
    "    # #     cons = s.constraints\n",
    "        \n",
    "    # #     for tr in transforms:\n",
    "    # #         fwds = tr.Valids(tr.Possibilities(s.have, cons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _apply_one(have: set[Endpoint], tr: Transform, sources: set[Endpoint]):\n",
    "#         match = next(tr.NextValid(tr.Possibilities(have, sources)), None)\n",
    "#         if match is not None:\n",
    "#             return tr.Apply(match)\n",
    "    \n",
    "#     # res = _map()\n",
    "#     # if not res.success: return res\n",
    "\n",
    "\n",
    "        # for e in given if len(sources)==0 else sources:\n",
    "        #     if not e.IsA(target): continue\n",
    "        #     return MapResult([], e)\n",
    "\n",
    "        # if \"sum\" in target.properties and any(\"2\" in s.properties for s in sources):\n",
    "        # if \"sum\" in target.properties:\n",
    "        #     x = 1\n",
    "        #     print(target, sources)\n",
    "\n",
    "        # todo: deque[MapState] = deque()\n",
    "        # todo.append(MapState(given, [], {t for t in transforms}))\n",
    "\n",
    "        # while len(todo)>0:\n",
    "        #     s = todo.popleft()\n",
    "        #     for tr in curr.remaining_transforms:\n",
    "        #         next_step = _apply_one(curr.have, tr)\n",
    "        #         if next_step is None: continue\n",
    "        #             # next_step = _apply_one(curr.have, tr)\n",
    "        #             # if next_step is None: continue\n",
    "        #         for e in next_step.produced:\n",
    "        #             if not e.IsA(target): continue\n",
    "        #             return MapResult(curr.plan+[next_step], e)\n",
    "\n",
    "        #         todo.append(MapState(\n",
    "        #             curr.have | next_step.produced,\n",
    "        #             curr.plan + [next_step],\n",
    "        #             curr.remaining_transforms - {tr}\n",
    "        #         ))\n",
    "\n",
    "#     def _solve_tr(given: set[Endpoint], target: Transform):\n",
    "#         have = set(given)\n",
    "#         plan: list[Application] = []\n",
    "#         dep2ep: dict[Node, Endpoint] = {} # really Dep -> Ep\n",
    "#         dep_parent_sets: dict[Dependency, set[Endpoint]] = {}\n",
    "#         todo: deque[Dependency] = deque()\n",
    "#         for r in target.requires: todo.append(r)\n",
    "#         loop_landmark = None\n",
    "#         while len(todo)>0:\n",
    "#             curr = todo.popleft()\n",
    "#             def _skip():\n",
    "#                 nonlocal loop_landmark\n",
    "#                 if loop_landmark is None: loop_landmark = curr\n",
    "#                 todo.append(curr)\n",
    "\n",
    "#             if loop_landmark is not None and curr == loop_landmark:\n",
    "#                 return Result([], f\"can't make {curr}\", info=have)\n",
    "#             # if any parent not generated, skip for now\n",
    "#             if any(p not in dep2ep for p in curr.parents): _skip(); continue\n",
    "\n",
    "#             if curr not in dep_parent_sets:\n",
    "#                 parents = {dep2ep[p] for p in curr.parents}\n",
    "#                 dep_parent_sets[curr] = parents\n",
    "#             # print(f\"---\",dep_parent_sets)\n",
    "\n",
    "#             # if \"sum\" in curr.properties:\n",
    "#             #     print(curr, dep_parent_sets[curr])\n",
    "#             sol = _solve_dep(have, curr, dep_parent_sets[curr])\n",
    "#             if sol is None: _skip(); continue\n",
    "#             loop_landmark = None\n",
    "\n",
    "#             # print(curr, dep_parent_sets[curr], loop_landmark)\n",
    "#             # print(\">\")\n",
    "#             # print(have)\n",
    "#             # print(todo)\n",
    "#             # print(sol)\n",
    "#             # for a in sol.plan:\n",
    "#             #     print(a)\n",
    "#             # print()\n",
    "\n",
    "#             dep2ep[curr] = sol.endpoint\n",
    "#             for a in sol.plan:\n",
    "#                 have |= a.produced\n",
    "#             plan += sol.plan\n",
    "\n",
    "#     return _solve_tr(set(given), target, set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # sol = res.solution\n",
    "    # last_l = 0\n",
    "    # while last_l != len(sol):\n",
    "    #     last_l = len(sol)\n",
    "    #     used = set()\n",
    "    #     for a in sol:\n",
    "    #         used |= a.used\n",
    "    #     sol = [a for a in sol if a.transform==target or any(e in used for e in a.produced)]\n",
    "    # res.solution = sol    \n",
    "\n",
    "# @dataclass\n",
    "    # class State:\n",
    "    #     have: set[Endpoint]\n",
    "    #     plan: list[Application]\n",
    "    #     usage_sigs: set[str]\n",
    "\n",
    "    # def _local_solve(have: set[Endpoint], target: Dependency):\n",
    "    #     todo: deque[State] = deque()\n",
    "    #     todo.append(State(have, [], set()))\n",
    "    #     MAX_S = 10_000\n",
    "    #     steps = 0\n",
    "    #     # _last_depth = 0\n",
    "    #     while len(todo) > 0:\n",
    "    #         steps += 1\n",
    "    #         if steps>MAX_S: return Result([], \"step limit\", steps, info=todo)\n",
    "    #         curr = todo.popleft()    \n",
    "\n",
    "# @dataclass\n",
    "    # class SubGoal:\n",
    "    #     target: Dependency\n",
    "\n",
    "    # have = set(given)\n",
    "    # dep2endpoint: dict[Dependency, Endpoint] = {}\n",
    "    # todo: deque[SubGoal] = deque()\n",
    "    # for d in target.requires: todo.appendleft(SubGoal(d))\n",
    "    # while len(todo)>0:\n",
    "    #     subgoal = todo.pop()\n",
    "    #     sources: list[Endpoint] = []\n",
    "    #     ok = True\n",
    "    #     for p in subgoal.target.parents:\n",
    "    #         if p not in dep2endpoint:\n",
    "    #             todo.appendleft(subgoal)\n",
    "    #             ok = False; break\n",
    "    #         sources.append(dep2endpoint[p])\n",
    "    #     if not ok: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Apply(self, have: Iterable[Endpoint], use_signatures: set[str]) -> Iterable[Application]:\n",
    "#         matches = self.Possibilities(have)\n",
    "#         if len(matches) == 0: return []\n",
    "\n",
    "#         # can reduce exponential trial here by enforcning the input groups first\n",
    "#         def _possible_configs(i: int, choosen: list[Endpoint]) -> list[list[Endpoint]]:\n",
    "#             if i >= len(self.requires): return [choosen]\n",
    "#             candidates = matches[i]\n",
    "#             parents = self._input_group_map.get(i, [])\n",
    "#             # print(parents, candidates, choosen)\n",
    "#             if len(parents) > 0:\n",
    "#                 for prototype in parents:\n",
    "#                     # parent must be in choosen, since it must have been added\n",
    "#                     # as a req. before being used as a parent\n",
    "#                     parent: None|Endpoint = None\n",
    "#                     for p in choosen:\n",
    "#                         if p.IsA(prototype): parent = p; break\n",
    "#                     if parent is None: return []\n",
    "#                     candidates = [c for c in candidates if parent in c.parents]\n",
    "#             configs = []\n",
    "#             for c in candidates:\n",
    "#                 configs += _possible_configs(i+1, choosen+[c])\n",
    "#             return configs\n",
    "#         configs = _possible_configs(0, [])\n",
    "\n",
    "#         def _same(a: Endpoint, b: Endpoint):\n",
    "#             return a.properties.issubset(b.properties) and b.properties.issubset(a.properties) \\\n",
    "#                 and a.parents.issubset(b.parents) and b.parents.issubset(a.parents)\n",
    "\n",
    "#         for input_set in configs:\n",
    "#             sis = set(input_set)\n",
    "#             sig = self._sig(input_set)\n",
    "#             if sig in use_signatures: continue\n",
    "#             _parents = sis|{p for g in [e.parents for e in input_set] for p in g}\n",
    "#             produced = {\n",
    "#                 Endpoint(\n",
    "#                     namespace=self._ns,\n",
    "#                     properties=out.properties,\n",
    "#                     parents=_parents\n",
    "#                 )\n",
    "#             for out in self.produces}\n",
    "#             # if all(_same(e, p) for e in have for p in produced):\n",
    "#             #     continue\n",
    "#             #     print(have)\n",
    "#             #     print(produced)\n",
    "#             #     print()\n",
    "#             yield Application(self, sis, produced, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # if len(target.parents) == 0:\n",
    "        #     sol = _map_to(have, target)\n",
    "        #     if sol is None: return Result([], \"x\")\n",
    "        #     return Result(sol, success=True)\n",
    "        # else:\n",
    "        #     for p in target.parents:\n",
    "        #         _p: Any = p\n",
    "        #         res = _map_to(have, target, _p)\n",
    "\n",
    "        #         print(\">\",res)\n",
    "        #         have |= {e for g in [a.produced for a in res.solution] for e in g}\n",
    "        #         if not res.success: return res\n",
    "\n",
    "    # have = set(given)\n",
    "    # for d in target.requires:\n",
    "    #     _solve(have, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def Signature(self):\n",
    "    #     cache = self.namespace.node_signatures\n",
    "    #     if self.key not in cache:\n",
    "    #         props = \",\".join(sorted(self.properties))\n",
    "    #         parents = \",\".join(sorted([p.Signature() for p in self.parents]))\n",
    "    #         sig = f\"{props}-{parents}\"\n",
    "    #         cache[self.hash] = sig\n",
    "    #     return cache[self.hash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # def _solve():\n",
    "    #     todo: deque[State] = deque()\n",
    "    #     todo.append(State(set(given), [], set()))\n",
    "    #     MAX_S = 100_000\n",
    "    #     steps = 0\n",
    "    #     # _last_depth = 0\n",
    "    #     while len(todo) > 0:\n",
    "    #         steps += 1\n",
    "    #         if steps>MAX_S: return Result([], \"step limit\", todo, steps)\n",
    "    #         # curr = todo.popleft()\n",
    "    #         curr = todo.pop()\n",
    "\n",
    "    #         final_appl = _check_done(curr)\n",
    "    #         if final_appl is not None: return Result(curr.plan+[final_appl], steps=steps)\n",
    "\n",
    "    #         # _depth = len(curr.plan)\n",
    "    #         # if _depth != _last_depth:\n",
    "    #         #     todo = _deduplicate_states(curr, todo)\n",
    "    #         #     _last_depth = _depth\n",
    "\n",
    "    #         next_states = _get_next_states(curr)\n",
    "    #         for n in next_states:\n",
    "    #             todo.append(n)\n",
    "\n",
    "    #     return Result([], \"no sol\", steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # plans: dict[Endpoint, Path] = {}\n",
    "    # def _path_to(have: Iterable[Endpoint], target: Dependency) -> Path|None:\n",
    "    #     if any(e.IsA(target) for e in have): return Path([])\n",
    "    #     if target in plans: return plans[target]\n",
    "\n",
    "    #     # DFS back from e\n",
    "    #     for tr in transforms:\n",
    "    #         if not any(d.IsA(target) for d in tr.produces): continue \n",
    "    #         for req in tr.requires:\n",
    "    #             path_result = _path_to(have, req)\n",
    "    #             if path_result is None: continue\n",
    "    #             path_result.plan.append(tr)\n",
    "    #             return path_result\n",
    "    # x = [\n",
    "    # # @dataclass\n",
    "    # # class State:\n",
    "    # #     have: Iterable[Endpoint]\n",
    "    # #     targets: Iterable[Dependency]\n",
    "    # #     plan: list[Transform]\n",
    "\n",
    "    # # todo: deque[State] = deque(maxlen=64)\n",
    "    # # todo.append(State([], [t for t in target.requires], []))\n",
    "    # # while len(todo)>0:\n",
    "    # #     _s = todo.popleft()\n",
    "    # #     t = next(iter(_s.targets))\n",
    "    # #     plan = \n",
    "    # ]\n",
    "\n",
    "    # usage_signatures: dict[Transform, set[str]] = {t:set() for t in transforms}\n",
    "    # def _solve(have: list[Endpoint], target: Transform, sigs: dict) -> list[Application]|None:\n",
    "    #     possibilities = target.Apply(have, sigs[target])\n",
    "    #     if len(possibilities)>0: return possibilities[0:1]\n",
    "\n",
    "    #     for t in target.requires:\n",
    "    #         path = _path_to(have, t)\n",
    "    #         if path is None: return None\n",
    "    #         fist_tr = path.plan[0]\n",
    "    #         poss = fist_tr.Apply(have, sigs[fist_tr])\n",
    "    #         if poss\n",
    "                        \n",
    "            \n",
    "\n",
    "\n",
    "    # _solve(list(given), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Solve(given: Iterable[Endpoint], target: Transform, transforms: Iterable[Transform]):\n",
    "#     @dataclass\n",
    "#     class State:\n",
    "#         have: list[Endpoint]\n",
    "#         usage_signatures: dict[int, set[str]]\n",
    "#         plan: list[Application]\n",
    "\n",
    "#     transforms = list(transforms)\n",
    "    \n",
    "#     def _done(state: State):\n",
    "#         appl = target.Apply(state.have, set())\n",
    "#         return appl \n",
    "\n",
    "#     def _solve() -> Result:\n",
    "#         MAXS = 10_000\n",
    "#         todo: deque[State] = deque([State(\n",
    "#             have = list(given),\n",
    "#             plan = [],\n",
    "#             usage_signatures={},\n",
    "#         )], maxlen=MAXS)\n",
    "        \n",
    "\n",
    "#         def _deduplicate_states(current: State):\n",
    "#             def _get_sig(s: State):\n",
    "#                 haves_sig = '|'.join([e.Signature() for e in s.have])\n",
    "#                 return haves_sig\n",
    "#             seen = {_get_sig(current)}\n",
    "#             new_todo: deque[State] = deque([], MAXS)\n",
    "#             for s in todo:\n",
    "#                 if _get_sig(s) in seen: continue\n",
    "#                 new_todo.append(s)\n",
    "\n",
    "#             if len(todo) != len(new_todo):\n",
    "#                 for s in todo:\n",
    "#                     print(s)\n",
    "#                 print(\"-\")\n",
    "#                 for s in new_todo:\n",
    "#                     print(s)\n",
    "#                 print()\n",
    "#             return new_todo\n",
    "\n",
    "#         _steps = 0\n",
    "#         _empty = set()\n",
    "#         _last_depth = 0\n",
    "#         while len(todo)>0:\n",
    "#             _steps += 1\n",
    "#             if _steps > MAXS: return Result([], f\"step limit exceeded\", steps=_steps)\n",
    "#             _s = todo.popleft()\n",
    "\n",
    "#             _target_applications = target.Apply(_s.have, _empty)\n",
    "#             if len(_target_applications)>0:\n",
    "#                 return Result(solution=_s.plan+[_target_applications[0]], steps=_steps)\n",
    "\n",
    "#             _depth = len(_s.plan)\n",
    "#             if _depth != _last_depth:\n",
    "#                 todo = _deduplicate_states(_s)\n",
    "#                 _last_depth = _depth\n",
    "\n",
    "#             if _done(_s): return Result(_s.plan, steps=_steps)\n",
    "#             for tr in transforms:\n",
    "#                 possibilities = tr.Apply(_s.have, _s.usage_signatures.get(tr.hash, set()))\n",
    "#                 # for app in possibilities:\n",
    "#                 #     usage_sigs = _s.usage_signatures.copy()\n",
    "#                 #     usage_sigs[tr.hash] = usage_sigs.get(tr.hash, set())|{app.signature}\n",
    "#                 #     todo.append(State(\n",
    "#                 #         have = _s.have+app.produced,\n",
    "#                 #         plan = _s.plan+[app],\n",
    "#                 #         usage_signatures = usage_sigs,\n",
    "#                 #     ))\n",
    "\n",
    "#                 if len(possibilities) == 0: continue\n",
    "#                 usage_sigs = _s.usage_signatures.copy()\n",
    "#                 new_have = _s.have.copy()\n",
    "#                 for app in possibilities:\n",
    "#                     usage_sigs[tr.hash] = usage_sigs.get(tr.hash, set())|{app.signature}\n",
    "#                     new_have += app.produced\n",
    "#                 todo.append(State(\n",
    "#                     have = new_have,\n",
    "#                     plan = _s.plan+possibilities,\n",
    "#                     usage_signatures=usage_sigs\n",
    "#                 ))\n",
    "#         return Result([], f\"ran out of things to try\", steps = _steps)\n",
    "    \n",
    "#     res = _solve()\n",
    "#     sol = res.solution\n",
    "#     last_l = 0\n",
    "#     while last_l != len(sol):\n",
    "#         last_l = len(sol)\n",
    "#         used = set()\n",
    "#         for a in sol:\n",
    "#             used |= a.used\n",
    "#         sol = [a for a in sol if a.transform==target or any(e in used for e in a.produced)]\n",
    "#     res.solution = sol\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import annotations\n",
    "# import os, sys\n",
    "# import asyncio\n",
    "# from typing import Iterable, Callable, Any\n",
    "# from pathlib import Path\n",
    "\n",
    "# from limes_x.solver import DependencySolver, Plan, Dependency\n",
    "# from limes_x.persistence import ProjectState, Instance\n",
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# mpath = Path(\"./test_solver/\")\n",
    "# modules = [\n",
    "#     ComputeModule(mpath.joinpath(d)) for d in os.listdir(mpath)\n",
    "# ]\n",
    "# print(modules)\n",
    "\n",
    "# given = [\n",
    "#     (\"a\", \"./test_data/a1\"),\n",
    "#     (\"a\", \"./test_data/a2\"),\n",
    "#     (\"b\", \"./test_data/b1\"),\n",
    "# ]\n",
    "\n",
    "# prj_path = \"./cache/man_test01/\"\n",
    "# state = ProjectState(prj_path, on_exist=\"overwrite\")\n",
    "# for dtype, val in given:\n",
    "#     state.RegisterInstance(Instance.Str(dtype, val))\n",
    "# for m in modules:\n",
    "#     state.RegisterInstance(Instance.ComputeModule(m))\n",
    "\n",
    "# deps = []\n",
    "# for k, inst in state._instances.items():\n",
    "#     if not inst.IsPyType(ComputeModule): continue\n",
    "#     deps.append(Dependency(inst.val.requires, inst.val.produces, k))\n",
    "\n",
    "# solver = DependencySolver(deps)\n",
    "# # plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan = solver.Solve({\"a\"}, {\"branched\"})\n",
    "# assert plan != False\n",
    "# [state.GetInstance(m.ref_key) for m in plan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_dependency(module: ComputeModule):\n",
    "#     return Dependency(module.requires, module.produces, module)\n",
    "\n",
    "# modules = Path(\"./test_solver/\")\n",
    "# solver = Plan([\n",
    "#     make_dependency(ComputeModule(p))\n",
    "# for p in [\n",
    "#     modules.joinpath(p) for p in os.listdir(modules)\n",
    "# ]])\n",
    "# plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# a = ComputeModule(\"./test_modules/copy/\")\n",
    "# b = ComputeModule(\"./test_modules/copy2/\")\n",
    "\n",
    "# a.requires, b.requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = ProjectState(\"./cache/test_persist\")\n",
    "# ok = Instance(\"asdf\", 1)\n",
    "# ov = Instance(\"s\", 2)\n",
    "# state._lineage[ok] = [ov]\n",
    "# state.Save()\n",
    "\n",
    "# s2 = ProjectState.Load(\"./cache/test_persist\")\n",
    "# for k, v in s2._lineage.items():\n",
    "#     _te = k.type, k.value, ok == k, [(i.type, i.value, i == ov) for i in v]\n",
    "#     print(_te)\n",
    "\n",
    "# ok._id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
