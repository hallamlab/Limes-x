{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'input size [100], states checked [304]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         9482072 function calls (9365620 primitive calls) in 2.473 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    42974    0.363    0.000    0.479    0.000 3144352985.py:143(<listcomp>)\n",
      "        1    0.316    0.316    2.457    2.457 3144352985.py:182(Solve)\n",
      "    27725    0.196    0.000    0.276    0.000 fromnumeric.py:69(_wrapreduction)\n",
      "  1120820    0.182    0.000    0.235    0.000 3144352985.py:59(IsA)\n",
      "  1394800    0.163    0.000    0.313    0.000 3144352985.py:226(<genexpr>)\n",
      "   697404    0.152    0.000    0.465    0.000 {built-in method builtins.any}\n",
      "  2502822    0.126    0.000    0.126    0.000 3144352985.py:23(__hash__)\n",
      "117355/907    0.113    0.000    0.613    0.001 3144352985.py:130(_possible_configs)\n",
      "      909    0.091    0.000    1.509    0.002 3144352985.py:122(Apply)\n",
      "   366300    0.080    0.000    0.112    0.000 3144352985.py:26(__eq__)\n",
      "    27725    0.059    0.000    0.388    0.000 {method 'randint' of 'numpy.random.mtrand.RandomState' objects}\n",
      "  1120820    0.053    0.000    0.053    0.000 {method 'issubset' of 'set' objects}\n",
      "     1514    0.048    0.000    0.121    0.000 3144352985.py:125(<listcomp>)\n",
      "    27725    0.045    0.000    0.486    0.000 utils.py:24(GenerateUID)\n",
      "    27725    0.042    0.000    0.042    0.000 utils.py:28(<listcomp>)\n",
      "    27725    0.038    0.000    0.038    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     7400    0.035    0.000    0.147    0.000 {method 'remove' of 'list' objects}\n",
      "    27725    0.032    0.000    0.550    0.000 3144352985.py:18(__init__)\n",
      "   101212    0.031    0.000    0.045    0.000 {method 'join' of 'str' objects}\n",
      "    27725    0.027    0.000    0.303    0.000 fromnumeric.py:2955(prod)\n",
      "   394056    0.026    0.000    0.026    0.000 {built-in method builtins.getattr}\n",
      "    73474    0.022    0.000    0.062    0.000 3144352985.py:119(_sig)\n",
      "    27725    0.021    0.000    0.021    0.000 fromnumeric.py:70(<dictcomp>)\n",
      "        1    0.021    0.021    2.478    2.478 <string>:1(<module>)\n",
      "    27725    0.018    0.000    0.595    0.000 3144352985.py:158(<listcomp>)\n",
      "   366304    0.017    0.000    0.017    0.000 {built-in method builtins.hasattr}\n",
      "   172696    0.015    0.000    0.015    0.000 3144352985.py:120(<genexpr>)\n",
      "    27725    0.014    0.000    0.329    0.000 <__array_function__ internals>:177(prod)\n",
      "    27725    0.013    0.000    0.576    0.000 3144352985.py:81(__init__)\n",
      "    27725    0.013    0.000    0.563    0.000 3144352985.py:31(__init__)\n",
      "    27725    0.012    0.000    0.498    0.000 3144352985.py:14(NewKey)\n",
      "    27726    0.010    0.000    0.010    0.000 {method 'items' of 'dict' objects}\n",
      "   198360    0.010    0.000    0.010    0.000 {built-in method builtins.len}\n",
      "    27725    0.009    0.000    0.312    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "    27725    0.009    0.000    0.009    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
      "    27725    0.007    0.000    0.007    0.000 {built-in method _hashlib.openssl_md5}\n",
      "    56983    0.006    0.000    0.006    0.000 {method 'append' of 'list' objects}\n",
      "    27725    0.005    0.000    0.005    0.000 3144352985.py:157(<setcomp>)\n",
      "    27726    0.005    0.000    0.005    0.000 <string>:2(__init__)\n",
      "    72557    0.005    0.000    0.005    0.000 {method 'get' of 'dict' objects}\n",
      "    27725    0.004    0.000    0.004    0.000 3144352985.py:157(<listcomp>)\n",
      "    27725    0.004    0.000    0.004    0.000 {method 'copy' of 'dict' objects}\n",
      "    27726    0.004    0.000    0.004    0.000 {method 'add' of 'set' objects}\n",
      "    27725    0.003    0.000    0.003    0.000 {method 'encode' of 'str' objects}\n",
      "     6974    0.003    0.000    0.003    0.000 {method 'copy' of 'list' objects}\n",
      "    27725    0.003    0.000    0.003    0.000 fromnumeric.py:2950(_prod_dispatcher)\n",
      "      4/1    0.000    0.000    2.478    2.478 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.001    0.001 dataclasses.py:885(_process_class)\n",
      "      204    0.000    0.000    0.000    0.000 3144352985.py:197(<genexpr>)\n",
      "      2/1    0.000    0.000    0.000    0.000 inspect.py:2422(_signature_from_callable)\n",
      "      304    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2327(_signature_from_function)\n",
      "       15    0.000    0.000    0.000    0.000 dataclasses.py:665(_is_type)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:724(_get_field)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:413(_create_fn)\n",
      "        1    0.000    0.000    0.001    0.001 dataclasses.py:1210(wrap)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3016(from_callable)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:2676(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:530(_init_fn)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3224(__str__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:2962(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
      "       77    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        5    0.000    0.000    0.000    0.000 inspect.py:2763(__str__)\n",
      "        6    0.000    0.000    0.000    0.000 enum.py:669(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2042(_signature_bound_method)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:1449(formatannotation)\n",
      "        7    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:735(unwrap)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:394(_recursive_repr)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:347(field)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:828(_set_new_attribute)\n",
      "       30    0.000    0.000    0.000    0.000 {method 'group' of 're.Match' objects}\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:451(_field_init)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:589(_repr_fn)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:371(_fields_in_init_order)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:267(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:821(_set_qualname)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:647(_is_classvar)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2068(_signature_is_builtin)\n",
      "        7    0.000    0.000    0.000    0.000 inspect.py:3011(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:380(_tuple_str)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:655(_is_initvar)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:167(get_annotations)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:574(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3270(signature)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:661(_is_kw_only)\n",
      "       12    0.000    0.000    0.000    0.000 dataclasses.py:427(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:389(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 3144352985.py:183(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 enum.py:1074(__new__)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:511(_init_param)\n",
      "        1    0.000    0.000    0.001    0.001 dataclasses.py:1193(dataclass)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.repr}\n",
      "       17    0.000    0.000    0.000    0.000 inspect.py:2741(kind)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:550(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1018(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 3144352985.py:185(State)\n",
      "        3    0.000    0.000    0.000    0.000 inspect.py:1950(_signature_get_user_defined_method)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:625(_cmp_fn)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:593(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:439(_field_assign)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3032(replace)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "       11    0.000    0.000    0.000    0.000 inspect.py:2729(name)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2080(_signature_is_functionlike)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 inspect.py:378(isfunction)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1044(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        6    0.000    0.000    0.000    0.000 dataclasses.py:375(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:325(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        6    0.000    0.000    0.000    0.000 dataclasses.py:1102(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:755(_is_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1053(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:292(isclass)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1047(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:376(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:310(ismethoddescriptor)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(__create_fn__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen abc>:146(update_abstractmethods)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:505(isbuiltin)\n",
      "        5    0.000    0.000    0.000    0.000 inspect.py:2733(default)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:3028(return_annotation)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:3024(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:843(_hash_set_none)"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "import os, sys\n",
    "from typing import Any, Iterable, Literal\n",
    "import hashlib\n",
    "from limes_x.utils import KeyGenerator\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self) -> None:\n",
    "        self.node_signatures: dict[str, str] = {}\n",
    "        self._keygen = KeyGenerator()\n",
    "        self._keys: set[str] = set()\n",
    "\n",
    "    def NewKey(self):\n",
    "        return self._keygen.GenerateUID(blacklist=self._keys)\n",
    "\n",
    "class Hashable:\n",
    "    def __init__(self, ns: Namespace) -> None:\n",
    "        self.namespace = ns\n",
    "        self.key = ns.NewKey()\n",
    "        self.hash = int(hashlib.md5(self.key.encode(\"latin1\")).hexdigest(), 16)\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return self.hash\n",
    "    \n",
    "    def __eq__(self, __value: object) -> bool:\n",
    "        K = \"hash\"\n",
    "        return hasattr(__value, K) and self.hash == getattr(__value, K)\n",
    "\n",
    "class Node(Hashable):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ns: Namespace,\n",
    "        properties: set[str],\n",
    "        parents: set[Node],\n",
    "    ) -> None:\n",
    "        super().__init__(ns)\n",
    "        self.namespace = ns\n",
    "        self.properties = properties\n",
    "        self.parents = parents\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"<{self.key}:{','.join(self.properties)}>\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self}\"\n",
    "    \n",
    "    # # x == y if x is a \"subset\" of y\n",
    "    # # that is, x has at least all features of y\n",
    "    # def __eq__(self, __value: object) -> bool:\n",
    "    #     if not isinstance(__value, Node): return False\n",
    "    #     # if not __value.properties.issubset(self.properties): return False\n",
    "    #     for p in __value.properties:\n",
    "    #         if p not in self.properties: return False\n",
    "    #     for p in __value.parents:\n",
    "    #         if all(p != op for op in self.parents): return False\n",
    "    #     return True\n",
    "    \n",
    "    def IsA(self, other: Node) -> bool:\n",
    "        if not other.properties.issubset(self.properties): return False\n",
    "        # if not other.parents.issubset(self.parents): return False\n",
    "        return True\n",
    "\n",
    "    def Signature(self):\n",
    "        cache = self.namespace.node_signatures\n",
    "        if self.key not in cache:\n",
    "            props = \"\".join(sorted(self.properties))\n",
    "            parents = \"\".join(sorted([p.Signature() for p in self.parents]))\n",
    "            sig = props+parents\n",
    "            cache[self.key] = sig\n",
    "        return cache[self.key]\n",
    "\n",
    "    def MatchesMemberOf(self, collection: Iterable[Node]):\n",
    "        return any(self == m for m in collection)\n",
    "\n",
    "class Dependency(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: set[Node]) -> None:\n",
    "        super().__init__(namespace, properties, parents)\n",
    "\n",
    "class Endpoint(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: set[Node]=set()) -> None:\n",
    "        super().__init__(namespace, properties, parents)\n",
    "\n",
    "class Transform(Hashable):\n",
    "    def __init__(self, ns: Namespace) -> None:\n",
    "        super().__init__(ns)\n",
    "        self.requires: list[Dependency] = []\n",
    "        self.produces: list[Dependency] = []\n",
    "        self._ns = ns\n",
    "        self._input_group_map: dict[int, list[Dependency]] = {}\n",
    "        self._key = ns.NewKey()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        def _props(d: Dependency):\n",
    "            return \"{\"+\"-\".join(d.properties)+\"}\"\n",
    "        return f\"<{','.join(_props(r) for r in self.requires)}->{','.join(_props(p) for p in self.produces)}>\"\n",
    "\n",
    "    def __repr__(self): return f\"{self}\"\n",
    "\n",
    "    def AddRequirement(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.requires, properties, parents)\n",
    "\n",
    "    def AddProduct(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.produces, properties, parents)\n",
    "\n",
    "    def _add_dependency(self, destination: list[Dependency], properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        _parents: Any = parents\n",
    "        _dep = Dependency(properties=set(properties), parents=_parents, namespace=self._ns)\n",
    "        assert not any(e.IsA(_dep) for e in destination), f\"prev. dep ⊆ new dep\"\n",
    "        assert not any(_dep.IsA(e) for e in destination), f\"new dep ⊆ prev. dep \"\n",
    "        destination.append(_dep)\n",
    "        if destination == self.requires:\n",
    "            i = len(self.requires)-1\n",
    "            for p in _parents:\n",
    "                assert p in self.requires, f\"{p} not added as a requirement\"\n",
    "            self._input_group_map[i] = self._input_group_map.get(i, [])+list(_parents)\n",
    "        return _dep\n",
    "\n",
    "    def _sig(self, endpoints: Iterable[Endpoint]):\n",
    "        return \"\".join(e.key for e in endpoints)\n",
    "\n",
    "    def Apply(self, have: Iterable[Endpoint], blacklist: set[str]):\n",
    "        matches: list[list[Endpoint]] = []\n",
    "        for req in self.requires:\n",
    "            _m = [m for m in have if m.IsA(req)]\n",
    "            if len(_m) == 0: return []\n",
    "            matches.append(_m)\n",
    "\n",
    "        # can reduce exponential trial here by enforcning the input groups first\n",
    "        def _possible_configs(i: int, choosen: list[Endpoint]) -> list[list[Endpoint]]:\n",
    "            if i >= len(self.requires): return [choosen]\n",
    "            candidates = matches[i]\n",
    "            parents = self._input_group_map.get(i, [])\n",
    "            # print(parents, candidates, choosen)\n",
    "            if len(parents) > 0:\n",
    "                for prototype in parents:\n",
    "                    # parent must be in choosen, since it must have been added\n",
    "                    # as a req. before being used as a parent\n",
    "                    parent: None|Endpoint = None\n",
    "                    for p in choosen:\n",
    "                        if p.IsA(prototype): parent = p; break\n",
    "                    if parent is None: return []\n",
    "                    candidates = [c for c in candidates if parent in c.parents]\n",
    "            configs = []\n",
    "            for c in candidates:\n",
    "                configs += _possible_configs(i+1, choosen+[c])\n",
    "            return configs\n",
    "        configs = _possible_configs(0, [])\n",
    "\n",
    "        # todo: next optimization is DFS, with saved subplans\n",
    "\n",
    "        applications: list[Application] = []\n",
    "        for input_set in configs:\n",
    "            sis = set(input_set)\n",
    "            sig = self._sig(input_set)\n",
    "            if sig in blacklist: continue\n",
    "            _parents = sis|{p for g in [e.parents for e in input_set] for p in g}\n",
    "            produced = [\n",
    "                Endpoint(\n",
    "                    namespace=self._ns,\n",
    "                    properties=out.properties,\n",
    "                    parents=_parents\n",
    "                )\n",
    "            for out in self.produces]\n",
    "            applications.append(Application(self, sis, produced, sig))\n",
    "        return applications\n",
    "\n",
    "@dataclass\n",
    "class Application:\n",
    "    transform: Transform\n",
    "    used: set[Endpoint]\n",
    "    produced: list[Endpoint]\n",
    "    signature: str\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    solution: list[Application]\n",
    "    message: str = \"\"\n",
    "    evidence: Any = None\n",
    "    steps: int = 0\n",
    "    \n",
    "def Solve(given: Iterable[Endpoint], targets: Iterable[Endpoint], transforms: Iterable[Transform]):\n",
    "    if all(any(t.IsA(g) for g in given) for t in targets): return Result([], \"given all targets\")\n",
    "\n",
    "    @dataclass\n",
    "    class State:\n",
    "        requirements: list[Endpoint]\n",
    "        have: list[Endpoint]\n",
    "        usage_signatures: dict[str, set[str]]\n",
    "        plan: list[Application]\n",
    "        last_tr_i: int\n",
    "\n",
    "    transforms = list(transforms)\n",
    "    solution_transforms: set[int] = set()\n",
    "    for i, tr in enumerate(transforms):\n",
    "        for p in tr.produces:\n",
    "            if not any(p.IsA(t) for t in targets): continue\n",
    "            solution_transforms.add(i)\n",
    "    todo = [State(\n",
    "        requirements = list(targets),\n",
    "        have = list(given),\n",
    "        plan = [],\n",
    "        last_tr_i = 0,\n",
    "        usage_signatures={},\n",
    "    )]\n",
    "    _steps = 0\n",
    "    MAXS = 9999\n",
    "    while len(todo)>0:\n",
    "        _steps += 1\n",
    "        if _steps > MAXS: return Result([], f\"step limit exceeded\", steps=_steps)\n",
    "        _s = todo.pop()\n",
    "        if len(_s.requirements) == 0: return Result(_s.plan, steps = _steps)\n",
    "        \n",
    "        tri = _s.last_tr_i+1\n",
    "        if tri>len(transforms): tri = 0\n",
    "        trs = transforms[tri:]+transforms[:tri]\n",
    "        # print(trs)\n",
    "        for tr in trs:\n",
    "\n",
    "            for app in tr.Apply(_s.have, _s.usage_signatures.get(tr.key, set())):\n",
    "                new_reqs = _s.requirements\n",
    "                if tri in solution_transforms:\n",
    "                    new_reqs = new_reqs.copy()\n",
    "                    for i in range(len(new_reqs)-1, -1, -1):\n",
    "                        req = new_reqs[i]\n",
    "                        if any(p.IsA(req) for p in app.produced): new_reqs.remove(req)\n",
    "                # print(len(_s.plan), tri, app)\n",
    "                sigs = _s.usage_signatures.copy()\n",
    "                sigs[tr.key] = sigs.get(tr.key, set())|{app.signature}\n",
    "                todo.append(State(\n",
    "                    requirements = new_reqs,\n",
    "                    have = _s.have+app.produced,\n",
    "                    last_tr_i = tri,\n",
    "                    plan = _s.plan+[app],\n",
    "                    usage_signatures = sigs,\n",
    "                ))\n",
    "    return Result([], f\"ran out of things to try\", steps = _steps)\n",
    "\n",
    "# x, steps = Solve([asm, bin], [sum_asm, sum_bin], [anner, taxer, sumer])\n",
    "# x, steps\n",
    "\n",
    "# x, steps = Solve([asm, bin]+bs, [sum_asm, sum_bin]+ss, [anner, taxer, sumer])\n",
    "# x, steps\n",
    "\n",
    "NS = Namespace()\n",
    "def _set(s: str):\n",
    "    return set(s.split(\", \"))\n",
    "\n",
    "anner = Transform(NS)\n",
    "anner.AddRequirement(_set(\"annable\"))\n",
    "anner.AddProduct(_set(\"ann\"))\n",
    "\n",
    "taxer = Transform(NS)\n",
    "taxer.AddRequirement(_set(\"taxable\"))\n",
    "taxer.AddProduct(_set(\"tax\"))\n",
    "\n",
    "sumer = Transform(NS)\n",
    "d_parent = sumer.AddRequirement(_set(\"annable, taxable\"))\n",
    "d_ann = sumer.AddRequirement(_set(\"ann\"), {d_parent})\n",
    "d_tax = sumer.AddRequirement(_set(\"tax\"), {d_parent})\n",
    "sumer.AddProduct(_set(\"sum\"))\n",
    "\n",
    "N = 100\n",
    "\n",
    "bs = [Endpoint(NS, _set(f\"{i+1}, annable, taxable\")) for i in range(N)]\n",
    "ss = [Endpoint(NS, _set(\"sum\"), {e}) for e in bs]\n",
    "tr = [anner, taxer, sumer]\n",
    "# %prun Solve(bs, ss, [anner, taxer, sumer])\n",
    "# r = Solve(bs, ss, [anner, taxer, sumer])\n",
    "# r\n",
    "\n",
    "test_have = []\n",
    "for b in bs[:N]:\n",
    "    test_have.append(b)\n",
    "    test_have.append(Endpoint(NS, _set(\"ann\"), {b}))\n",
    "    test_have.append(Endpoint(NS, _set(\"tax\"), {b}))\n",
    "\n",
    "# sumer.Apply(test_have)\n",
    "print(\"Start\")\n",
    "%prun r = Solve(bs, ss, tr)\n",
    "f\"input size [{N}], states checked [{r.steps}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 16)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.solution), r.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Application(transform=<{annable}->{ann}>, used={<ryIimv2Ja9KS:annable,4,taxable>}, produced=[<4NRzojmhcJlh:ann>], signature='ryIimv2Ja9KS'),\n",
       " Application(transform=<{taxable}->{tax}>, used={<ryIimv2Ja9KS:annable,4,taxable>}, produced=[<LlxShHV0KfYo:tax>], signature='ryIimv2Ja9KS'),\n",
       " Application(transform=<{annable-taxable},{ann},{tax}->{sum}>, used={<ryIimv2Ja9KS:annable,4,taxable>, <4NRzojmhcJlh:ann>, <LlxShHV0KfYo:tax>}, produced=[<kGC0ewpNoyY9:sum>], signature='ryIimv2Ja9KS4NRzojmhcJlhLlxShHV0KfYo'),\n",
       " Application(transform=<{taxable}->{tax}>, used={<d3UN0uBb10oO:3,taxable,annable>}, produced=[<MjLKKBe8ut3M:tax>], signature='d3UN0uBb10oO'),\n",
       " Application(transform=<{annable}->{ann}>, used={<d3UN0uBb10oO:3,taxable,annable>}, produced=[<4IcUcAw2ka73:ann>], signature='d3UN0uBb10oO'),\n",
       " Application(transform=<{taxable}->{tax}>, used={<ESD4GQHUimAV:2,taxable,annable>}, produced=[<9Ev3sT9oLCG9:tax>], signature='ESD4GQHUimAV'),\n",
       " Application(transform=<{annable-taxable},{ann},{tax}->{sum}>, used={<4IcUcAw2ka73:ann>, <MjLKKBe8ut3M:tax>, <d3UN0uBb10oO:3,taxable,annable>}, produced=[<KNoRM2zZS1p0:sum>], signature='d3UN0uBb10oO4IcUcAw2ka73MjLKKBe8ut3M'),\n",
       " Application(transform=<{taxable}->{tax}>, used={<8naVThkJkUdg:annable,1,taxable>}, produced=[<ZIkrpcNoGJKm:tax>], signature='8naVThkJkUdg'),\n",
       " Application(transform=<{annable}->{ann}>, used={<ESD4GQHUimAV:2,taxable,annable>}, produced=[<uctludjqhcbL:ann>], signature='ESD4GQHUimAV'),\n",
       " Application(transform=<{annable-taxable},{ann},{tax}->{sum}>, used={<ESD4GQHUimAV:2,taxable,annable>, <9Ev3sT9oLCG9:tax>, <uctludjqhcbL:ann>}, produced=[<XnndB6gbzhUR:sum>], signature='ESD4GQHUimAVuctludjqhcbL9Ev3sT9oLCG9')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test all given\n",
    "# r = Solve(bs, bs, [anner, taxer, sumer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Solve(given: Iterable[Endpoint], targets: Iterable[Endpoint], transforms: Iterable[Transform]):\n",
    "#     todo: list[tuple[set[Endpoint], list[Application]]] = [\n",
    "#         (set(given), [])\n",
    "#     ]\n",
    "#     def _signature(state: Iterable[Endpoint]):\n",
    "#         return \",\".join(e.Signature() for e in state)\n",
    "\n",
    "#     steps = 0\n",
    "#     seen = set()\n",
    "#     while len(todo) > 0:\n",
    "#         steps += 1\n",
    "#         _have, _path = todo.pop(0)\n",
    "#         if all(any(e == t for e in _have) for t in targets): return _path, steps\n",
    "#         for tr in transforms:\n",
    "#             applications = tr.Apply(_have, _path)\n",
    "#             for appl in applications:\n",
    "#                 new_have = _have | set(appl.produced)\n",
    "#                 # sig = _signature(new_have)\n",
    "#                 # if sig in seen: continue\n",
    "#                 # seen.add(sig)\n",
    "#                 todo.append((new_have, _path+[appl]))\n",
    "#     return False, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _start = Endpoint(namespace=NS, properties=_settify(\"primeable\"))\n",
    "# _target = Endpoint(namespace=NS, properties=_settify(\"starred\"), parents={_start})\n",
    "\n",
    "# primer = Transform(NS)\n",
    "# primer.AddDependency(\n",
    "#     \"req\", _settify(\"primeable\"),\n",
    "# )\n",
    "# primer.AddDependency(\n",
    "#     \"prod\", _settify(\"primed\"),\n",
    "# )\n",
    "\n",
    "# starer = Transform(NS)\n",
    "# starer.AddDependency(\n",
    "#     \"req\", _settify(\"primed\"),\n",
    "# )\n",
    "# starer.AddDependency(\n",
    "#     \"prod\", _settify(\"starred\"),\n",
    "# )\n",
    "\n",
    "# have = {_start}\n",
    "# targets = {_target}\n",
    "\n",
    "# def Solve(have: Iterable[Endpoint], targets: Iterable[Endpoint]):\n",
    "#     todo = [\n",
    "#         (set(have), [])\n",
    "#     ]\n",
    "#     while len(todo)\n",
    "\n",
    "# xs = primer.Apply([_start])\n",
    "# ys = starer.Apply(xs)\n",
    "\n",
    "# for x in ys:\n",
    "#     print(x == _target, _target == x)\n",
    "#     print(x.parents, x.properties)\n",
    "#     print(_target.parents, _target.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Solve(given: Iterable[Endpoint], targets: Iterable[Endpoint], transforms: Iterable[Transform]):\n",
    "#     if all(any(t.IsA(g) for g in given) for t in targets): return Result([], \"given all targets\")\n",
    "\n",
    "#     @dataclass\n",
    "#     class State:\n",
    "#         targets: set[Endpoint]\n",
    "#         usage_signatures: set[str]\n",
    "#         plan: list[Application]\n",
    "\n",
    "#     prod_map: dict[str, set[Transform]] = {}\n",
    "#     for tr in transforms:\n",
    "#         for prod in tr.produces:\n",
    "#             for prop in prod.properties:\n",
    "#                 prod_map[prop] = prod_map.get(prop, set()) | {tr}\n",
    "\n",
    "#     # sub_solutions: dict[Endpoint, list[Transform]] = {}\n",
    "#     def _solve_target(target: Node):\n",
    "#         # if can't produce a property, can't produce target\n",
    "#         if any(p not in prod_map for p in target.properties): return []\n",
    "#         # get transforms that can create all properties\n",
    "#         candidates: None|set[Transform] = None\n",
    "#         for p in target.properties:\n",
    "#             if candidates is None: candidates = prod_map[p]\n",
    "#             else: candidates = candidates ^ prod_map[p]\n",
    "#         if candidates is None or len(candidates) == 0: return []\n",
    "#         # ensure transforms can create target. properties are no same product\n",
    "#         valid_transforms: list[Transform] = []\n",
    "#         for tr in candidates:\n",
    "#             for prod in tr.produces:\n",
    "#                 # print(prod.properties, target.properties)\n",
    "#                 # print(prod.parents, target.parents)\n",
    "#                 if not prod.IsA(target): continue\n",
    "#                 valid_transforms.append(tr)\n",
    "#                 break\n",
    "#         return valid_transforms\n",
    "\n",
    "#     given_props = {p for g in [g.properties for g in given] for p in g}\n",
    "#     def _in_given(n: Node):\n",
    "#         if not n.properties.issubset(given_props): return False\n",
    "#         useable = [g for g in given if g.IsA(n)]\n",
    "#         if len(useable) == 0: return False\n",
    "#         return useable\n",
    "    \n",
    "#     def signature():\n",
    "#         pass\n",
    "\n",
    "#     s_given: set[Endpoint] = set(given)\n",
    "#     s_targets: set[Endpoint] = set(targets)\n",
    "#     todo: list[State] = [State(\n",
    "#         targets=s_targets-s_given,\n",
    "#         usage_signatures=set(),\n",
    "#         plan=[],\n",
    "#     )]\n",
    "#     while len(todo)>0:\n",
    "#         print(\">\")\n",
    "#         _s = todo.pop()\n",
    "#         if len(_s.targets) == 0: return Result(_s.plan) # solved!\n",
    "        \n",
    "#         valid_transforms = {tr for g in [_solve_target(t) for t in _s.targets] for tr in g}\n",
    "#         if len(valid_transforms) == 0: return Result(_s.plan, \"no valid transforms for\", _s.targets)\n",
    "#         print(valid_transforms, _s.targets)\n",
    "#         for tr in valid_transforms:\n",
    "#             reqs, pending = [], set()\n",
    "#             for r in tr.requires:\n",
    "#                 useable_givens = _in_given(r)\n",
    "#                 _continue = False\n",
    "#                 if useable_givens:\n",
    "#                     for g in useable_givens:\n",
    "#                         if g in used_givens: continue\n",
    "#                         reqs.append(g)\n",
    "#                         used_givens.add(g)\n",
    "#                         _continue=True; break\n",
    "#                 if _continue: continue\n",
    "#                 n = Endpoint\n",
    "\n",
    "#                 reqs.append(r)\n",
    "#                 pending.add(r)\n",
    "        \n",
    "#             produced = set()\n",
    "#             for p in tr.produces:\n",
    "#                 for t in _s.targets:\n",
    "#                     if t in produced: continue # comparison using exact hash\n",
    "#                     if p.IsA(t):\n",
    "#                         produced.add(t)\n",
    "#                         break\n",
    "#             todo.append(State(\n",
    "#                 targets=_s.targets-produced|pending,\n",
    "#                 usage_signatures=_s.usage_signatures.copy(),\n",
    "#                 plan=_s.plan+[Application(tr, reqs, produced)],\n",
    "#             ))\n",
    "\n",
    "#     return Result([], \"todo exhausted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# NS = Namespace()\n",
    "# anner = Transform(\"anner\", NS)\n",
    "# anner.AddDependency(\n",
    "#     \"req\", \"a_in\",\n",
    "#     \"annable\".split(\", \"),\n",
    "# )\n",
    "# anner.AddDependency(\n",
    "#     \"prod\", \"a_out\",\n",
    "#     \"ann\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# taxer = Transform(\"taxer\", NS)\n",
    "# taxer.AddDependency(\n",
    "#     \"req\", \"t_in\",\n",
    "#     \"taxable\".split(\", \"),\n",
    "# )\n",
    "# taxer.AddDependency(\n",
    "#     \"prod\", \"t_out\",\n",
    "#     \"tax\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# sumer = Transform(\"sumer\", NS)\n",
    "# sumer.AddDependency(\n",
    "#     \"req\", \"s_in_ann\",\n",
    "#     \"ann\".split(\", \"),\n",
    "# )\n",
    "# sumer.AddDependency(\n",
    "#     \"req\", \"s_in_tax\",\n",
    "#     \"tax\".split(\", \"),\n",
    "# )\n",
    "# sumer.AddDependency(\n",
    "#     \"prod\", \"s_out\",\n",
    "#     \"sum\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# in_asm = Endpoint.New(NS, \"in_asm\", \"asm, annable, taxable\", have=True)\n",
    "# in_bin = Endpoint.New(NS, \"in_bin\", \"bin, annable, taxable\", have=True)\n",
    "\n",
    "# for tr in [anner, taxer, sumer]:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import annotations\n",
    "# from dataclasses import dataclass, field\n",
    "# import os, sys\n",
    "# from typing import Any, Iterable, Literal\n",
    "# import networkx as nx\n",
    "# import hashlib\n",
    "\n",
    "# class Namespace:\n",
    "#     def __init__(self) -> None:\n",
    "#         self.node_hashes: dict[str, int] = {}\n",
    "#         self.properties: dict[str, Property] = {}\n",
    "\n",
    "#     def GetProperty(self, key: str):\n",
    "#         if key not in self.properties:\n",
    "#             new = Property(self, key)\n",
    "#             new.back_links = set()\n",
    "#             self.properties[key] = new\n",
    "#         return self.properties[key]\n",
    "\n",
    "# @dataclass\n",
    "# class Node:\n",
    "#     namespace: Namespace\n",
    "#     key: str\n",
    "\n",
    "#     def __hash__(self) -> int:\n",
    "#         node_hashes = self.namespace.node_hashes\n",
    "#         if self.key not in node_hashes:\n",
    "#             node_hashes[self.key] = int(hashlib.md5(self.key.encode(\"latin1\")).hexdigest(), 16)\n",
    "#         return node_hashes[self.key]\n",
    "    \n",
    "#     def __eq__(self, __value: object) -> bool:\n",
    "#         if not isinstance(__value, type(self)): return False\n",
    "#         return self.key == __value.key\n",
    "\n",
    "# class Linkable:\n",
    "#     back_links: set[HasLinks]\n",
    "\n",
    "# @dataclass\n",
    "# class Haveable:\n",
    "#     have: bool\n",
    "\n",
    "# @dataclass\n",
    "# class HasLinks:\n",
    "#     links: set[Linkable]\n",
    "\n",
    "#     def Enforce_backlinks(self):\n",
    "#         for o in self.links:\n",
    "#             o.back_links.add(self)\n",
    "\n",
    "#     def Link(self, o: Linkable):\n",
    "#         self.links.add(o)\n",
    "#         o.back_links.add(self)\n",
    "\n",
    "#     def Clear(self):\n",
    "#         for o in self.links:\n",
    "#             o.back_links.remove(self)\n",
    "#         self.links.clear()\n",
    "\n",
    "#     def Matches(self, other: HasLinks):\n",
    "#         return all(l in other.links for l in self.links)\n",
    "\n",
    "# @dataclass\n",
    "# class Property(Node, Linkable):\n",
    "#     def __hash__(self) -> int: return Node.__hash__(self)\n",
    "#     def __eq__(self, __value: object) -> bool: return Node.__eq__(self, __value)\n",
    "    \n",
    "# @dataclass\n",
    "# class Template(Node, HasLinks):\n",
    "#     pass\n",
    "\n",
    "# @dataclass\n",
    "# class Dependency(Node, HasLinks, Haveable):\n",
    "#     template: Template\n",
    "#     def __hash__(self) -> int: return Node.__hash__(self)\n",
    "#     def __eq__(self, __value: object) -> bool: return Node.__eq__(self, __value)\n",
    "\n",
    "#     def Reset(self):\n",
    "#         self.Clear()\n",
    "#         self.links = self.template.links.copy()\n",
    "#         self.Enforce_backlinks()\n",
    "\n",
    "# @dataclass\n",
    "# class Endpoint(Node, HasLinks, Linkable, Haveable):\n",
    "#     def __hash__(self) -> int: return Node.__hash__(self)\n",
    "#     def __eq__(self, __value: object) -> bool: return Node.__eq__(self, __value)\n",
    "\n",
    "#     @classmethod\n",
    "#     def New(cls, ns: Namespace, key: str, properties: Iterable[str], parents: set[Linkable]=set(), have=False):\n",
    "#         _links: set[Linkable] = {ns.GetProperty(p) for p in properties}\n",
    "#         _links = _links.union(parents)\n",
    "#         return Endpoint(\n",
    "#             key = key, links = _links,\n",
    "#             have = have, namespace=ns,\n",
    "#         )\n",
    "\n",
    "# class Transform:\n",
    "#     def __init__(self, name: str, namespace: Namespace) -> None:\n",
    "#         self.requires: set[Dependency] = set()\n",
    "#         self.produces: set[Dependency] = set()\n",
    "#         self.raw: bool = True\n",
    "#         self.name = name\n",
    "#         self._ns = namespace\n",
    "\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f\"Tr:{self.name}\"\n",
    "\n",
    "#     def AddDependency(self, role: Literal[\"req\"]|Literal[\"prod\"], key: str, properties: Iterable[str], parents: set[Linkable]=set()):\n",
    "#         _links: set[Linkable] = {self._ns.GetProperty(p) for p in properties}\n",
    "#         _links = _links.union(parents)\n",
    "#         _template = Template(key=f\"T-{key}\", links =_links, namespace=self._ns)\n",
    "#         _dep = Dependency(key=key, links=_links, template=_template, have=False, namespace=self._ns)\n",
    "#         _dep.Enforce_backlinks() # should be in init, but @_dep is dataclass!\n",
    "\n",
    "#         if role == \"req\":\n",
    "#             assert _dep not in self.produces\n",
    "#             self.requires.add(_dep)\n",
    "#         else:\n",
    "#             assert _dep not in self.requires\n",
    "#             self.produces.add(_dep)\n",
    "\n",
    "#     def Reset(self):\n",
    "#         self.raw = True\n",
    "#         for d in self.requires | self.produces:\n",
    "#             d.Reset()\n",
    "        \n",
    "# NS = Namespace()\n",
    "# anner = Transform(\"anner\", NS)\n",
    "# anner.AddDependency(\n",
    "#     \"req\", \"a_in\",\n",
    "#     \"annable\".split(\", \"),\n",
    "# )\n",
    "# anner.AddDependency(\n",
    "#     \"prod\", \"a_out\",\n",
    "#     \"ann\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# taxer = Transform(\"taxer\", NS)\n",
    "# taxer.AddDependency(\n",
    "#     \"req\", \"t_in\",\n",
    "#     \"taxable\".split(\", \"),\n",
    "# )\n",
    "# taxer.AddDependency(\n",
    "#     \"prod\", \"t_out\",\n",
    "#     \"tax\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# sumer = Transform(\"sumer\", NS)\n",
    "# sumer.AddDependency(\n",
    "#     \"req\", \"s_in_ann\",\n",
    "#     \"ann\".split(\", \"),\n",
    "# )\n",
    "# sumer.AddDependency(\n",
    "#     \"req\", \"s_in_tax\",\n",
    "#     \"tax\".split(\", \"),\n",
    "# )\n",
    "# sumer.AddDependency(\n",
    "#     \"prod\", \"s_out\",\n",
    "#     \"sum\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# in_asm = Endpoint.New(NS, \"in_asm\", \"asm, annable, taxable\", have=True)\n",
    "# in_bin = Endpoint.New(NS, \"in_bin\", \"bin, annable, taxable\", have=True)\n",
    "\n",
    "# for tr in [anner, taxer, sumer]:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import annotations\n",
    "# import os, sys\n",
    "# import asyncio\n",
    "# from typing import Iterable, Callable, Any\n",
    "# from pathlib import Path\n",
    "\n",
    "# from limes_x.solver import DependencySolver, Plan, Dependency\n",
    "# from limes_x.persistence import ProjectState, Instance\n",
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# mpath = Path(\"./test_solver/\")\n",
    "# modules = [\n",
    "#     ComputeModule(mpath.joinpath(d)) for d in os.listdir(mpath)\n",
    "# ]\n",
    "# print(modules)\n",
    "\n",
    "# given = [\n",
    "#     (\"a\", \"./test_data/a1\"),\n",
    "#     (\"a\", \"./test_data/a2\"),\n",
    "#     (\"b\", \"./test_data/b1\"),\n",
    "# ]\n",
    "\n",
    "# prj_path = \"./cache/man_test01/\"\n",
    "# state = ProjectState(prj_path, on_exist=\"overwrite\")\n",
    "# for dtype, val in given:\n",
    "#     state.RegisterInstance(Instance.Str(dtype, val))\n",
    "# for m in modules:\n",
    "#     state.RegisterInstance(Instance.ComputeModule(m))\n",
    "\n",
    "# deps = []\n",
    "# for k, inst in state._instances.items():\n",
    "#     if not inst.IsPyType(ComputeModule): continue\n",
    "#     deps.append(Dependency(inst.val.requires, inst.val.produces, k))\n",
    "\n",
    "# solver = DependencySolver(deps)\n",
    "# # plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan = solver.Solve({\"a\"}, {\"branched\"})\n",
    "# assert plan != False\n",
    "# [state.GetInstance(m.ref_key) for m in plan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_dependency(module: ComputeModule):\n",
    "#     return Dependency(module.requires, module.produces, module)\n",
    "\n",
    "# modules = Path(\"./test_solver/\")\n",
    "# solver = Plan([\n",
    "#     make_dependency(ComputeModule(p))\n",
    "# for p in [\n",
    "#     modules.joinpath(p) for p in os.listdir(modules)\n",
    "# ]])\n",
    "# plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# a = ComputeModule(\"./test_modules/copy/\")\n",
    "# b = ComputeModule(\"./test_modules/copy2/\")\n",
    "\n",
    "# a.requires, b.requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = ProjectState(\"./cache/test_persist\")\n",
    "# ok = Instance(\"asdf\", 1)\n",
    "# ov = Instance(\"s\", 2)\n",
    "# state._lineage[ok] = [ov]\n",
    "# state.Save()\n",
    "\n",
    "# s2 = ProjectState.Load(\"./cache/test_persist\")\n",
    "# for k, v in s2._lineage.items():\n",
    "#     _te = k.type, k.value, ok == k, [(i.type, i.value, i == ov) for i in v]\n",
    "#     print(_te)\n",
    "\n",
    "# ok._id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = []\n",
    "# for i in range(100000):\n",
    "#     x = Instance(\"asdf\", [\"x\"*150, \"y\"*150])\n",
    "#     # x = 1\n",
    "#     test.append(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
