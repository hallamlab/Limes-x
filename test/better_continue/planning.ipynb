{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>00 <{bin},{table}->> {}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>])\n",
      " -> <D:bin> {}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>])\n",
      ">>>01 <{dna},{asm,contigs}->{bin,contigs,annable}> {}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>])\n",
      " -> <D:dna> {}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>])\n",
      "    ^ <X000:dna> <D:dna>\n",
      "    ^ set()\n",
      "    ^ {}\n",
      "    ^\n",
      " <- <D:dna> <X000:dna> DIRECT\n",
      " -> <D:asm,contigs> {<D:dna>: <X000:dna>}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>])\n",
      ">>>02 <{dna}->{asm,contigs,annable}> {<D:dna>: <X000:dna>}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>])\n",
      " -> <D:dna> {}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>])\n",
      "    ^ <X000:dna> <D:dna>\n",
      "    ^ set()\n",
      "    ^ {}\n",
      "    ^\n",
      " <- <D:dna> <X000:dna> DIRECT\n",
      "<<<02 <{dna}->{asm,contigs,annable}>\n",
      "  . {<h000:asm,contigs,annable>: <D:asm,contigs,annable>, <V000:cog,db>: <D:cog,db>, <W000:kegg,db>: <D:kegg,db>, <X000:dna>: <D:dna>}\n",
      "    <X000:dna> []\n",
      "    __ Application(transform=<{dna}->{asm,contigs,annable}>, used={<X000:dna>: <D:dna>}, produced={<h000:asm,contigs,annable>: <D:asm,contigs,annable>})\n",
      " <- <D:asm,contigs> Application(transform=<{dna}->{asm,contigs,annable}>, used={<X000:dna>: <D:dna>}, produced={<h000:asm,contigs,annable>: <D:asm,contigs,annable>})\n",
      "<<<01 <{dna},{asm,contigs}->{bin,contigs,annable}>\n",
      "  . {<i000:bin,contigs,annable>: <D:bin,contigs,annable>, <V000:cog,db>: <D:cog,db>, <W000:kegg,db>: <D:kegg,db>, <X000:dna>: <D:dna>, <h000:asm,contigs,annable>: <D:asm,contigs,annable>}\n",
      "    <X000:dna> []\n",
      "    <h000:asm,contigs,annable> [Application(transform=<{dna}->{asm,contigs,annable}>, used={<X000:dna>: <D:dna>}, produced={<h000:asm,contigs,annable>: <D:asm,contigs,annable>})]\n",
      "    __ Application(transform=<{dna}->{asm,contigs,annable}>, used={<X000:dna>: <D:dna>}, produced={<h000:asm,contigs,annable>: <D:asm,contigs,annable>})\n",
      "    __ Application(transform=<{dna},{asm,contigs}->{bin,contigs,annable}>, used={<X000:dna>: <D:dna>, <h000:asm,contigs,annable>: <D:asm,contigs>}, produced={<i000:bin,contigs,annable>: <D:bin,contigs,annable>})\n",
      " <- <D:bin> Application(transform=<{dna},{asm,contigs}->{bin,contigs,annable}>, used={<X000:dna>: <D:dna>, <h000:asm,contigs,annable>: <D:asm,contigs>}, produced={<i000:bin,contigs,annable>: <D:bin,contigs,annable>})\n",
      " -> <D:table> {<D:bin>: <i000:bin,contigs,annable>}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>, <h000:asm,contigs,annable>, <i000:bin,contigs,annable>])\n",
      ">>>01 <{cog},{ann},{kegg},{ann}->{table}> {<D:bin>: <i000:bin,contigs,annable>}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>, <h000:asm,contigs,annable>, <i000:bin,contigs,annable>])\n",
      " -> <D:cog> {<D:bin>: <i000:bin,contigs,annable>}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>, <h000:asm,contigs,annable>, <i000:bin,contigs,annable>])\n",
      "    ^ <V000:cog,db> <D:cog,db>\n",
      "    ^ set()\n",
      "    ^ {<D:bin>: <i000:bin,contigs,annable>}\n",
      "    ^\n",
      " <- FAIL <D:cog> {<D:bin>: <i000:bin,contigs,annable>}\n",
      " -> <D:kegg> {<D:bin>: <i000:bin,contigs,annable>}\n",
      "    dict_keys([<V000:cog,db>, <W000:kegg,db>, <X000:dna>, <h000:asm,contigs,annable>, <i000:bin,contigs,annable>])\n",
      "    ^ <W000:kegg,db> <D:kegg,db>\n",
      "    ^ set()\n",
      "    ^ {<D:bin>: <i000:bin,contigs,annable>}\n",
      "    ^\n",
      " <- FAIL <D:kegg> {<D:bin>: <i000:bin,contigs,annable>}\n",
      "<<< FAIL <{cog},{ann},{kegg},{ann}->{table}> <D:cog>\n",
      " <- FAIL <D:table> {<D:bin>: <i000:bin,contigs,annable>}\n",
      "<<< FAIL <{bin},{table}->> <D:table>\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "import os, sys\n",
    "from typing import Any, Generator, Iterable, Literal\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import deque\n",
    "\n",
    "from limes_x.utils import KeyGenerator\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self) -> None:\n",
    "        self.node_signatures: dict[int, str] = {}\n",
    "        self._last_k: int = 0\n",
    "        self._kg = KeyGenerator(True)\n",
    "        self._KLEN = 4\n",
    "        self._MAX_K = len(self._kg.vocab)**self._KLEN\n",
    "\n",
    "    def NewKey(self):\n",
    "        self._last_k += 1\n",
    "        assert self._last_k < self._MAX_K\n",
    "        return self._last_k, self._kg.FromInt(self._last_k, self._KLEN)\n",
    "\n",
    "class Hashable:\n",
    "    def __init__(self, ns: Namespace) -> None:\n",
    "        self.namespace = ns\n",
    "        self.hash, self.key = ns.NewKey()\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return self.hash\n",
    "    \n",
    "    def __eq__(self, __value: object) -> bool:\n",
    "        K = \"key\"\n",
    "        return hasattr(__value, K) and self.key == getattr(__value, K)\n",
    "\n",
    "class Node(Hashable):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ns: Namespace,\n",
    "        properties: set[str],\n",
    "        parents: set[Node],\n",
    "    ) -> None:\n",
    "        super().__init__(ns)\n",
    "        self.namespace = ns\n",
    "        self.properties = properties\n",
    "        self.parents = parents\n",
    "        self._sig: str|None = None\n",
    "        # self._diffs = set()\n",
    "        # self._sames = set()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"<{self.key}:{','.join(self.properties)}>\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self}\"\n",
    "    \n",
    "    def IsA(self, other: Node) -> bool:\n",
    "        # if other.key in self._diffs: return False\n",
    "        # if other.key in self._sames: return True\n",
    "        if not other.properties.issubset(self.properties):\n",
    "            # self._diffs.add(other.key)\n",
    "            return False\n",
    "        # self._sames.add(other.key)\n",
    "        # if compare_lineage: return  other.parents.issubset(self.parents)\n",
    "        return True\n",
    "\n",
    "    def Signature(self):\n",
    "        if self._sig is None:\n",
    "            self._sig = \",\".join(sorted(self.properties))\n",
    "        return self._sig\n",
    "\n",
    "class Dependency(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: set[Node]) -> None:\n",
    "        super().__init__(namespace, properties, parents)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"<D:{','.join(self.properties)}>\"\n",
    "    \n",
    "class Endpoint(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: dict[Endpoint, Node]=dict()) -> None:\n",
    "        super().__init__(namespace, properties, set(parents))\n",
    "        self._parent_map = parents # real, proto\n",
    "\n",
    "    def Iterparents(self):\n",
    "        \"\"\"real, prototype\"\"\"\n",
    "        for e, p in self._parent_map.items():\n",
    "            yield e, p\n",
    "\n",
    "class Transform(Hashable):\n",
    "    def __init__(self, ns: Namespace) -> None:\n",
    "        super().__init__(ns)\n",
    "        self.requires: list[Dependency] = list()\n",
    "        self.produces: list[Dependency] = list()\n",
    "        self._ns = ns\n",
    "        self._input_group_map: dict[int, list[Dependency]] = {}\n",
    "        self._key = ns.NewKey()\n",
    "        self._seen: set[str] = set()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        def _props(d: Dependency):\n",
    "            return \"{\"+\",\".join(d.properties)+\"}\"\n",
    "        return f\"<{','.join(_props(r) for r in self.requires)}->{','.join(_props(p) for p in self.produces)}>\"\n",
    "\n",
    "    def __repr__(self): return f\"{self}\"\n",
    "\n",
    "    def AddRequirement(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.requires, properties, parents)\n",
    "\n",
    "    def AddProduct(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.produces, properties, parents)\n",
    "\n",
    "    def _add_dependency(self, destination: list[Dependency], properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        _parents: Any = parents\n",
    "        _dep = Dependency(properties=set(properties), parents=_parents, namespace=self._ns)\n",
    "        # assert not any(e.IsA(_dep) for e in destination), f\"prev. dep ⊆ new dep\"\n",
    "        # assert not any(_dep.IsA(e) for e in destination), f\"new dep ⊆ prev. dep \"\n",
    "        # destination.add(_dep)\n",
    "        destination.append(_dep)\n",
    "        if destination == self.requires:\n",
    "            i = len(self.requires)-1\n",
    "            for p in _parents:\n",
    "                assert p in self.requires, f\"{p} not added as a requirement\"\n",
    "            self._input_group_map[i] = self._input_group_map.get(i, [])+list(_parents)\n",
    "        return _dep\n",
    "\n",
    "    def _sig(self, endpoints: Iterable[Endpoint]):\n",
    "        # return \"\".join(e.key for e in endpoints)\n",
    "        return self.key+\"-\"+ \"\".join(e.key for e in endpoints)\n",
    "\n",
    "    # just all possibilities regardless of lineage\n",
    "    def Possibilities(self, have: set[Endpoint], constraints: dict[Dependency, Endpoint]=dict()) -> Generator[list[Endpoint], Any, None]:\n",
    "        matches: list[list[Endpoint]] = []\n",
    "        constraints_used = False\n",
    "        for req in self.requires:\n",
    "            if req in constraints:\n",
    "                must_use = constraints[req]\n",
    "                _m = [must_use]\n",
    "            else:\n",
    "                _m = [m for m in have if m.IsA(req)]\n",
    "            if len(_m) == 0: return None\n",
    "            matches.append(_m)\n",
    "        if len(constraints)>0 and not constraints_used: return None\n",
    "\n",
    "        indexes = [0]*len(matches)\n",
    "        indexes[0] = -1\n",
    "        def _advance():\n",
    "            i = 0\n",
    "            while True:\n",
    "                indexes[i] += 1\n",
    "                if indexes[i] < len(matches[i]): return True\n",
    "                indexes[i] = 0\n",
    "                i += 1\n",
    "                if i >= len(matches): return False\n",
    "        while _advance():\n",
    "            yield [matches[i][j] for i, j in enumerate(indexes)]\n",
    "    \n",
    "    # filter possibilities based on correct lineage\n",
    "    def Valids(self, matches: Iterable[list[Endpoint]]):\n",
    "        black_list: set[tuple[int, Endpoint]] = set()\n",
    "        white_list: set[tuple[int, Endpoint]] = set()\n",
    "\n",
    "        choosen: list[Endpoint] = []\n",
    "        for config in matches:\n",
    "            ok = True\n",
    "            for i, (e, r) in enumerate(zip(config, self.requires)):\n",
    "                k = (i, e)\n",
    "                if k in black_list: ok=False; break\n",
    "                if k in white_list: continue\n",
    "                \n",
    "                parents = self._input_group_map.get(i, [])\n",
    "                if len(parents) == 0: # no lineage req.\n",
    "                    white_list.add(k)\n",
    "                    continue\n",
    "                \n",
    "                for prototype in parents:\n",
    "                    # parent must already be in choosen, since it must have been added\n",
    "                    # as a req. before being used as a parent during setup\n",
    "                    found = False\n",
    "                    for p in choosen:\n",
    "                        if not p.IsA(prototype): continue\n",
    "                        if p in e.parents: found=True; break\n",
    "                    if not found: black_list.add(k); ok=False; break\n",
    "                if not ok: break\n",
    "            if ok: yield config\n",
    "\n",
    "    def Apply(self, inputs: Iterable[tuple[Endpoint, Node]]):\n",
    "        for r, (e, e_proto) in zip(self.requires, inputs):\n",
    "            assert e.IsA(r), f\"{e_proto}, {e}, {r}\"\n",
    "\n",
    "        inputs_dict = dict(inputs)\n",
    "        parent_dict: dict[Any, Any] = inputs_dict.copy()\n",
    "        for e, _ in inputs_dict.items():\n",
    "            for p, pproto in e.Iterparents():\n",
    "                if p in parent_dict: continue\n",
    "                parent_dict[p] = pproto\n",
    "        produced = {\n",
    "            Endpoint(\n",
    "                namespace=self._ns,\n",
    "                properties=out.properties,\n",
    "                parents=parent_dict\n",
    "            ):out\n",
    "        for out in self.produces}\n",
    "        return Application(self, inputs_dict, produced)\n",
    "\n",
    "@dataclass\n",
    "class Application:\n",
    "    transform: Transform\n",
    "    used: dict[Endpoint, Node]\n",
    "    produced: dict[Endpoint, Dependency]\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    application: Application\n",
    "    dependency_plan: list[Application]\n",
    "    steps: int\n",
    "    \n",
    "def Solve(given: Iterable[Endpoint], target: Transform, transforms: Iterable[Transform]):\n",
    "    def _get_producers_of(target: Dependency):\n",
    "        for tr in transforms:\n",
    "            for p in tr.produces:\n",
    "                if not p.IsA(target): continue\n",
    "                yield tr\n",
    "                break\n",
    "\n",
    "    @dataclass\n",
    "    class State:\n",
    "        have: dict[Endpoint, Dependency]\n",
    "        target: Dependency|Transform\n",
    "        required_parents: dict[Node, Endpoint]\n",
    "        steps: int\n",
    "        depth: int\n",
    "\n",
    "    @dataclass\n",
    "    class DepResult:\n",
    "        plan: list[Application]\n",
    "        endpoint: Endpoint\n",
    "        steps: int\n",
    "\n",
    "    # debug_print = lambda *args: None\n",
    "    debug_print = lambda *args: print(*args)\n",
    "\n",
    "    HORIZON=64\n",
    "    def _solve_dep(s: State) -> None|DepResult:\n",
    "        if s.depth >= HORIZON: return None\n",
    "        assert isinstance(s.target, Dependency), f\"{s.target}, not dep\"\n",
    "        debug_print(f\" ->\", s.target, s.required_parents)\n",
    "        debug_print(f\"   \", s.have.keys())\n",
    "\n",
    "        for e, eproto in s.have.items():\n",
    "            if not e.IsA(s.target): continue\n",
    "            debug_print(f\"    ^\", e, eproto)\n",
    "            debug_print(f\"    ^\", e.parents)\n",
    "            debug_print(f\"    ^\", s.required_parents)\n",
    "            ok = True\n",
    "            for rproto, r in s.required_parents.items():\n",
    "                if e == r: continue\n",
    "                if eproto.IsA(rproto):\n",
    "                    ok=False; break\n",
    "\n",
    "                if all(not rproto.IsA(pproto) or p != r for p, pproto in e.Iterparents()):\n",
    "                    ok=False; break\n",
    "\n",
    "            debug_print(f\"    ^\")\n",
    "            if not ok: continue\n",
    "\n",
    "            debug_print(f\" <-\", s.target, e, \"DIRECT\")\n",
    "            return DepResult([], e, s.steps)\n",
    "\n",
    "        best_depth = -1\n",
    "        best: None|Result = None\n",
    "        for tr in _get_producers_of(s.target):\n",
    "            res = _solve_tr(State(s.have, tr, s.required_parents, s.steps, s.depth))\n",
    "            if res is None: continue # can't use tr\n",
    "            if best_depth == -1 or res.steps<best_depth:\n",
    "                best_depth = res.steps\n",
    "                best = res\n",
    "\n",
    "        if best is None:\n",
    "            debug_print(f\" <- FAIL\", s.target, s.required_parents)\n",
    "            return None\n",
    "        debug_print(f\" <-\", s.target, best.application if best is not None else best)\n",
    "\n",
    "        ep: Endpoint|None = None\n",
    "        for e in best.application.produced:\n",
    "            if e.IsA(s.target):\n",
    "                ep = e; break\n",
    "        assert isinstance(ep, Endpoint)\n",
    "        return DepResult(\n",
    "            best.dependency_plan+[best.application],\n",
    "            ep,\n",
    "            s.steps+best.steps\n",
    "        )\n",
    "\n",
    "    def _solve_tr(s: State) -> None|Result:\n",
    "        assert isinstance(s.target, Transform), f\"{s.target} not tr\"\n",
    "        plans: dict[Node, list[Application]] = {}\n",
    "        deps: dict[Node, Endpoint] = {}\n",
    "        steps = 0\n",
    "        debug_print(f\">>>{s.depth:02}\", s.target, s.required_parents)\n",
    "        debug_print(f\"   \", s.have.keys())\n",
    "        _have = s.have.copy()\n",
    "\n",
    "        satisfied_lineages: dict[Endpoint, Dependency] = {}\n",
    "        todo: deque[Dependency] = deque()\n",
    "        for req in s.target.requires:\n",
    "            todo.append(req)\n",
    "        loop_marker: Dependency|None = None\n",
    "        while len(todo)>0:\n",
    "            req = todo.popleft()\n",
    "            if req == loop_marker:\n",
    "                debug_print(f\"<<< FAIL\", s.target, req)\n",
    "                return\n",
    "\n",
    "            req_p = {}\n",
    "            for proto, e in s.required_parents.items():\n",
    "                if req.IsA(proto): continue\n",
    "                # if already satisfied by other req and lineage not specified for this req: skip\n",
    "                if e in satisfied_lineages and all(not pproto.IsA(proto) for pproto in req.parents): continue\n",
    "                req_p[proto] = e\n",
    "            if any(p not in deps for p in req.parents):\n",
    "                res = None # requirements of node not satisfied yet\n",
    "            else:\n",
    "                req_p |= {p:deps[p] for p in req.parents}\n",
    "                res = _solve_dep(State(_have, req, req_p, s.steps+1, s.depth+1))\n",
    "            \n",
    "            if res is None:\n",
    "                todo.append(req)\n",
    "                if loop_marker is None: loop_marker = req\n",
    "                continue\n",
    "            loop_marker = None\n",
    "\n",
    "            if res.endpoint in plans: continue # for duplicate reqs...\n",
    "            plans[res.endpoint] = res.plan\n",
    "            deps[req] = res.endpoint\n",
    "            steps += res.steps\n",
    "            for appl in res.plan:\n",
    "                _have |= appl.produced\n",
    "            satisfied_lineages[res.endpoint] = req\n",
    "\n",
    "\n",
    "        debug_print(f\"<<<{s.depth:02}\", s.target)\n",
    "        # debug_print([(e, proto) for proto, e in deps.items()])\n",
    "        # debug_print(s.target.requires)\n",
    "        my_appl = s.target.Apply([(deps[r], r) for r in s.target.requires])\n",
    "        debug_print(f\"  .\", my_appl.produced|_have)\n",
    "        if s.target == target:\n",
    "            debug_print(plans)\n",
    "\n",
    "        consolidated_plan = []\n",
    "        produced_sigs: set[str] = {p.Signature() for p in my_appl.produced}\n",
    "        for req, plan in plans.items():\n",
    "            debug_print(f\"   \", req, plan)\n",
    "\n",
    "            for appl in plan:\n",
    "                if all(p.Signature() in produced_sigs for p in appl.produced): continue\n",
    "                consolidated_plan.append(appl)\n",
    "        # print(my_appl)\n",
    "        for appl in consolidated_plan+[my_appl]:\n",
    "            debug_print(f\"    __\", appl)\n",
    "\n",
    "        return Result(\n",
    "            my_appl,\n",
    "            consolidated_plan,\n",
    "            s.steps+steps,\n",
    "        )\n",
    "\n",
    "    input_tr = Transform(target._ns)\n",
    "    given_dict = {g:input_tr.AddProduct(g.properties) for g in given}\n",
    "    return _solve_tr(State(given_dict, target, {}, 0, 0))\n",
    "\n",
    "def _set(s: str):\n",
    "    return set(s.split(\", \"))\n",
    " \n",
    "transforms = []\n",
    "NS = Namespace()\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"dna\"))\n",
    "t.AddProduct(_set(\"contigs, asm, annable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "r = t.AddRequirement(_set(\"dna\"))\n",
    "t.AddRequirement(_set(\"contigs, asm\"), {r})\n",
    "t.AddProduct(_set(\"contigs, bin, annable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"db\"))\n",
    "t.AddRequirement(_set(\"annable\"))\n",
    "t.AddProduct(_set(\"ann\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "r = t.AddRequirement(_set(\"cog\"))\n",
    "t.AddRequirement(_set(\"ann\"), {r})\n",
    "r = t.AddRequirement(_set(\"kegg\"))\n",
    "t.AddRequirement(_set(\"ann\"), {r})\n",
    "t.AddProduct(_set(\"table\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "db1 = t.AddRequirement(_set(\"cog\"))\n",
    "db2 = t.AddRequirement(_set(\"kegg\"))\n",
    "r = t.AddRequirement(_set(\"contigs, asm\"))\n",
    "t.AddRequirement(_set(\"table\"), {r})\n",
    "r = t.AddRequirement(_set(\"contigs, bin\"))\n",
    "t.AddRequirement(_set(\"table\"), {r})\n",
    "t.AddProduct(_set(\"figure\"))\n",
    "transforms.append(t)\n",
    "\n",
    "# print(t.requires)\n",
    "\n",
    "# haves = [Endpoint(NS, _set(r)) for r in [\n",
    "#     \"reads\",\n",
    "#     \"db, kegg\",\n",
    "# ]]\n",
    "# target = Transform(NS)\n",
    "# r = target.AddRequirement(_set(\"asm\"))\n",
    "# target.AddRequirement(_set(\"ann\"), {r})\n",
    "# r = target.AddRequirement(_set(\"bin\"))\n",
    "# target.AddRequirement(_set(\"ann\"), {r})\n",
    "\n",
    "# res = Solve(haves, target, transforms)\n",
    "\n",
    "\n",
    "##############\n",
    "# failing because lineage requirement may be split, thus relieving some inputs of lineage\n",
    "# but can't proceed if the first input must be relieved by the following inputs\n",
    "# which can't run becuase they \"depend\" on the first input\n",
    "# todo: look ahead (no pathing, so fast) to determine which inputs can be relieved\n",
    "##############\n",
    "\n",
    "\n",
    "haves = [Endpoint(NS, _set(r)) for r in [\n",
    "    \"db, cog\",\n",
    "    \"db, kegg\",\n",
    "    \"dna\",\n",
    "]]\n",
    "\n",
    "target = Transform(NS)\n",
    "r = target.AddRequirement(_set(\"bin\"))\n",
    "# db = target.AddRequirement(_set(\"cog\"))\n",
    "# target.AddRequirement(_set(\"ann\"), {r})\n",
    "# target.AddRequirement(_set(\"table\"))\n",
    "target.AddRequirement(_set(\"table\"), {r})\n",
    "\n",
    "res = Solve(haves, target, transforms)\n",
    "if res is not None:\n",
    "    for a in res.dependency_plan:\n",
    "        print(a)\n",
    "    print(res.application)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NS = Namespace()\n",
    "transforms = []\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"reads\"))\n",
    "t.AddProduct(_set(\"annable, taxable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"annable\"))\n",
    "t.AddProduct(_set(\"ann\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"ann\"))\n",
    "t.AddProduct(_set(\"annable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"taxable\"))\n",
    "t.AddProduct(_set(\"tax\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "d_parent = t.AddRequirement(_set(\"annable, taxable\"))\n",
    "d_ann = t.AddRequirement(_set(\"ann\"), {d_parent})\n",
    "d_tax = t.AddRequirement(_set(\"tax\"), {d_parent})\n",
    "t.AddProduct(_set(\"sum\"))\n",
    "transforms.append(t)\n",
    "\n",
    "# M, N = 2, 1\n",
    "M, N = 3, 2\n",
    "# M, N = 1_000, 1_000\n",
    "haves = [Endpoint(NS, _set(f\"{i+1}, reads\")) for i in range(M)]\n",
    "\n",
    "target = Transform(NS)\n",
    "# for e in haves[-N:]:\n",
    "for e in haves[:N]:\n",
    "    de = target.AddRequirement(e.properties)\n",
    "    target.AddRequirement(_set(\"sum\"), {de})\n",
    "    # target.AddRequirement(_set(\"sum\"))\n",
    "\n",
    "print(\"Start\")\n",
    "# %prun r = Solve(haves, target, transforms)\n",
    "res = Solve(haves, target, transforms)\n",
    "print()\n",
    "print(res.application)\n",
    "res.dependency_plan\n",
    "# f\"input size [{N}], states checked [{r.steps}], {r.message}, {len(target.requires)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = []\n",
    "NS = Namespace()\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"dna\"))\n",
    "t.AddProduct(_set(\"contigs, asm, annable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "r = t.AddRequirement(_set(\"dna\"))\n",
    "t.AddRequirement(_set(\"contigs, asm\"), {r})\n",
    "t.AddProduct(_set(\"contigs, bin, annable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"annable\"))\n",
    "t.AddRequirement(_set(\"db\"))\n",
    "t.AddProduct(_set(\"ann\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "r = t.AddRequirement(_set(\"db, cog\"))\n",
    "t.AddRequirement(_set(\"ann\"), {r})\n",
    "r = t.AddRequirement(_set(\"db, kegg\"))\n",
    "t.AddRequirement(_set(\"ann\"), {r})\n",
    "t.AddProduct(_set(\"table\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "db1 = t.AddRequirement(_set(\"db, cog\"))\n",
    "db2 = t.AddRequirement(_set(\"db, kegg\"))\n",
    "r = t.AddRequirement(_set(\"contigs, asm\"))\n",
    "t.AddRequirement(_set(\"table\"), {r, db1, db2})\n",
    "r = t.AddRequirement(_set(\"contigs, bin\"))\n",
    "t.AddRequirement(_set(\"table\"), {r, db1, db2})\n",
    "t.AddProduct(_set(\"figure\"))\n",
    "transforms.append(t)\n",
    "\n",
    "# print(t.requires)\n",
    "\n",
    "# haves = [Endpoint(NS, _set(r)) for r in [\n",
    "#     \"reads\",\n",
    "#     \"db, kegg\",\n",
    "# ]]\n",
    "# target = Transform(NS)\n",
    "# r = target.AddRequirement(_set(\"asm\"))\n",
    "# target.AddRequirement(_set(\"ann\"), {r})\n",
    "# r = target.AddRequirement(_set(\"bin\"))\n",
    "# target.AddRequirement(_set(\"ann\"), {r})\n",
    "\n",
    "# res = Solve(haves, target, transforms)\n",
    "\n",
    "\n",
    "\n",
    "haves = [Endpoint(NS, _set(r)) for r in [\n",
    "    \"db, cog\",\n",
    "    \"db, kegg\",\n",
    "    \"dna\",\n",
    "]]\n",
    "\n",
    "target = Transform(NS)\n",
    "target.AddRequirement(_set(\"figure\"))\n",
    "\n",
    "# change to target transform, where inputs are targets\n",
    "#   this captures the required parents better\n",
    "# can use parents in req. to get subtasks (parent -> req. dep.) \n",
    "r = Solve(haves, target, transforms)\n",
    "print(r.steps)\n",
    "for a in r.solution:\n",
    "    print(a)\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # reqs = deque()\n",
    "    # for r in target.requires:\n",
    "    #     reqs.append(r)\n",
    "\n",
    "    # todo: deque[State] = deque()\n",
    "    # todo.append(State(set(given), [], target, [], reqs))\n",
    "    # steps, MAX_S = 0, 5\n",
    "    # while len(todo)>0:\n",
    "    #     steps += 1\n",
    "    #     if steps>MAX_S: \n",
    "    #         print(\"step limit\")\n",
    "    #         return\n",
    "\n",
    "    #     s = todo.popleft()\n",
    "        \n",
    "    #     print(s.target)\n",
    "    #     # print(s.have)\n",
    "    #     for x in s.plan:\n",
    "    #         print(x)\n",
    "    #     print()\n",
    "\n",
    "    #     if len(s.requirements) == 0: return s\n",
    "\n",
    "    #     if isinstance(s.target, Dependency):\n",
    "    #         for e in s.have:\n",
    "    #             if not e.IsA(s.target): continue\n",
    "    #             todo.append(State(\n",
    "    #                 s.have,\n",
    "    #                 [],\n",
    "    #                 s.requirements.popleft(),\n",
    "    #                 s.all_plans+[s.plan+[e]],\n",
    "    #                 s.requirements,\n",
    "    #             ))\n",
    "            \n",
    "    #         for tr in _get_producers_of(s.target):\n",
    "    #             todo.append(State(\n",
    "    #                 s.have,\n",
    "    #                 s.plan + [tr],\n",
    "    #                 tr,\n",
    "    #                 s.all_plans,\n",
    "    #                 s.requirements,\n",
    "    #             ))\n",
    "    #     else:\n",
    "    #         for req in target.requires:\n",
    "    #             if len(req.parents)>0:\n",
    "    #                 continue # figure out later\n",
    "    #             todo.append(State(\n",
    "    #                 s.have,\n",
    "    #                 s.plan + [req],\n",
    "    #                 req,\n",
    "    #                 s.all_plans,\n",
    "    #                 s.requirements\n",
    "    #             ))\n",
    "\n",
    "    # # @dataclass\n",
    "    # # class State:\n",
    "    # #     target: Transform\n",
    "    # #     have: set[Endpoint]\n",
    "    # #     constraints: dict[Dependency, Endpoint]\n",
    "    # #     plan: list[Transform]\n",
    "\n",
    "    # # todo: deque[State] = deque()\n",
    "    # # todo.append(State(target, set(given), {}, []))\n",
    "    # # while len(todo)>0:\n",
    "    # #     s = todo.popleft()\n",
    "    # #     cons = s.constraints\n",
    "        \n",
    "    # #     for tr in transforms:\n",
    "    # #         fwds = tr.Valids(tr.Possibilities(s.have, cons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _apply_one(have: set[Endpoint], tr: Transform, sources: set[Endpoint]):\n",
    "#         match = next(tr.NextValid(tr.Possibilities(have, sources)), None)\n",
    "#         if match is not None:\n",
    "#             return tr.Apply(match)\n",
    "    \n",
    "#     # res = _map()\n",
    "#     # if not res.success: return res\n",
    "\n",
    "\n",
    "        # for e in given if len(sources)==0 else sources:\n",
    "        #     if not e.IsA(target): continue\n",
    "        #     return MapResult([], e)\n",
    "\n",
    "        # if \"sum\" in target.properties and any(\"2\" in s.properties for s in sources):\n",
    "        # if \"sum\" in target.properties:\n",
    "        #     x = 1\n",
    "        #     print(target, sources)\n",
    "\n",
    "        # todo: deque[MapState] = deque()\n",
    "        # todo.append(MapState(given, [], {t for t in transforms}))\n",
    "\n",
    "        # while len(todo)>0:\n",
    "        #     s = todo.popleft()\n",
    "        #     for tr in curr.remaining_transforms:\n",
    "        #         next_step = _apply_one(curr.have, tr)\n",
    "        #         if next_step is None: continue\n",
    "        #             # next_step = _apply_one(curr.have, tr)\n",
    "        #             # if next_step is None: continue\n",
    "        #         for e in next_step.produced:\n",
    "        #             if not e.IsA(target): continue\n",
    "        #             return MapResult(curr.plan+[next_step], e)\n",
    "\n",
    "        #         todo.append(MapState(\n",
    "        #             curr.have | next_step.produced,\n",
    "        #             curr.plan + [next_step],\n",
    "        #             curr.remaining_transforms - {tr}\n",
    "        #         ))\n",
    "\n",
    "#     def _solve_tr(given: set[Endpoint], target: Transform):\n",
    "#         have = set(given)\n",
    "#         plan: list[Application] = []\n",
    "#         dep2ep: dict[Node, Endpoint] = {} # really Dep -> Ep\n",
    "#         dep_parent_sets: dict[Dependency, set[Endpoint]] = {}\n",
    "#         todo: deque[Dependency] = deque()\n",
    "#         for r in target.requires: todo.append(r)\n",
    "#         loop_landmark = None\n",
    "#         while len(todo)>0:\n",
    "#             curr = todo.popleft()\n",
    "#             def _skip():\n",
    "#                 nonlocal loop_landmark\n",
    "#                 if loop_landmark is None: loop_landmark = curr\n",
    "#                 todo.append(curr)\n",
    "\n",
    "#             if loop_landmark is not None and curr == loop_landmark:\n",
    "#                 return Result([], f\"can't make {curr}\", info=have)\n",
    "#             # if any parent not generated, skip for now\n",
    "#             if any(p not in dep2ep for p in curr.parents): _skip(); continue\n",
    "\n",
    "#             if curr not in dep_parent_sets:\n",
    "#                 parents = {dep2ep[p] for p in curr.parents}\n",
    "#                 dep_parent_sets[curr] = parents\n",
    "#             # print(f\"---\",dep_parent_sets)\n",
    "\n",
    "#             # if \"sum\" in curr.properties:\n",
    "#             #     print(curr, dep_parent_sets[curr])\n",
    "#             sol = _solve_dep(have, curr, dep_parent_sets[curr])\n",
    "#             if sol is None: _skip(); continue\n",
    "#             loop_landmark = None\n",
    "\n",
    "#             # print(curr, dep_parent_sets[curr], loop_landmark)\n",
    "#             # print(\">\")\n",
    "#             # print(have)\n",
    "#             # print(todo)\n",
    "#             # print(sol)\n",
    "#             # for a in sol.plan:\n",
    "#             #     print(a)\n",
    "#             # print()\n",
    "\n",
    "#             dep2ep[curr] = sol.endpoint\n",
    "#             for a in sol.plan:\n",
    "#                 have |= a.produced\n",
    "#             plan += sol.plan\n",
    "\n",
    "#     return _solve_tr(set(given), target, set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # sol = res.solution\n",
    "    # last_l = 0\n",
    "    # while last_l != len(sol):\n",
    "    #     last_l = len(sol)\n",
    "    #     used = set()\n",
    "    #     for a in sol:\n",
    "    #         used |= a.used\n",
    "    #     sol = [a for a in sol if a.transform==target or any(e in used for e in a.produced)]\n",
    "    # res.solution = sol    \n",
    "\n",
    "# @dataclass\n",
    "    # class State:\n",
    "    #     have: set[Endpoint]\n",
    "    #     plan: list[Application]\n",
    "    #     usage_sigs: set[str]\n",
    "\n",
    "    # def _local_solve(have: set[Endpoint], target: Dependency):\n",
    "    #     todo: deque[State] = deque()\n",
    "    #     todo.append(State(have, [], set()))\n",
    "    #     MAX_S = 10_000\n",
    "    #     steps = 0\n",
    "    #     # _last_depth = 0\n",
    "    #     while len(todo) > 0:\n",
    "    #         steps += 1\n",
    "    #         if steps>MAX_S: return Result([], \"step limit\", steps, info=todo)\n",
    "    #         curr = todo.popleft()    \n",
    "\n",
    "# @dataclass\n",
    "    # class SubGoal:\n",
    "    #     target: Dependency\n",
    "\n",
    "    # have = set(given)\n",
    "    # dep2endpoint: dict[Dependency, Endpoint] = {}\n",
    "    # todo: deque[SubGoal] = deque()\n",
    "    # for d in target.requires: todo.appendleft(SubGoal(d))\n",
    "    # while len(todo)>0:\n",
    "    #     subgoal = todo.pop()\n",
    "    #     sources: list[Endpoint] = []\n",
    "    #     ok = True\n",
    "    #     for p in subgoal.target.parents:\n",
    "    #         if p not in dep2endpoint:\n",
    "    #             todo.appendleft(subgoal)\n",
    "    #             ok = False; break\n",
    "    #         sources.append(dep2endpoint[p])\n",
    "    #     if not ok: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Apply(self, have: Iterable[Endpoint], use_signatures: set[str]) -> Iterable[Application]:\n",
    "#         matches = self.Possibilities(have)\n",
    "#         if len(matches) == 0: return []\n",
    "\n",
    "#         # can reduce exponential trial here by enforcning the input groups first\n",
    "#         def _possible_configs(i: int, choosen: list[Endpoint]) -> list[list[Endpoint]]:\n",
    "#             if i >= len(self.requires): return [choosen]\n",
    "#             candidates = matches[i]\n",
    "#             parents = self._input_group_map.get(i, [])\n",
    "#             # print(parents, candidates, choosen)\n",
    "#             if len(parents) > 0:\n",
    "#                 for prototype in parents:\n",
    "#                     # parent must be in choosen, since it must have been added\n",
    "#                     # as a req. before being used as a parent\n",
    "#                     parent: None|Endpoint = None\n",
    "#                     for p in choosen:\n",
    "#                         if p.IsA(prototype): parent = p; break\n",
    "#                     if parent is None: return []\n",
    "#                     candidates = [c for c in candidates if parent in c.parents]\n",
    "#             configs = []\n",
    "#             for c in candidates:\n",
    "#                 configs += _possible_configs(i+1, choosen+[c])\n",
    "#             return configs\n",
    "#         configs = _possible_configs(0, [])\n",
    "\n",
    "#         def _same(a: Endpoint, b: Endpoint):\n",
    "#             return a.properties.issubset(b.properties) and b.properties.issubset(a.properties) \\\n",
    "#                 and a.parents.issubset(b.parents) and b.parents.issubset(a.parents)\n",
    "\n",
    "#         for input_set in configs:\n",
    "#             sis = set(input_set)\n",
    "#             sig = self._sig(input_set)\n",
    "#             if sig in use_signatures: continue\n",
    "#             _parents = sis|{p for g in [e.parents for e in input_set] for p in g}\n",
    "#             produced = {\n",
    "#                 Endpoint(\n",
    "#                     namespace=self._ns,\n",
    "#                     properties=out.properties,\n",
    "#                     parents=_parents\n",
    "#                 )\n",
    "#             for out in self.produces}\n",
    "#             # if all(_same(e, p) for e in have for p in produced):\n",
    "#             #     continue\n",
    "#             #     print(have)\n",
    "#             #     print(produced)\n",
    "#             #     print()\n",
    "#             yield Application(self, sis, produced, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # if len(target.parents) == 0:\n",
    "        #     sol = _map_to(have, target)\n",
    "        #     if sol is None: return Result([], \"x\")\n",
    "        #     return Result(sol, success=True)\n",
    "        # else:\n",
    "        #     for p in target.parents:\n",
    "        #         _p: Any = p\n",
    "        #         res = _map_to(have, target, _p)\n",
    "\n",
    "        #         print(\">\",res)\n",
    "        #         have |= {e for g in [a.produced for a in res.solution] for e in g}\n",
    "        #         if not res.success: return res\n",
    "\n",
    "    # have = set(given)\n",
    "    # for d in target.requires:\n",
    "    #     _solve(have, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def Signature(self):\n",
    "    #     cache = self.namespace.node_signatures\n",
    "    #     if self.key not in cache:\n",
    "    #         props = \",\".join(sorted(self.properties))\n",
    "    #         parents = \",\".join(sorted([p.Signature() for p in self.parents]))\n",
    "    #         sig = f\"{props}-{parents}\"\n",
    "    #         cache[self.hash] = sig\n",
    "    #     return cache[self.hash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # def _solve():\n",
    "    #     todo: deque[State] = deque()\n",
    "    #     todo.append(State(set(given), [], set()))\n",
    "    #     MAX_S = 100_000\n",
    "    #     steps = 0\n",
    "    #     # _last_depth = 0\n",
    "    #     while len(todo) > 0:\n",
    "    #         steps += 1\n",
    "    #         if steps>MAX_S: return Result([], \"step limit\", todo, steps)\n",
    "    #         # curr = todo.popleft()\n",
    "    #         curr = todo.pop()\n",
    "\n",
    "    #         final_appl = _check_done(curr)\n",
    "    #         if final_appl is not None: return Result(curr.plan+[final_appl], steps=steps)\n",
    "\n",
    "    #         # _depth = len(curr.plan)\n",
    "    #         # if _depth != _last_depth:\n",
    "    #         #     todo = _deduplicate_states(curr, todo)\n",
    "    #         #     _last_depth = _depth\n",
    "\n",
    "    #         next_states = _get_next_states(curr)\n",
    "    #         for n in next_states:\n",
    "    #             todo.append(n)\n",
    "\n",
    "    #     return Result([], \"no sol\", steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # plans: dict[Endpoint, Path] = {}\n",
    "    # def _path_to(have: Iterable[Endpoint], target: Dependency) -> Path|None:\n",
    "    #     if any(e.IsA(target) for e in have): return Path([])\n",
    "    #     if target in plans: return plans[target]\n",
    "\n",
    "    #     # DFS back from e\n",
    "    #     for tr in transforms:\n",
    "    #         if not any(d.IsA(target) for d in tr.produces): continue \n",
    "    #         for req in tr.requires:\n",
    "    #             path_result = _path_to(have, req)\n",
    "    #             if path_result is None: continue\n",
    "    #             path_result.plan.append(tr)\n",
    "    #             return path_result\n",
    "    # x = [\n",
    "    # # @dataclass\n",
    "    # # class State:\n",
    "    # #     have: Iterable[Endpoint]\n",
    "    # #     targets: Iterable[Dependency]\n",
    "    # #     plan: list[Transform]\n",
    "\n",
    "    # # todo: deque[State] = deque(maxlen=64)\n",
    "    # # todo.append(State([], [t for t in target.requires], []))\n",
    "    # # while len(todo)>0:\n",
    "    # #     _s = todo.popleft()\n",
    "    # #     t = next(iter(_s.targets))\n",
    "    # #     plan = \n",
    "    # ]\n",
    "\n",
    "    # usage_signatures: dict[Transform, set[str]] = {t:set() for t in transforms}\n",
    "    # def _solve(have: list[Endpoint], target: Transform, sigs: dict) -> list[Application]|None:\n",
    "    #     possibilities = target.Apply(have, sigs[target])\n",
    "    #     if len(possibilities)>0: return possibilities[0:1]\n",
    "\n",
    "    #     for t in target.requires:\n",
    "    #         path = _path_to(have, t)\n",
    "    #         if path is None: return None\n",
    "    #         fist_tr = path.plan[0]\n",
    "    #         poss = fist_tr.Apply(have, sigs[fist_tr])\n",
    "    #         if poss\n",
    "                        \n",
    "            \n",
    "\n",
    "\n",
    "    # _solve(list(given), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Solve(given: Iterable[Endpoint], target: Transform, transforms: Iterable[Transform]):\n",
    "#     @dataclass\n",
    "#     class State:\n",
    "#         have: list[Endpoint]\n",
    "#         usage_signatures: dict[int, set[str]]\n",
    "#         plan: list[Application]\n",
    "\n",
    "#     transforms = list(transforms)\n",
    "    \n",
    "#     def _done(state: State):\n",
    "#         appl = target.Apply(state.have, set())\n",
    "#         return appl \n",
    "\n",
    "#     def _solve() -> Result:\n",
    "#         MAXS = 10_000\n",
    "#         todo: deque[State] = deque([State(\n",
    "#             have = list(given),\n",
    "#             plan = [],\n",
    "#             usage_signatures={},\n",
    "#         )], maxlen=MAXS)\n",
    "        \n",
    "\n",
    "#         def _deduplicate_states(current: State):\n",
    "#             def _get_sig(s: State):\n",
    "#                 haves_sig = '|'.join([e.Signature() for e in s.have])\n",
    "#                 return haves_sig\n",
    "#             seen = {_get_sig(current)}\n",
    "#             new_todo: deque[State] = deque([], MAXS)\n",
    "#             for s in todo:\n",
    "#                 if _get_sig(s) in seen: continue\n",
    "#                 new_todo.append(s)\n",
    "\n",
    "#             if len(todo) != len(new_todo):\n",
    "#                 for s in todo:\n",
    "#                     print(s)\n",
    "#                 print(\"-\")\n",
    "#                 for s in new_todo:\n",
    "#                     print(s)\n",
    "#                 print()\n",
    "#             return new_todo\n",
    "\n",
    "#         _steps = 0\n",
    "#         _empty = set()\n",
    "#         _last_depth = 0\n",
    "#         while len(todo)>0:\n",
    "#             _steps += 1\n",
    "#             if _steps > MAXS: return Result([], f\"step limit exceeded\", steps=_steps)\n",
    "#             _s = todo.popleft()\n",
    "\n",
    "#             _target_applications = target.Apply(_s.have, _empty)\n",
    "#             if len(_target_applications)>0:\n",
    "#                 return Result(solution=_s.plan+[_target_applications[0]], steps=_steps)\n",
    "\n",
    "#             _depth = len(_s.plan)\n",
    "#             if _depth != _last_depth:\n",
    "#                 todo = _deduplicate_states(_s)\n",
    "#                 _last_depth = _depth\n",
    "\n",
    "#             if _done(_s): return Result(_s.plan, steps=_steps)\n",
    "#             for tr in transforms:\n",
    "#                 possibilities = tr.Apply(_s.have, _s.usage_signatures.get(tr.hash, set()))\n",
    "#                 # for app in possibilities:\n",
    "#                 #     usage_sigs = _s.usage_signatures.copy()\n",
    "#                 #     usage_sigs[tr.hash] = usage_sigs.get(tr.hash, set())|{app.signature}\n",
    "#                 #     todo.append(State(\n",
    "#                 #         have = _s.have+app.produced,\n",
    "#                 #         plan = _s.plan+[app],\n",
    "#                 #         usage_signatures = usage_sigs,\n",
    "#                 #     ))\n",
    "\n",
    "#                 if len(possibilities) == 0: continue\n",
    "#                 usage_sigs = _s.usage_signatures.copy()\n",
    "#                 new_have = _s.have.copy()\n",
    "#                 for app in possibilities:\n",
    "#                     usage_sigs[tr.hash] = usage_sigs.get(tr.hash, set())|{app.signature}\n",
    "#                     new_have += app.produced\n",
    "#                 todo.append(State(\n",
    "#                     have = new_have,\n",
    "#                     plan = _s.plan+possibilities,\n",
    "#                     usage_signatures=usage_sigs\n",
    "#                 ))\n",
    "#         return Result([], f\"ran out of things to try\", steps = _steps)\n",
    "    \n",
    "#     res = _solve()\n",
    "#     sol = res.solution\n",
    "#     last_l = 0\n",
    "#     while last_l != len(sol):\n",
    "#         last_l = len(sol)\n",
    "#         used = set()\n",
    "#         for a in sol:\n",
    "#             used |= a.used\n",
    "#         sol = [a for a in sol if a.transform==target or any(e in used for e in a.produced)]\n",
    "#     res.solution = sol\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import annotations\n",
    "# import os, sys\n",
    "# import asyncio\n",
    "# from typing import Iterable, Callable, Any\n",
    "# from pathlib import Path\n",
    "\n",
    "# from limes_x.solver import DependencySolver, Plan, Dependency\n",
    "# from limes_x.persistence import ProjectState, Instance\n",
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# mpath = Path(\"./test_solver/\")\n",
    "# modules = [\n",
    "#     ComputeModule(mpath.joinpath(d)) for d in os.listdir(mpath)\n",
    "# ]\n",
    "# print(modules)\n",
    "\n",
    "# given = [\n",
    "#     (\"a\", \"./test_data/a1\"),\n",
    "#     (\"a\", \"./test_data/a2\"),\n",
    "#     (\"b\", \"./test_data/b1\"),\n",
    "# ]\n",
    "\n",
    "# prj_path = \"./cache/man_test01/\"\n",
    "# state = ProjectState(prj_path, on_exist=\"overwrite\")\n",
    "# for dtype, val in given:\n",
    "#     state.RegisterInstance(Instance.Str(dtype, val))\n",
    "# for m in modules:\n",
    "#     state.RegisterInstance(Instance.ComputeModule(m))\n",
    "\n",
    "# deps = []\n",
    "# for k, inst in state._instances.items():\n",
    "#     if not inst.IsPyType(ComputeModule): continue\n",
    "#     deps.append(Dependency(inst.val.requires, inst.val.produces, k))\n",
    "\n",
    "# solver = DependencySolver(deps)\n",
    "# # plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan = solver.Solve({\"a\"}, {\"branched\"})\n",
    "# assert plan != False\n",
    "# [state.GetInstance(m.ref_key) for m in plan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_dependency(module: ComputeModule):\n",
    "#     return Dependency(module.requires, module.produces, module)\n",
    "\n",
    "# modules = Path(\"./test_solver/\")\n",
    "# solver = Plan([\n",
    "#     make_dependency(ComputeModule(p))\n",
    "# for p in [\n",
    "#     modules.joinpath(p) for p in os.listdir(modules)\n",
    "# ]])\n",
    "# plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# a = ComputeModule(\"./test_modules/copy/\")\n",
    "# b = ComputeModule(\"./test_modules/copy2/\")\n",
    "\n",
    "# a.requires, b.requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = ProjectState(\"./cache/test_persist\")\n",
    "# ok = Instance(\"asdf\", 1)\n",
    "# ov = Instance(\"s\", 2)\n",
    "# state._lineage[ok] = [ov]\n",
    "# state.Save()\n",
    "\n",
    "# s2 = ProjectState.Load(\"./cache/test_persist\")\n",
    "# for k, v in s2._lineage.items():\n",
    "#     _te = k.type, k.value, ok == k, [(i.type, i.value, i == ov) for i in v]\n",
    "#     print(_te)\n",
    "\n",
    "# ok._id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
