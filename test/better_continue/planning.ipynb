{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1 solutions',\n",
       " [{dna}->{annable-contigs-asm} || (c000:dna) >> (l000:annable-contigs-asm),\n",
       "  {dna},{contigs-asm}->{annable-bin-contigs} || (c000:dna),(l000:annable-contigs-asm) >> (m000:annable-bin-contigs),\n",
       "  {db},{annable}->{ann} || (a000:db-cog),(l000:annable-contigs-asm) >> (n000:ann),\n",
       "  {db},{annable}->{ann} || (b000:kegg-db),(l000:annable-contigs-asm) >> (o000:ann),\n",
       "  {annable},{db-cog},{ann},{kegg-db},{ann}->{table} || (l000:annable-contigs-asm),(a000:db-cog),(n000:ann),(b000:kegg-db),(o000:ann) >> (r000:table),\n",
       "  {db},{annable}->{ann} || (a000:db-cog),(m000:annable-bin-contigs) >> (p000:ann),\n",
       "  {db},{annable}->{ann} || (b000:kegg-db),(m000:annable-bin-contigs) >> (q000:ann),\n",
       "  {annable},{db-cog},{ann},{kegg-db},{ann}->{table} || (m000:annable-bin-contigs),(a000:db-cog),(p000:ann),(b000:kegg-db),(q000:ann) >> (s000:table),\n",
       "  {db-cog},{kegg-db},{contigs-asm},{bin-contigs},{table},{table}->{figure} || (a000:db-cog),(b000:kegg-db),(l000:annable-contigs-asm),(m000:annable-bin-contigs),(r000:table),(s000:table) >> (t000:figure),\n",
       "  {figure}-> || (t000:figure) >> ])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "import os, sys\n",
    "from typing import Any, Generator, Iterable, Literal\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import deque\n",
    "\n",
    "from limes_x.utils import KeyGenerator\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self) -> None:\n",
    "        self.node_signatures: dict[int, str] = {}\n",
    "        self._last_k: int = 0\n",
    "        self._kg = KeyGenerator(True)\n",
    "        self._KLEN = 4\n",
    "        self._MAX_K = len(self._kg.vocab)**self._KLEN\n",
    "\n",
    "    def NewKey(self):\n",
    "        self._last_k += 1\n",
    "        assert self._last_k < self._MAX_K\n",
    "        return self._last_k, self._kg.FromInt(self._last_k, self._KLEN)\n",
    "\n",
    "class Hashable:\n",
    "    def __init__(self, ns: Namespace) -> None:\n",
    "        self.namespace = ns\n",
    "        self.hash, self.key = ns.NewKey()\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return self.hash\n",
    "    \n",
    "    def __eq__(self, __value: object) -> bool:\n",
    "        K = \"key\"\n",
    "        return hasattr(__value, K) and self.key == getattr(__value, K)\n",
    "\n",
    "class Node(Hashable):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ns: Namespace,\n",
    "        properties: set[str],\n",
    "        parents: set[Node],\n",
    "    ) -> None:\n",
    "        super().__init__(ns)\n",
    "        self.namespace = ns\n",
    "        self.properties = properties\n",
    "        self.parents = parents\n",
    "        self._sig: str|None = None\n",
    "        # self._diffs = set()\n",
    "        # self._sames = set()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"({self.key}:{'-'.join(self.properties)})\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self}\"\n",
    "    \n",
    "    def IsA(self, other: Node) -> bool:\n",
    "        # if other.key in self._diffs: return False\n",
    "        # if other.key in self._sames: return True\n",
    "        if not other.properties.issubset(self.properties):\n",
    "            # self._diffs.add(other.key)\n",
    "            return False\n",
    "        # self._sames.add(other.key)\n",
    "        # if compare_lineage: return  other.parents.issubset(self.parents)\n",
    "        return True\n",
    "\n",
    "    def Signature(self):\n",
    "        if self._sig is None:\n",
    "            psig = \",\".join(sorted(p.Signature() for p in self.parents))\n",
    "            sig = \",\".join(sorted(self.properties))\n",
    "            self._sig = f'{sig}:[{psig}]' if len(self.parents)>0 else sig\n",
    "        return self._sig\n",
    "\n",
    "class Dependency(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: set[Node]) -> None:\n",
    "        super().__init__(namespace, properties, parents)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"(D:{'-'.join(self.properties)})\"\n",
    "    \n",
    "class Endpoint(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: dict[Endpoint, Node]=dict()) -> None:\n",
    "        super().__init__(namespace, properties, set(parents))\n",
    "        self._parent_map = parents # real, proto\n",
    "\n",
    "    def Iterparents(self):\n",
    "        \"\"\"real, prototype\"\"\"\n",
    "        for e, p in self._parent_map.items():\n",
    "            yield e, p\n",
    "\n",
    "class Transform(Hashable):\n",
    "    def __init__(self, ns: Namespace) -> None:\n",
    "        super().__init__(ns)\n",
    "        self.requires: list[Dependency] = list()\n",
    "        self.produces: list[Dependency] = list()\n",
    "        self._ns = ns\n",
    "        self._input_group_map: dict[int, list[Dependency]] = {}\n",
    "        self._key = ns.NewKey()\n",
    "        self._seen: set[str] = set()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        def _props(d: Dependency):\n",
    "            return \"{\"+\"-\".join(d.properties)+\"}\"\n",
    "        return f\"{','.join(_props(r) for r in self.requires)}->{','.join(_props(p) for p in self.produces)}\"\n",
    "\n",
    "    def __repr__(self): return f\"{self}\"\n",
    "\n",
    "    def AddRequirement(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.requires, properties, parents)\n",
    "\n",
    "    def AddProduct(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.produces, properties, parents)\n",
    "\n",
    "    def _add_dependency(self, destination: list[Dependency], properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        _parents: Any = parents\n",
    "        _dep = Dependency(properties=set(properties), parents=_parents, namespace=self._ns)\n",
    "        # assert not any(e.IsA(_dep) for e in destination), f\"prev. dep ⊆ new dep\"\n",
    "        # assert not any(_dep.IsA(e) for e in destination), f\"new dep ⊆ prev. dep \"\n",
    "        # destination.add(_dep)\n",
    "        destination.append(_dep)\n",
    "        if destination == self.requires:\n",
    "            i = len(self.requires)-1\n",
    "            for p in _parents:\n",
    "                assert p in self.requires, f\"{p} not added as a requirement\"\n",
    "            self._input_group_map[i] = self._input_group_map.get(i, [])+list(_parents)\n",
    "        return _dep\n",
    "\n",
    "    def _sig(self, endpoints: Iterable[Endpoint]):\n",
    "        # return \"\".join(e.key for e in endpoints)\n",
    "        return self.key+\"-\"+ \"\".join(e.key for e in endpoints)\n",
    "\n",
    "    # just all possibilities regardless of lineage\n",
    "    def Possibilities(self, have: set[Endpoint], constraints: dict[Dependency, Endpoint]=dict()) -> Generator[list[Endpoint], Any, None]:\n",
    "        matches: list[list[Endpoint]] = []\n",
    "        constraints_used = False\n",
    "        for req in self.requires:\n",
    "            if req in constraints:\n",
    "                must_use = constraints[req]\n",
    "                _m = [must_use]\n",
    "            else:\n",
    "                _m = [m for m in have if m.IsA(req)]\n",
    "            if len(_m) == 0: return None\n",
    "            matches.append(_m)\n",
    "        if len(constraints)>0 and not constraints_used: return None\n",
    "\n",
    "        indexes = [0]*len(matches)\n",
    "        indexes[0] = -1\n",
    "        def _advance():\n",
    "            i = 0\n",
    "            while True:\n",
    "                indexes[i] += 1\n",
    "                if indexes[i] < len(matches[i]): return True\n",
    "                indexes[i] = 0\n",
    "                i += 1\n",
    "                if i >= len(matches): return False\n",
    "        while _advance():\n",
    "            yield [matches[i][j] for i, j in enumerate(indexes)]\n",
    "    \n",
    "    # filter possibilities based on correct lineage\n",
    "    def Valids(self, matches: Iterable[list[Endpoint]]):\n",
    "        black_list: set[tuple[int, Endpoint]] = set()\n",
    "        white_list: set[tuple[int, Endpoint]] = set()\n",
    "\n",
    "        choosen: list[Endpoint] = []\n",
    "        for config in matches:\n",
    "            ok = True\n",
    "            for i, (e, r) in enumerate(zip(config, self.requires)):\n",
    "                k = (i, e)\n",
    "                if k in black_list: ok=False; break\n",
    "                if k in white_list: continue\n",
    "                \n",
    "                parents = self._input_group_map.get(i, [])\n",
    "                if len(parents) == 0: # no lineage req.\n",
    "                    white_list.add(k)\n",
    "                    continue\n",
    "                \n",
    "                for prototype in parents:\n",
    "                    # parent must already be in choosen, since it must have been added\n",
    "                    # as a req. before being used as a parent during setup\n",
    "                    found = False\n",
    "                    for p in choosen:\n",
    "                        if not p.IsA(prototype): continue\n",
    "                        if p in e.parents: found=True; break\n",
    "                    if not found: black_list.add(k); ok=False; break\n",
    "                if not ok: break\n",
    "            if ok: yield config\n",
    "\n",
    "    def Apply(self, inputs: Iterable[tuple[Endpoint, Node]]):\n",
    "        for r, (e, e_proto) in zip(self.requires, inputs):\n",
    "            assert e.IsA(r), f\"{e_proto}, {e}, {r}\"\n",
    "\n",
    "        inputs_dict = dict(inputs)\n",
    "        parent_dict: dict[Any, Any] = {}\n",
    "        for e, _ in inputs_dict.items():\n",
    "            for p, pproto in e.Iterparents():\n",
    "                if p in parent_dict: continue\n",
    "                parent_dict[p] = pproto\n",
    "        for e, eproto in inputs_dict.items():\n",
    "            parent_dict[e] = eproto\n",
    "        produced = {\n",
    "            Endpoint(\n",
    "                namespace=self._ns,\n",
    "                properties=out.properties,\n",
    "                parents=parent_dict\n",
    "            ):out\n",
    "        for out in self.produces}\n",
    "        return Application(self, inputs_dict, produced)\n",
    "\n",
    "@dataclass\n",
    "class Application:\n",
    "    transform: Transform\n",
    "    used: dict[Endpoint, Node]\n",
    "    produced: dict[Endpoint, Dependency]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.transform} || {','.join(str(e) for e in self.used.keys())} >> {','.join(str(e) for e in self.produced)}\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self}\"\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    steps: int\n",
    "\n",
    "@dataclass\n",
    "class TrResult(Result):\n",
    "    application: Application\n",
    "    dependency_plan: list[Application]\n",
    "    \n",
    "@dataclass\n",
    "class DepResult(Result):\n",
    "    plan: list[Application]\n",
    "    endpoint: Endpoint\n",
    "\n",
    "def Solve(given: Iterable[Endpoint], target: Transform, transforms: Iterable[Transform]):\n",
    "    @dataclass\n",
    "    class State:\n",
    "        have: dict[Endpoint, Dependency]\n",
    "        target: Dependency|Transform\n",
    "        lineage_requirements: dict[Node, Endpoint]\n",
    "        depth: int\n",
    "\n",
    "    def _get_producers_of(target: Dependency):\n",
    "        for tr in transforms:\n",
    "            for p in tr.produces:\n",
    "                if p.IsA(target):\n",
    "                    yield tr\n",
    "                    break\n",
    "\n",
    "    # if DEBUG: debug_print = lambda *args: None\n",
    "    # if DEBUG: debug_print = lambda *args: None\n",
    "    DEBUG = True\n",
    "    # DEBUG = False\n",
    "    log = open(\"debug_log.txt\", \"w\")\n",
    "    debug_print = lambda *args: log.write(\" \".join(str(a) for a in args)+\"\\n\") if args[0] != \"END\" else log.close()\n",
    "\n",
    "    _apply_cache: dict[str, Application] = {}\n",
    "    def _apply(target: Transform, inputs: Iterable[tuple[Endpoint, Node]]):\n",
    "        sig  = \"\".join(e.key+d.key for e, d in inputs)\n",
    "        if sig in _apply_cache:\n",
    "            return _apply_cache[sig]\n",
    "        appl = target.Apply(inputs)\n",
    "        _apply_cache[sig] = appl\n",
    "        return appl\n",
    "\n",
    "    def _satisfies_lineage(tproto: Dependency, candidate: Endpoint):\n",
    "        for tp_proto in tproto.parents:\n",
    "            if all(not p.IsA(tp_proto) for p, _ in candidate.Iterparents()):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    HORIZON=64\n",
    "    def _solve_dep(s: State) -> list[DepResult]:\n",
    "        if s.depth >= HORIZON:\n",
    "            if DEBUG: debug_print(f\" <-  HORIZON\", s.depth)\n",
    "            return []\n",
    "        target: Any = s.target\n",
    "        assert isinstance(target, Dependency), f\"{s.target}, not dep\"\n",
    "        if DEBUG: debug_print(f\" ->\", s.target, s.lineage_requirements)\n",
    "        if DEBUG: debug_print(f\"   \", s.have.keys())\n",
    "\n",
    "        candidates:list[DepResult] = []\n",
    "        for e, eproto in s.have.items():\n",
    "            if not e.IsA(target): continue\n",
    "            acceptable = True\n",
    "            for rproto, r in s.lineage_requirements.items():\n",
    "                if e == r: continue\n",
    "                if eproto.IsA(rproto): # e is protype, but explicitly breaks lineage\n",
    "                    acceptable=False; break\n",
    "\n",
    "                for p, pproto in e.Iterparents():\n",
    "                    if rproto.IsA(pproto):\n",
    "                        if p != r:\n",
    "                            acceptable=False; break\n",
    "\n",
    "            if not acceptable:\n",
    "                continue\n",
    "            else:\n",
    "                if DEBUG: debug_print(f\"    ^candidate\", e, eproto, e.parents)\n",
    "                if DEBUG: debug_print(f\"    ^reqs.    \", s.lineage_requirements)\n",
    "                candidates.append(DepResult(0, [], e))\n",
    "            # elif quality == 2:\n",
    "            #     if DEBUG: debug_print(f\" <-\", s.target, e, \"DIRECT\")\n",
    "            #     return [DepResult(0, [], e)]\n",
    "\n",
    "        def _add_result(res: TrResult):\n",
    "            ep: Endpoint|None = None\n",
    "            for e in res.application.produced:\n",
    "                if e.IsA(target):\n",
    "                    ep = e; break\n",
    "            assert isinstance(ep, Endpoint)\n",
    "            if not _satisfies_lineage(target, ep): return\n",
    "            candidates.append(DepResult(\n",
    "                res.steps,\n",
    "                res.dependency_plan+[res.application],\n",
    "                ep,\n",
    "            ))\n",
    "\n",
    "        for tr in _get_producers_of(target):\n",
    "            results = _solve_tr(State(s.have, tr, s.lineage_requirements, s.depth))\n",
    "            for res in results:\n",
    "                _add_result(res)\n",
    "\n",
    "        if DEBUG: debug_print(f\" <-\", s.target, f\"{len(candidates)} sol.\", candidates[0].endpoint if len(candidates)>0 else None)\n",
    "        return candidates\n",
    "\n",
    "    _transform_cache: dict[str, list[TrResult]] = {}\n",
    "    def _solve_tr(s: State) -> list[TrResult]:\n",
    "        assert isinstance(s.target, Transform), f\"{s.target} not tr\"\n",
    "        if DEBUG: debug_print(f\">>>{s.depth:02}\", s.target, s.lineage_requirements)\n",
    "        for h in s.have:\n",
    "            if DEBUG: debug_print(f\"      \", h)\n",
    "\n",
    "        # memoization\n",
    "        sig = \"\".join(e.key for e in s.have)\n",
    "        sig += f\":{s.target.key}\"\n",
    "        sig += \":\"+\"\".join(e.key for e in s.lineage_requirements.values())\n",
    "        if sig in _transform_cache:\n",
    "            if DEBUG: debug_print(f\"<<<{s.depth:02} CACHED: {len(_transform_cache[sig])} solutions\")\n",
    "            return _transform_cache[sig]\n",
    "        \n",
    "        plans: list[list[DepResult]] = []\n",
    "        for i, req in enumerate(s.target.requires):\n",
    "            req_p = {}\n",
    "            for proto, e in s.lineage_requirements.items():\n",
    "                if req.IsA(proto): continue\n",
    "                req_p[proto] = e\n",
    "\n",
    "            results = _solve_dep(State(s.have, req, req_p, s.depth+1))\n",
    "            \n",
    "            if len(results) == 0:\n",
    "                if DEBUG: debug_print(f\"<<< FAIL\", s.target, req)\n",
    "                return []\n",
    "            else:\n",
    "                plans.append(results)\n",
    "\n",
    "        def _iter_plans():\n",
    "            indexes = [0]*len(plans)\n",
    "            indexes[0] = -1\n",
    "            def _advance():\n",
    "                i = 0\n",
    "                while True:\n",
    "                    indexes[i] += 1\n",
    "                    if indexes[i] < len(plans[i]): return True\n",
    "                    indexes[i] = 0\n",
    "                    i += 1\n",
    "                    if i >= len(plans): return False\n",
    "            while _advance():\n",
    "                yield [plans[i][j] for i, j in enumerate(indexes)]\n",
    "\n",
    "        target: Transform = s.target\n",
    "        def _iter_satisfies():\n",
    "            input_sigs = set()\n",
    "            if DEBUG: debug_print(f\"    #\", s.lineage_requirements)\n",
    "            for i, inputs in enumerate(_iter_plans()):\n",
    "                sig = \"\".join(e.endpoint.key for e in inputs)\n",
    "                if sig in input_sigs: continue\n",
    "                input_sigs.add(sig)\n",
    "                if DEBUG: debug_print(f\"    .\", i+1)\n",
    "\n",
    "                deps: dict[Node, Endpoint] = {}\n",
    "                _fail = False\n",
    "                used: set[Endpoint] = set()\n",
    "                for res, req in zip(inputs, target.requires):\n",
    "                    if DEBUG: debug_print(f\"          \", deps)\n",
    "                    if DEBUG: debug_print(f\"    ___\", req, req.parents)\n",
    "                    if DEBUG: debug_print(f\"        __\", res.endpoint, list(res.endpoint.Iterparents()))\n",
    "                    if res.endpoint in used:\n",
    "                        if DEBUG: debug_print(f\"    ___ FAIL: duplicate input\", res.endpoint)\n",
    "                        _fail=True; break\n",
    "                    used.add(res.endpoint)\n",
    "\n",
    "                    if not _satisfies_lineage(req, res.endpoint):\n",
    "                        if DEBUG: debug_print(f\"    ___ FAIL: unsatisfied lineage\", req)\n",
    "                        _fail=True; break\n",
    "\n",
    "                    for rproto in req.parents:\n",
    "                        r = deps[rproto]\n",
    "                        # if all(not p.IsA(rproto) for p, pproto in res.endpoint.Iterparents()):\n",
    "                        #     if DEBUG: debug_print(f\"    ___ FAIL: unsatisfied lineage\", rproto)\n",
    "                        #     _fail=True; break\n",
    "                        res_parents = list(res.endpoint.Iterparents())\n",
    "                        res_parents.reverse()\n",
    "                        for p, pproto in res_parents:\n",
    "                            if not p.IsA(rproto): continue\n",
    "                            if p!=r:\n",
    "                                if DEBUG: debug_print(f\"    ___ FAIL: lineage mismatch\", p, r)\n",
    "                                _fail=True; break\n",
    "                            else:\n",
    "                                break # in the case of asm -> bin, the closest ancestor takes priority\n",
    "                        if _fail: break\n",
    "                    if _fail: break\n",
    "\n",
    "                    deps[req] = res.endpoint\n",
    "                if _fail:\n",
    "                    continue\n",
    "                if DEBUG: debug_print(f\"    ___ KEPT\")\n",
    "                yield inputs\n",
    "\n",
    "        if DEBUG: debug_print(f\"<<<{s.depth:02}\", s.target, s.lineage_requirements)\n",
    "        if DEBUG: debug_print(f\"     \", [len(x) for x in plans])\n",
    "        solutions: list[TrResult] = []\n",
    "        for inputs in _iter_satisfies():\n",
    "            my_appl = _apply(s.target, [(res.endpoint, req) for req, res in zip(s.target.requires, inputs)])\n",
    "            consolidated_plan: list[Application] = []\n",
    "            produced_sigs: set[str] = {p.Signature() for p in my_appl.produced}\n",
    "            # if DEBUG: debug_print(f\"   __\", my_appl)\n",
    "            for res in inputs:\n",
    "                for appl in res.plan:\n",
    "                    if all(p.Signature() in produced_sigs for p in appl.produced): continue\n",
    "                    consolidated_plan.append(appl)\n",
    "                    produced_sigs = produced_sigs.union(p.Signature() for p in appl.produced)\n",
    "            solutions.append(TrResult(\n",
    "                len(consolidated_plan),\n",
    "                my_appl,\n",
    "                consolidated_plan,\n",
    "            ))\n",
    "            # if DEBUG: debug_print(f\"    *\", my_appl)\n",
    "            # if DEBUG: debug_print(f\"     \", [res.endpoint for res in inputs])\n",
    "            # if DEBUG: debug_print(f\"    .\", target.requires)\n",
    "            # for appl in consolidated_plan:\n",
    "            #     if DEBUG: debug_print(f\"    __\", appl)\n",
    "        if DEBUG: debug_print(f\"     \", f\"{len(solutions)} sol.\", solutions[0].application.produced if len(solutions)>0 else None)\n",
    "        solutions = sorted(solutions, key=lambda s: s.steps)\n",
    "        _transform_cache[sig] = solutions\n",
    "        return solutions\n",
    "\n",
    "    input_tr = Transform(target._ns)\n",
    "    given_dict = {g:input_tr.AddProduct(g.properties) for g in given}\n",
    "    res = _solve_tr(State(given_dict, target, {}, 0))\n",
    "    if DEBUG: debug_print(\"END\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def _set(s: str):\n",
    "    return set(s.split(\", \"))\n",
    " \n",
    "transforms = []\n",
    "NS = Namespace()\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"dna\"))\n",
    "t.AddProduct(_set(\"contigs, asm, annable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "r = t.AddRequirement(_set(\"dna\"))\n",
    "t.AddRequirement(_set(\"contigs, asm\"), {r})\n",
    "t.AddProduct(_set(\"contigs, bin, annable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"db\"))\n",
    "t.AddRequirement(_set(\"annable\"))\n",
    "t.AddProduct(_set(\"ann\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "ann = t.AddRequirement(_set(\"annable\"))\n",
    "r = t.AddRequirement(_set(\"db, cog\"))\n",
    "t.AddRequirement(_set(\"ann\"), {r, ann})\n",
    "r = t.AddRequirement(_set(\"db, kegg\"))\n",
    "t.AddRequirement(_set(\"ann\"), {r, ann})\n",
    "t.AddProduct(_set(\"table\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "db1 = t.AddRequirement(_set(\"db, cog\"))\n",
    "db2 = t.AddRequirement(_set(\"db, kegg\"))\n",
    "asm = t.AddRequirement(_set(\"contigs, asm\"))\n",
    "bin = t.AddRequirement(_set(\"contigs, bin\"))\n",
    "# t.AddRequirement(_set(\"ann\"), {asm, db1})\n",
    "# t.AddRequirement(_set(\"ann\"), {asm, db2})\n",
    "# t.AddRequirement(_set(\"ann\"), {bin, db1})\n",
    "# t.AddRequirement(_set(\"ann\"), {bin, db2})\n",
    "t.AddRequirement(_set(\"table\"), {asm, db1, db2})\n",
    "t.AddRequirement(_set(\"table\"), {bin, db1, db2})\n",
    "t.AddProduct(_set(\"figure\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"precog\"))\n",
    "t.AddProduct(_set(\"db, cog\"))\n",
    "transforms.append(t)\n",
    "\n",
    "# t = Transform(NS)\n",
    "# t.AddRequirement(_set(\"prekegg\"))\n",
    "# t.AddProduct(_set(\"db, kegg\"))\n",
    "# transforms.append(t)\n",
    "\n",
    "##############\n",
    "# failing because lineage requirement may be split, thus relieving some inputs of lineage\n",
    "# but can't proceed if the first input must be relieved by the following inputs\n",
    "# which can't run becuase they \"depend\" on the first input\n",
    "# todo: look ahead (no pathing, so fast) to determine which inputs can be relieved\n",
    "##############\n",
    "\n",
    "\n",
    "haves = [Endpoint(NS, _set(r)) for r in [\n",
    "    # \"precog\",\n",
    "    \"db, cog\",\n",
    "    \"db, kegg\",\n",
    "    \"dna\",\n",
    "]]\n",
    "\n",
    "target = Transform(NS)\n",
    "# r = target.AddRequirement(_set(\"bin\"))\n",
    "# db = target.AddRequirement(_set(\"cog\"))\n",
    "# target.AddRequirement(_set(\"ann\"), {db, r})\n",
    "# target.AddRequirement(_set(\"ann\"), {db})\n",
    "\n",
    "# r = target.AddRequirement(_set(\"bin\"))\n",
    "# target.AddRequirement(_set(\"table\"), {r})\n",
    "\n",
    "target.AddRequirement(_set(\"figure\"))\n",
    "\n",
    "solutions = None\n",
    "def _test():\n",
    "    global solutions\n",
    "    solutions = Solve(haves, target, transforms)\n",
    "    for res in solutions:\n",
    "        print(res.steps)\n",
    "        return f\"{len(solutions)} solutions\", res.dependency_plan+[res.application]\n",
    "    # if res is not None:\n",
    "_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dna}->{annable-contigs-asm} || (c000:dna) >> (l000:annable-contigs-asm)\n",
      "{dna},{contigs-asm}->{annable-bin-contigs} || (c000:dna),(l000:annable-contigs-asm) >> (m000:annable-bin-contigs)\n",
      "{db},{annable}->{ann} || (a000:db-cog),(l000:annable-contigs-asm) >> (n000:ann)\n",
      "{db},{annable}->{ann} || (b000:kegg-db),(l000:annable-contigs-asm) >> (o000:ann)\n",
      "{annable},{db-cog},{ann},{kegg-db},{ann}->{table} || (l000:annable-contigs-asm),(a000:db-cog),(n000:ann),(b000:kegg-db),(o000:ann) >> (r000:table)\n",
      "{db},{annable}->{ann} || (a000:db-cog),(m000:annable-bin-contigs) >> (p000:ann)\n",
      "{db},{annable}->{ann} || (b000:kegg-db),(m000:annable-bin-contigs) >> (q000:ann)\n",
      "{annable},{db-cog},{ann},{kegg-db},{ann}->{table} || (m000:annable-bin-contigs),(a000:db-cog),(p000:ann),(b000:kegg-db),(q000:ann) >> (s000:table)\n",
      "{db-cog},{kegg-db},{contigs-asm},{bin-contigs},{table},{table}->{figure} || (a000:db-cog),(b000:kegg-db),(l000:annable-contigs-asm),(m000:annable-bin-contigs),(r000:table),(s000:table) >> (t000:figure)\n",
      "{figure}-> || (t000:figure) >> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for res in solutions:\n",
    "    for a in res.dependency_plan:\n",
    "        print(a)\n",
    "    print(res.application)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         25653 function calls (23079 primitive calls) in 0.010 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     4658    0.001    0.000    0.003    0.000 562999156.py:256(<genexpr>)\n",
      "       26    0.001    0.000    0.007    0.000 562999156.py:373(_iter_satisfies)\n",
      "4066/1570    0.001    0.000    0.004    0.000 {method 'join' of 'str' objects}\n",
      "     1301    0.001    0.000    0.005    0.000 562999156.py:256(<lambda>)\n",
      "     1300    0.001    0.000    0.001    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "     1495    0.000    0.000    0.001    0.000 562999156.py:55(__repr__)\n",
      "     1843    0.000    0.000    0.000    0.000 562999156.py:87(Iterparents)\n",
      "     1302    0.000    0.000    0.001    0.000 562999156.py:52(__str__)\n",
      "     1122    0.000    0.000    0.000    0.000 562999156.py:79(__str__)\n",
      "      9/1    0.000    0.000    0.009    0.009 562999156.py:329(_solve_tr)\n",
      "      336    0.000    0.000    0.001    0.000 562999156.py:267(_satisfies_lineage)\n",
      "      4/1    0.000    0.000    0.010    0.010 {built-in method builtins.exec}\n",
      "      552    0.000    0.000    0.000    0.000 562999156.py:269(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "      720    0.000    0.000    0.000    0.000 562999156.py:58(IsA)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
      "       27    0.000    0.000    0.000    0.000 utils.py:32(FromInt)\n",
      "       21    0.000    0.000    0.000    0.000 562999156.py:189(Apply)\n",
      "      146    0.000    0.000    0.000    0.000 562999156.py:358(_iter_plans)\n",
      "     12/6    0.000    0.000    0.008    0.001 562999156.py:274(_solve_dep)\n",
      "     1097    0.000    0.000    0.000    0.000 562999156.py:30(__hash__)\n",
      "      146    0.000    0.000    0.000    0.000 562999156.py:361(_advance)\n",
      "      437    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "      153    0.000    0.000    0.000    0.000 562999156.py:33(__eq__)\n",
      "      225    0.000    0.000    0.001    0.000 {built-in method builtins.all}\n",
      "      720    0.000    0.000    0.000    0.000 {method 'issubset' of 'set' objects}\n",
      "      738    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "      537    0.000    0.000    0.000    0.000 562999156.py:377(<genexpr>)\n",
      "      141    0.000    0.000    0.000    0.000 562999156.py:370(<listcomp>)\n",
      "  149/104    0.000    0.000    0.000    0.000 562999156.py:68(Signature)\n",
      "       40    0.000    0.000    0.000    0.000 562999156.py:307(_add_result)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:885(_process_class)\n",
      "    55/45    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "      388    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       21    0.000    0.000    0.000    0.000 562999156.py:259(_apply)\n",
      "       21    0.000    0.000    0.000    0.000 562999156.py:201(<dictcomp>)\n",
      "        1    0.000    0.000    0.010    0.010 562999156.py:236(Solve)\n",
      "       27    0.000    0.000    0.000    0.000 562999156.py:20(NewKey)\n",
      "      181    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "       37    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
      "       12    0.000    0.000    0.000    0.000 dataclasses.py:665(_is_type)\n",
      "      157    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       94    0.000    0.000    0.000    0.000 562999156.py:431(<genexpr>)\n",
      "      2/1    0.000    0.000    0.000    0.000 inspect.py:2422(_signature_from_callable)\n",
      "       20    0.000    0.000    0.000    0.000 562999156.py:83(__init__)\n",
      "       25    0.000    0.000    0.000    0.000 562999156.py:38(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:724(_get_field)\n",
      "       20    0.000    0.000    0.000    0.000 562999156.py:244(_get_producers_of)\n",
      "    70/65    0.000    0.000    0.000    0.000 562999156.py:70(<genexpr>)\n",
      "       14    0.000    0.000    0.000    0.000 562999156.py:102(__str__)\n",
      "       44    0.000    0.000    0.000    0.000 562999156.py:103(_props)\n",
      "      153    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
      "       26    0.000    0.000    0.000    0.000 562999156.py:26(__init__)\n",
      "       21    0.000    0.000    0.000    0.000 562999156.py:427(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:413(_create_fn)\n",
      "       36    0.000    0.000    0.000    0.000 <string>:2(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2327(_signature_from_function)\n",
      "      128    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "       74    0.000    0.000    0.000    0.000 562999156.py:433(<genexpr>)\n",
      "       46    0.000    0.000    0.000    0.000 562999156.py:105(<genexpr>)\n",
      "       57    0.000    0.000    0.000    0.000 562999156.py:260(<genexpr>)\n",
      "      129    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        5    0.000    0.000    0.000    0.000 inspect.py:2676(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:2962(__init__)\n",
      "       21    0.000    0.000    0.000    0.000 562999156.py:425(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:530(_init_fn)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3224(__str__)\n",
      "        5    0.000    0.000    0.000    0.000 562999156.py:115(_add_dependency)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
      "       54    0.000    0.000    0.000    0.000 562999156.py:336(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 562999156.py:450(<dictcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:2763(__str__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2042(_signature_bound_method)\n",
      "        5    0.000    0.000    0.000    0.000 inspect.py:1449(formatannotation)\n",
      "       34    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:735(unwrap)\n",
      "        5    0.000    0.000    0.000    0.000 562999156.py:112(AddProduct)\n",
      "        1    0.000    0.000    0.000    0.000 562999156.py:93(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        5    0.000    0.000    0.000    0.000 562999156.py:422(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:828(_set_new_attribute)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:394(_recursive_repr)\n",
      "        5    0.000    0.000    0.000    0.000 enum.py:669(__call__)\n",
      "        5    0.000    0.000    0.000    0.000 562999156.py:76(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:267(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:371(_fields_in_init_order)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:347(field)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:589(_repr_fn)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:821(_set_qualname)\n",
      "        1    0.000    0.000    0.000    0.000 interactiveshell.py:273(_modified_open)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:451(_field_init)\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:380(_tuple_str)\n",
      "        8    0.000    0.000    0.000    0.000 dataclasses.py:647(_is_classvar)\n",
      "       24    0.000    0.000    0.000    0.000 {method 'group' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2068(_signature_is_builtin)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3016(from_callable)\n",
      "       21    0.000    0.000    0.000    0.000 562999156.py:445(<lambda>)\n",
      "       11    0.000    0.000    0.000    0.000 dataclasses.py:427(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:325(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:167(get_annotations)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:3011(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 dataclasses.py:655(_is_initvar)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3270(signature)\n",
      "        9    0.000    0.000    0.000    0.000 562999156.py:338(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:511(_init_param)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1210(wrap)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "       14    0.000    0.000    0.000    0.000 inspect.py:2741(kind)\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:389(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3032(replace)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1193(dataclass)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:550(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
      "        8    0.000    0.000    0.000    0.000 dataclasses.py:661(_is_kw_only)\n",
      "        1    0.000    0.000    0.000    0.000 562999156.py:237(State)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1018(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:574(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 inspect.py:1950(_signature_get_user_defined_method)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:186(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 enum.py:1074(__new__)\n",
      "        5    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.repr}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:625(_cmp_fn)\n",
      "        4    0.000    0.000    0.000    0.000 dataclasses.py:439(_field_assign)\n",
      "        3    0.000    0.000    0.000    0.000 inspect.py:378(isfunction)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2080(_signature_is_functionlike)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:593(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:505(isbuiltin)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:375(<genexpr>)\n",
      "        9    0.000    0.000    0.000    0.000 inspect.py:2729(name)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:755(_is_wrapper)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:292(isclass)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1044(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 dataclasses.py:1102(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:310(ismethoddescriptor)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1047(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen abc>:146(update_abstractmethods)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:376(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:2733(default)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1053(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:3028(return_annotation)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:3024(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(__create_fn__)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:843(_hash_set_none)"
     ]
    }
   ],
   "source": [
    "\n",
    "NS = Namespace()\n",
    "transforms = []\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"reads\"))\n",
    "t.AddProduct(_set(\"annable, taxable\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"annable\"))\n",
    "t.AddProduct(_set(\"ann\"))\n",
    "transforms.append(t)\n",
    "\n",
    "# t = Transform(NS)\n",
    "# t.AddRequirement(_set(\"ann\"))\n",
    "# t.AddProduct(_set(\"annable\"))\n",
    "# transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "t.AddRequirement(_set(\"taxable\"))\n",
    "t.AddProduct(_set(\"tax\"))\n",
    "transforms.append(t)\n",
    "\n",
    "t = Transform(NS)\n",
    "d_parent = t.AddRequirement(_set(\"annable, taxable\"))\n",
    "d_ann = t.AddRequirement(_set(\"ann\"), {d_parent})\n",
    "d_tax = t.AddRequirement(_set(\"tax\"), {d_parent})\n",
    "t.AddProduct(_set(\"sum\"))\n",
    "transforms.append(t)\n",
    "\n",
    "# M, N = 2, 1\n",
    "# M, N = 2, 2\n",
    "M, N = 5, 3\n",
    "# M, N = 6, 6\n",
    "# M, N = 8, 6\n",
    "# M, N = 8, 8\n",
    "# M, N = 50, 2\n",
    "# M, N = 60, 2\n",
    "haves = [Endpoint(NS, _set(f\"{i+1}, reads\")) for i in range(M)]\n",
    "\n",
    "target = Transform(NS)\n",
    "# for e in haves[-N:]:\n",
    "for e in haves[:N]:\n",
    "    de = target.AddRequirement(e.properties)\n",
    "    target.AddRequirement(_set(\"sum\"), {de})\n",
    "    # target.AddRequirement(_set(\"sum\"))\n",
    "\n",
    "print(\"Start\")\n",
    "# %prun r = Solve(haves, target, transforms)\n",
    "%prun solutions = Solve(haves, target, transforms)\n",
    "# f\"input size [{N}], states checked [{r.steps}], {r.message}, {len(target.requires)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "12\n",
      "{reads}->{annable-taxable} || (J000:1-reads) >> (d000:annable-taxable)\n",
      "{annable}->{ann} || (d000:annable-taxable) >> (i000:ann)\n",
      "{taxable}->{tax} || (d000:annable-taxable) >> (n000:tax)\n",
      "{annable-taxable},{ann},{tax}->{sum} || (d000:annable-taxable),(i000:ann),(n000:tax) >> (s000:sum)\n",
      "{reads}->{annable-taxable} || (K000:reads-2) >> (e000:annable-taxable)\n",
      "{annable}->{ann} || (e000:annable-taxable) >> (j000:ann)\n",
      "{taxable}->{tax} || (e000:annable-taxable) >> (o000:tax)\n",
      "{annable-taxable},{ann},{tax}->{sum} || (e000:annable-taxable),(j000:ann),(o000:tax) >> (t000:sum)\n",
      "{reads}->{annable-taxable} || (L000:3-reads) >> (f000:annable-taxable)\n",
      "{annable}->{ann} || (f000:annable-taxable) >> (k000:ann)\n",
      "{taxable}->{tax} || (f000:annable-taxable) >> (p000:tax)\n",
      "{annable-taxable},{ann},{tax}->{sum} || (f000:annable-taxable),(k000:ann),(p000:tax) >> (u000:sum)\n",
      "{1-reads},{sum},{reads-2},{sum},{3-reads},{sum}-> || (J000:1-reads),(s000:sum),(K000:reads-2),(t000:sum),(L000:3-reads),(u000:sum) >> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(solutions))\n",
    "for i, res in enumerate(solutions):\n",
    "    print(res.steps)\n",
    "    for a in res.dependency_plan:\n",
    "        print(a)\n",
    "    print(res.application)\n",
    "    print()\n",
    "    if i > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        # todo: deque[Dependency] = deque()\n",
    "        # loop_marker: Dependency|None = None\n",
    "        # # check here for lineage constraints\n",
    "        # while len(todo)>0:\n",
    "        #     req = todo.popleft()\n",
    "        #     if req == loop_marker:\n",
    "        #         if DEBUG: debug_print(f\"<<< FAIL\", s.target, req)\n",
    "        #         return\n",
    "\n",
    "        #     req_p = {}\n",
    "        #     for proto, e in s.required_parents.items():\n",
    "        #         if req.IsA(proto): continue\n",
    "        #         # if already satisfied by other req and lineage not specified for this req: skip\n",
    "        #         # if e in satisfied_lineages and all(not pproto.IsA(proto) for pproto in req.parents): continue\n",
    "        #         req_p[proto] = e\n",
    "        #     if any(p not in deps for p in req.parents):\n",
    "        #         res = None # requirements of node not satisfied yet\n",
    "        #     else:\n",
    "        #         rreq = {p:deps[p] for p in req.parents}\n",
    "        #         res = _solve_dep(State(_have, req, req_p|rreq, s.steps+1, s.depth+1))\n",
    "        #         # if res is None:\n",
    "\n",
    "\n",
    "        #     if res is None:\n",
    "        #         todo.append(req)\n",
    "        #         if loop_marker is None: loop_marker = req\n",
    "        #         continue\n",
    "        #     loop_marker = None\n",
    "\n",
    "        #     if res.endpoint in plans: continue # for duplicate reqs...\n",
    "        #     plans[res.endpoint] = res.plan\n",
    "        #     deps[req] = res.endpoint\n",
    "        #     steps += res.steps\n",
    "        #     for appl in res.plan:\n",
    "        #         _have |= appl.produced\n",
    "        #     satisfied_lineages[res.endpoint] = req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # reqs = deque()\n",
    "    # for r in target.requires:\n",
    "    #     reqs.append(r)\n",
    "\n",
    "    # todo: deque[State] = deque()\n",
    "    # todo.append(State(set(given), [], target, [], reqs))\n",
    "    # steps, MAX_S = 0, 5\n",
    "    # while len(todo)>0:\n",
    "    #     steps += 1\n",
    "    #     if steps>MAX_S: \n",
    "    #         print(\"step limit\")\n",
    "    #         return\n",
    "\n",
    "    #     s = todo.popleft()\n",
    "        \n",
    "    #     print(s.target)\n",
    "    #     # print(s.have)\n",
    "    #     for x in s.plan:\n",
    "    #         print(x)\n",
    "    #     print()\n",
    "\n",
    "    #     if len(s.requirements) == 0: return s\n",
    "\n",
    "    #     if isinstance(s.target, Dependency):\n",
    "    #         for e in s.have:\n",
    "    #             if not e.IsA(s.target): continue\n",
    "    #             todo.append(State(\n",
    "    #                 s.have,\n",
    "    #                 [],\n",
    "    #                 s.requirements.popleft(),\n",
    "    #                 s.all_plans+[s.plan+[e]],\n",
    "    #                 s.requirements,\n",
    "    #             ))\n",
    "            \n",
    "    #         for tr in _get_producers_of(s.target):\n",
    "    #             todo.append(State(\n",
    "    #                 s.have,\n",
    "    #                 s.plan + [tr],\n",
    "    #                 tr,\n",
    "    #                 s.all_plans,\n",
    "    #                 s.requirements,\n",
    "    #             ))\n",
    "    #     else:\n",
    "    #         for req in target.requires:\n",
    "    #             if len(req.parents)>0:\n",
    "    #                 continue # figure out later\n",
    "    #             todo.append(State(\n",
    "    #                 s.have,\n",
    "    #                 s.plan + [req],\n",
    "    #                 req,\n",
    "    #                 s.all_plans,\n",
    "    #                 s.requirements\n",
    "    #             ))\n",
    "\n",
    "    # # @dataclass\n",
    "    # # class State:\n",
    "    # #     target: Transform\n",
    "    # #     have: set[Endpoint]\n",
    "    # #     constraints: dict[Dependency, Endpoint]\n",
    "    # #     plan: list[Transform]\n",
    "\n",
    "    # # todo: deque[State] = deque()\n",
    "    # # todo.append(State(target, set(given), {}, []))\n",
    "    # # while len(todo)>0:\n",
    "    # #     s = todo.popleft()\n",
    "    # #     cons = s.constraints\n",
    "        \n",
    "    # #     for tr in transforms:\n",
    "    # #         fwds = tr.Valids(tr.Possibilities(s.have, cons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _apply_one(have: set[Endpoint], tr: Transform, sources: set[Endpoint]):\n",
    "#         match = next(tr.NextValid(tr.Possibilities(have, sources)), None)\n",
    "#         if match is not None:\n",
    "#             return tr.Apply(match)\n",
    "    \n",
    "#     # res = _map()\n",
    "#     # if not res.success: return res\n",
    "\n",
    "\n",
    "        # for e in given if len(sources)==0 else sources:\n",
    "        #     if not e.IsA(target): continue\n",
    "        #     return MapResult([], e)\n",
    "\n",
    "        # if \"sum\" in target.properties and any(\"2\" in s.properties for s in sources):\n",
    "        # if \"sum\" in target.properties:\n",
    "        #     x = 1\n",
    "        #     print(target, sources)\n",
    "\n",
    "        # todo: deque[MapState] = deque()\n",
    "        # todo.append(MapState(given, [], {t for t in transforms}))\n",
    "\n",
    "        # while len(todo)>0:\n",
    "        #     s = todo.popleft()\n",
    "        #     for tr in curr.remaining_transforms:\n",
    "        #         next_step = _apply_one(curr.have, tr)\n",
    "        #         if next_step is None: continue\n",
    "        #             # next_step = _apply_one(curr.have, tr)\n",
    "        #             # if next_step is None: continue\n",
    "        #         for e in next_step.produced:\n",
    "        #             if not e.IsA(target): continue\n",
    "        #             return MapResult(curr.plan+[next_step], e)\n",
    "\n",
    "        #         todo.append(MapState(\n",
    "        #             curr.have | next_step.produced,\n",
    "        #             curr.plan + [next_step],\n",
    "        #             curr.remaining_transforms - {tr}\n",
    "        #         ))\n",
    "\n",
    "#     def _solve_tr(given: set[Endpoint], target: Transform):\n",
    "#         have = set(given)\n",
    "#         plan: list[Application] = []\n",
    "#         dep2ep: dict[Node, Endpoint] = {} # really Dep -> Ep\n",
    "#         dep_parent_sets: dict[Dependency, set[Endpoint]] = {}\n",
    "#         todo: deque[Dependency] = deque()\n",
    "#         for r in target.requires: todo.append(r)\n",
    "#         loop_landmark = None\n",
    "#         while len(todo)>0:\n",
    "#             curr = todo.popleft()\n",
    "#             def _skip():\n",
    "#                 nonlocal loop_landmark\n",
    "#                 if loop_landmark is None: loop_landmark = curr\n",
    "#                 todo.append(curr)\n",
    "\n",
    "#             if loop_landmark is not None and curr == loop_landmark:\n",
    "#                 return Result([], f\"can't make {curr}\", info=have)\n",
    "#             # if any parent not generated, skip for now\n",
    "#             if any(p not in dep2ep for p in curr.parents): _skip(); continue\n",
    "\n",
    "#             if curr not in dep_parent_sets:\n",
    "#                 parents = {dep2ep[p] for p in curr.parents}\n",
    "#                 dep_parent_sets[curr] = parents\n",
    "#             # print(f\"---\",dep_parent_sets)\n",
    "\n",
    "#             # if \"sum\" in curr.properties:\n",
    "#             #     print(curr, dep_parent_sets[curr])\n",
    "#             sol = _solve_dep(have, curr, dep_parent_sets[curr])\n",
    "#             if sol is None: _skip(); continue\n",
    "#             loop_landmark = None\n",
    "\n",
    "#             # print(curr, dep_parent_sets[curr], loop_landmark)\n",
    "#             # print(\">\")\n",
    "#             # print(have)\n",
    "#             # print(todo)\n",
    "#             # print(sol)\n",
    "#             # for a in sol.plan:\n",
    "#             #     print(a)\n",
    "#             # print()\n",
    "\n",
    "#             dep2ep[curr] = sol.endpoint\n",
    "#             for a in sol.plan:\n",
    "#                 have |= a.produced\n",
    "#             plan += sol.plan\n",
    "\n",
    "#     return _solve_tr(set(given), target, set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # sol = res.solution\n",
    "    # last_l = 0\n",
    "    # while last_l != len(sol):\n",
    "    #     last_l = len(sol)\n",
    "    #     used = set()\n",
    "    #     for a in sol:\n",
    "    #         used |= a.used\n",
    "    #     sol = [a for a in sol if a.transform==target or any(e in used for e in a.produced)]\n",
    "    # res.solution = sol    \n",
    "\n",
    "# @dataclass\n",
    "    # class State:\n",
    "    #     have: set[Endpoint]\n",
    "    #     plan: list[Application]\n",
    "    #     usage_sigs: set[str]\n",
    "\n",
    "    # def _local_solve(have: set[Endpoint], target: Dependency):\n",
    "    #     todo: deque[State] = deque()\n",
    "    #     todo.append(State(have, [], set()))\n",
    "    #     MAX_S = 10_000\n",
    "    #     steps = 0\n",
    "    #     # _last_depth = 0\n",
    "    #     while len(todo) > 0:\n",
    "    #         steps += 1\n",
    "    #         if steps>MAX_S: return Result([], \"step limit\", steps, info=todo)\n",
    "    #         curr = todo.popleft()    \n",
    "\n",
    "# @dataclass\n",
    "    # class SubGoal:\n",
    "    #     target: Dependency\n",
    "\n",
    "    # have = set(given)\n",
    "    # dep2endpoint: dict[Dependency, Endpoint] = {}\n",
    "    # todo: deque[SubGoal] = deque()\n",
    "    # for d in target.requires: todo.appendleft(SubGoal(d))\n",
    "    # while len(todo)>0:\n",
    "    #     subgoal = todo.pop()\n",
    "    #     sources: list[Endpoint] = []\n",
    "    #     ok = True\n",
    "    #     for p in subgoal.target.parents:\n",
    "    #         if p not in dep2endpoint:\n",
    "    #             todo.appendleft(subgoal)\n",
    "    #             ok = False; break\n",
    "    #         sources.append(dep2endpoint[p])\n",
    "    #     if not ok: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Apply(self, have: Iterable[Endpoint], use_signatures: set[str]) -> Iterable[Application]:\n",
    "#         matches = self.Possibilities(have)\n",
    "#         if len(matches) == 0: return []\n",
    "\n",
    "#         # can reduce exponential trial here by enforcning the input groups first\n",
    "#         def _possible_configs(i: int, choosen: list[Endpoint]) -> list[list[Endpoint]]:\n",
    "#             if i >= len(self.requires): return [choosen]\n",
    "#             candidates = matches[i]\n",
    "#             parents = self._input_group_map.get(i, [])\n",
    "#             # print(parents, candidates, choosen)\n",
    "#             if len(parents) > 0:\n",
    "#                 for prototype in parents:\n",
    "#                     # parent must be in choosen, since it must have been added\n",
    "#                     # as a req. before being used as a parent\n",
    "#                     parent: None|Endpoint = None\n",
    "#                     for p in choosen:\n",
    "#                         if p.IsA(prototype): parent = p; break\n",
    "#                     if parent is None: return []\n",
    "#                     candidates = [c for c in candidates if parent in c.parents]\n",
    "#             configs = []\n",
    "#             for c in candidates:\n",
    "#                 configs += _possible_configs(i+1, choosen+[c])\n",
    "#             return configs\n",
    "#         configs = _possible_configs(0, [])\n",
    "\n",
    "#         def _same(a: Endpoint, b: Endpoint):\n",
    "#             return a.properties.issubset(b.properties) and b.properties.issubset(a.properties) \\\n",
    "#                 and a.parents.issubset(b.parents) and b.parents.issubset(a.parents)\n",
    "\n",
    "#         for input_set in configs:\n",
    "#             sis = set(input_set)\n",
    "#             sig = self._sig(input_set)\n",
    "#             if sig in use_signatures: continue\n",
    "#             _parents = sis|{p for g in [e.parents for e in input_set] for p in g}\n",
    "#             produced = {\n",
    "#                 Endpoint(\n",
    "#                     namespace=self._ns,\n",
    "#                     properties=out.properties,\n",
    "#                     parents=_parents\n",
    "#                 )\n",
    "#             for out in self.produces}\n",
    "#             # if all(_same(e, p) for e in have for p in produced):\n",
    "#             #     continue\n",
    "#             #     print(have)\n",
    "#             #     print(produced)\n",
    "#             #     print()\n",
    "#             yield Application(self, sis, produced, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # if len(target.parents) == 0:\n",
    "        #     sol = _map_to(have, target)\n",
    "        #     if sol is None: return Result([], \"x\")\n",
    "        #     return Result(sol, success=True)\n",
    "        # else:\n",
    "        #     for p in target.parents:\n",
    "        #         _p: Any = p\n",
    "        #         res = _map_to(have, target, _p)\n",
    "\n",
    "        #         print(\">\",res)\n",
    "        #         have |= {e for g in [a.produced for a in res.solution] for e in g}\n",
    "        #         if not res.success: return res\n",
    "\n",
    "    # have = set(given)\n",
    "    # for d in target.requires:\n",
    "    #     _solve(have, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def Signature(self):\n",
    "    #     cache = self.namespace.node_signatures\n",
    "    #     if self.key not in cache:\n",
    "    #         props = \",\".join(sorted(self.properties))\n",
    "    #         parents = \",\".join(sorted([p.Signature() for p in self.parents]))\n",
    "    #         sig = f\"{props}-{parents}\"\n",
    "    #         cache[self.hash] = sig\n",
    "    #     return cache[self.hash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # def _solve():\n",
    "    #     todo: deque[State] = deque()\n",
    "    #     todo.append(State(set(given), [], set()))\n",
    "    #     MAX_S = 100_000\n",
    "    #     steps = 0\n",
    "    #     # _last_depth = 0\n",
    "    #     while len(todo) > 0:\n",
    "    #         steps += 1\n",
    "    #         if steps>MAX_S: return Result([], \"step limit\", todo, steps)\n",
    "    #         # curr = todo.popleft()\n",
    "    #         curr = todo.pop()\n",
    "\n",
    "    #         final_appl = _check_done(curr)\n",
    "    #         if final_appl is not None: return Result(curr.plan+[final_appl], steps=steps)\n",
    "\n",
    "    #         # _depth = len(curr.plan)\n",
    "    #         # if _depth != _last_depth:\n",
    "    #         #     todo = _deduplicate_states(curr, todo)\n",
    "    #         #     _last_depth = _depth\n",
    "\n",
    "    #         next_states = _get_next_states(curr)\n",
    "    #         for n in next_states:\n",
    "    #             todo.append(n)\n",
    "\n",
    "    #     return Result([], \"no sol\", steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # plans: dict[Endpoint, Path] = {}\n",
    "    # def _path_to(have: Iterable[Endpoint], target: Dependency) -> Path|None:\n",
    "    #     if any(e.IsA(target) for e in have): return Path([])\n",
    "    #     if target in plans: return plans[target]\n",
    "\n",
    "    #     # DFS back from e\n",
    "    #     for tr in transforms:\n",
    "    #         if not any(d.IsA(target) for d in tr.produces): continue \n",
    "    #         for req in tr.requires:\n",
    "    #             path_result = _path_to(have, req)\n",
    "    #             if path_result is None: continue\n",
    "    #             path_result.plan.append(tr)\n",
    "    #             return path_result\n",
    "    # x = [\n",
    "    # # @dataclass\n",
    "    # # class State:\n",
    "    # #     have: Iterable[Endpoint]\n",
    "    # #     targets: Iterable[Dependency]\n",
    "    # #     plan: list[Transform]\n",
    "\n",
    "    # # todo: deque[State] = deque(maxlen=64)\n",
    "    # # todo.append(State([], [t for t in target.requires], []))\n",
    "    # # while len(todo)>0:\n",
    "    # #     _s = todo.popleft()\n",
    "    # #     t = next(iter(_s.targets))\n",
    "    # #     plan = \n",
    "    # ]\n",
    "\n",
    "    # usage_signatures: dict[Transform, set[str]] = {t:set() for t in transforms}\n",
    "    # def _solve(have: list[Endpoint], target: Transform, sigs: dict) -> list[Application]|None:\n",
    "    #     possibilities = target.Apply(have, sigs[target])\n",
    "    #     if len(possibilities)>0: return possibilities[0:1]\n",
    "\n",
    "    #     for t in target.requires:\n",
    "    #         path = _path_to(have, t)\n",
    "    #         if path is None: return None\n",
    "    #         fist_tr = path.plan[0]\n",
    "    #         poss = fist_tr.Apply(have, sigs[fist_tr])\n",
    "    #         if poss\n",
    "                        \n",
    "            \n",
    "\n",
    "\n",
    "    # _solve(list(given), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Solve(given: Iterable[Endpoint], target: Transform, transforms: Iterable[Transform]):\n",
    "#     @dataclass\n",
    "#     class State:\n",
    "#         have: list[Endpoint]\n",
    "#         usage_signatures: dict[int, set[str]]\n",
    "#         plan: list[Application]\n",
    "\n",
    "#     transforms = list(transforms)\n",
    "    \n",
    "#     def _done(state: State):\n",
    "#         appl = target.Apply(state.have, set())\n",
    "#         return appl \n",
    "\n",
    "#     def _solve() -> Result:\n",
    "#         MAXS = 10_000\n",
    "#         todo: deque[State] = deque([State(\n",
    "#             have = list(given),\n",
    "#             plan = [],\n",
    "#             usage_signatures={},\n",
    "#         )], maxlen=MAXS)\n",
    "        \n",
    "\n",
    "#         def _deduplicate_states(current: State):\n",
    "#             def _get_sig(s: State):\n",
    "#                 haves_sig = '|'.join([e.Signature() for e in s.have])\n",
    "#                 return haves_sig\n",
    "#             seen = {_get_sig(current)}\n",
    "#             new_todo: deque[State] = deque([], MAXS)\n",
    "#             for s in todo:\n",
    "#                 if _get_sig(s) in seen: continue\n",
    "#                 new_todo.append(s)\n",
    "\n",
    "#             if len(todo) != len(new_todo):\n",
    "#                 for s in todo:\n",
    "#                     print(s)\n",
    "#                 print(\"-\")\n",
    "#                 for s in new_todo:\n",
    "#                     print(s)\n",
    "#                 print()\n",
    "#             return new_todo\n",
    "\n",
    "#         _steps = 0\n",
    "#         _empty = set()\n",
    "#         _last_depth = 0\n",
    "#         while len(todo)>0:\n",
    "#             _steps += 1\n",
    "#             if _steps > MAXS: return Result([], f\"step limit exceeded\", steps=_steps)\n",
    "#             _s = todo.popleft()\n",
    "\n",
    "#             _target_applications = target.Apply(_s.have, _empty)\n",
    "#             if len(_target_applications)>0:\n",
    "#                 return Result(solution=_s.plan+[_target_applications[0]], steps=_steps)\n",
    "\n",
    "#             _depth = len(_s.plan)\n",
    "#             if _depth != _last_depth:\n",
    "#                 todo = _deduplicate_states(_s)\n",
    "#                 _last_depth = _depth\n",
    "\n",
    "#             if _done(_s): return Result(_s.plan, steps=_steps)\n",
    "#             for tr in transforms:\n",
    "#                 possibilities = tr.Apply(_s.have, _s.usage_signatures.get(tr.hash, set()))\n",
    "#                 # for app in possibilities:\n",
    "#                 #     usage_sigs = _s.usage_signatures.copy()\n",
    "#                 #     usage_sigs[tr.hash] = usage_sigs.get(tr.hash, set())|{app.signature}\n",
    "#                 #     todo.append(State(\n",
    "#                 #         have = _s.have+app.produced,\n",
    "#                 #         plan = _s.plan+[app],\n",
    "#                 #         usage_signatures = usage_sigs,\n",
    "#                 #     ))\n",
    "\n",
    "#                 if len(possibilities) == 0: continue\n",
    "#                 usage_sigs = _s.usage_signatures.copy()\n",
    "#                 new_have = _s.have.copy()\n",
    "#                 for app in possibilities:\n",
    "#                     usage_sigs[tr.hash] = usage_sigs.get(tr.hash, set())|{app.signature}\n",
    "#                     new_have += app.produced\n",
    "#                 todo.append(State(\n",
    "#                     have = new_have,\n",
    "#                     plan = _s.plan+possibilities,\n",
    "#                     usage_signatures=usage_sigs\n",
    "#                 ))\n",
    "#         return Result([], f\"ran out of things to try\", steps = _steps)\n",
    "    \n",
    "#     res = _solve()\n",
    "#     sol = res.solution\n",
    "#     last_l = 0\n",
    "#     while last_l != len(sol):\n",
    "#         last_l = len(sol)\n",
    "#         used = set()\n",
    "#         for a in sol:\n",
    "#             used |= a.used\n",
    "#         sol = [a for a in sol if a.transform==target or any(e in used for e in a.produced)]\n",
    "#     res.solution = sol\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import annotations\n",
    "# import os, sys\n",
    "# import asyncio\n",
    "# from typing import Iterable, Callable, Any\n",
    "# from pathlib import Path\n",
    "\n",
    "# from limes_x.solver import DependencySolver, Plan, Dependency\n",
    "# from limes_x.persistence import ProjectState, Instance\n",
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# mpath = Path(\"./test_solver/\")\n",
    "# modules = [\n",
    "#     ComputeModule(mpath.joinpath(d)) for d in os.listdir(mpath)\n",
    "# ]\n",
    "# print(modules)\n",
    "\n",
    "# given = [\n",
    "#     (\"a\", \"./test_data/a1\"),\n",
    "#     (\"a\", \"./test_data/a2\"),\n",
    "#     (\"b\", \"./test_data/b1\"),\n",
    "# ]\n",
    "\n",
    "# prj_path = \"./cache/man_test01/\"\n",
    "# state = ProjectState(prj_path, on_exist=\"overwrite\")\n",
    "# for dtype, val in given:\n",
    "#     state.RegisterInstance(Instance.Str(dtype, val))\n",
    "# for m in modules:\n",
    "#     state.RegisterInstance(Instance.ComputeModule(m))\n",
    "\n",
    "# deps = []\n",
    "# for k, inst in state._instances.items():\n",
    "#     if not inst.IsPyType(ComputeModule): continue\n",
    "#     deps.append(Dependency(inst.val.requires, inst.val.produces, k))\n",
    "\n",
    "# solver = DependencySolver(deps)\n",
    "# # plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan = solver.Solve({\"a\"}, {\"branched\"})\n",
    "# assert plan != False\n",
    "# [state.GetInstance(m.ref_key) for m in plan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_dependency(module: ComputeModule):\n",
    "#     return Dependency(module.requires, module.produces, module)\n",
    "\n",
    "# modules = Path(\"./test_solver/\")\n",
    "# solver = Plan([\n",
    "#     make_dependency(ComputeModule(p))\n",
    "# for p in [\n",
    "#     modules.joinpath(p) for p in os.listdir(modules)\n",
    "# ]])\n",
    "# plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# a = ComputeModule(\"./test_modules/copy/\")\n",
    "# b = ComputeModule(\"./test_modules/copy2/\")\n",
    "\n",
    "# a.requires, b.requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = ProjectState(\"./cache/test_persist\")\n",
    "# ok = Instance(\"asdf\", 1)\n",
    "# ov = Instance(\"s\", 2)\n",
    "# state._lineage[ok] = [ov]\n",
    "# state.Save()\n",
    "\n",
    "# s2 = ProjectState.Load(\"./cache/test_persist\")\n",
    "# for k, v in s2._lineage.items():\n",
    "#     _te = k.type, k.value, ok == k, [(i.type, i.value, i == ov) for i in v]\n",
    "#     print(_te)\n",
    "\n",
    "# ok._id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
