{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Application(transform=<{annable}->{ann}>, used=[<iBLp9efruEYo:taxable,annable,asm>], produced=[<WmMiKdZ21wbQ:ann>]),\n",
       " Application(transform=<{annable}->{ann}>, used=[<hCo6o52e7CrJ:taxable,annable,bin>], produced=[<T7DH2XGCR7hV:ann>]),\n",
       " Application(transform=<{taxable}->{tax}>, used=[<iBLp9efruEYo:taxable,annable,asm>], produced=[<UN0tLjl6Ze0V:tax>]),\n",
       " Application(transform=<{taxable}->{tax}>, used=[<hCo6o52e7CrJ:taxable,annable,bin>], produced=[<qOr6VNOo0WdX:tax>]),\n",
       " Application(transform=<{ann},{tax}->{sum}>, used=[<WmMiKdZ21wbQ:ann>, <UN0tLjl6Ze0V:tax>], produced=[<iNNxj69p5A3Q:sum>]),\n",
       " Application(transform=<{ann},{tax}->{sum}>, used=[<T7DH2XGCR7hV:ann>, <qOr6VNOo0WdX:tax>], produced=[<4p8riM5j6mGg:sum>])]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "import os, sys\n",
    "from typing import Any, Iterable, Literal\n",
    "import hashlib\n",
    "\n",
    "from limes_x.utils import KeyGenerator\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self) -> None:\n",
    "        self.node_hashes: dict[str, int] = {}\n",
    "        self._keygen = KeyGenerator()\n",
    "        self._keys: set[str] = set()\n",
    "\n",
    "    def NewKey(self):\n",
    "        return self._keygen.GenerateUID(blacklist=self._keys)\n",
    "\n",
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        namespace: Namespace,\n",
    "        properties: set[str],\n",
    "        parents: set[Node],\n",
    "    ) -> None:\n",
    "        self.namespace = namespace\n",
    "        self.properties = properties\n",
    "        self.parents = parents\n",
    "        self.key = namespace.NewKey()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"<{self.key}:{','.join(self.properties)}>\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self}\"\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        node_hashes = self.namespace.node_hashes\n",
    "        if self.key not in node_hashes:\n",
    "            node_hashes[self.key] = int(hashlib.md5(self.key.encode(\"latin1\")).hexdigest(), 16)\n",
    "        return node_hashes[self.key]\n",
    "    \n",
    "    # x == y if x is a \"subset\" of y\n",
    "    # that is, x has at least all features of y\n",
    "    def __eq__(self, __value: object) -> bool:\n",
    "        if not isinstance(__value, Node): return False\n",
    "        for p in __value.properties:\n",
    "            if p not in self.properties: return False\n",
    "        for p in __value.parents:\n",
    "            if all(p != op for op in self.parents): return False\n",
    "        return True\n",
    "    \n",
    "    def MatchesMemberOf(self, collection: Iterable[Node]):\n",
    "        return any(self == m for m in collection)\n",
    "\n",
    "class Dependency(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: set[Node]) -> None:\n",
    "        super().__init__(namespace, properties, parents)\n",
    "\n",
    "class Endpoint(Node):\n",
    "    def __init__(self, namespace: Namespace, properties: set[str], parents: set[Node]=set()) -> None:\n",
    "        super().__init__(namespace, properties, parents)\n",
    "\n",
    "@dataclass\n",
    "class InputGrouping:\n",
    "    group: Iterable[Dependency]\n",
    "    parent_prototype: Node\n",
    "\n",
    "@dataclass\n",
    "class Application:\n",
    "    transform: Transform\n",
    "    used: Iterable[Endpoint]\n",
    "    produced: Iterable[Endpoint]\n",
    "\n",
    "    def Signature(self): return self.CalculateSignature(self.transform, self.used)\n",
    "    \n",
    "    @classmethod\n",
    "    def CalculateSignature(cls, tr:Transform, trial: Iterable[Endpoint]):\n",
    "        return f\"{tr._key}\"+\"-\".join(e.key for e in trial)\n",
    "\n",
    "class Transform:\n",
    "    def __init__(self, ns: Namespace) -> None:\n",
    "        self.requires: set[Dependency] = set()\n",
    "        self.produces: set[Dependency] = set()\n",
    "        self._ns = ns\n",
    "        self._input_groupings: list[InputGrouping] = []\n",
    "        self._key = ns.NewKey()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        def _props(d: Dependency):\n",
    "            return \"{\"+\"-\".join(d.properties)+\"}\"\n",
    "        return f\"<{','.join(_props(r) for r in self.requires)}->{','.join(_props(p) for p in self.produces)}>\"\n",
    "\n",
    "    def __repr__(self): return f\"{self}\"\n",
    "\n",
    "    def AddInputGrouping(self, grp: Iterable[Dependency], parent_prototype: Node):\n",
    "        for d in grp:\n",
    "            assert d in self.requires, f\"{d} not in requirements\"\n",
    "        self._input_groupings.append(InputGrouping(group=grp, parent_prototype=parent_prototype))\n",
    "\n",
    "    def AddRequirement(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.requires, properties, parents)\n",
    "\n",
    "    def AddProduct(self, properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        return self._add_dependency(self.produces, properties, parents)\n",
    "\n",
    "    def _add_dependency(self, destination: set[Dependency], properties: Iterable[str], parents: set[Dependency]=set()):\n",
    "        _parents: Any = parents\n",
    "        _dep = Dependency(properties=set(properties), parents=_parents, namespace=self._ns)\n",
    "        destination.add(_dep)\n",
    "        return _dep\n",
    "\n",
    "    def _valid_trail(self, trial: Iterable[tuple[Dependency, Endpoint]]):\n",
    "        for grouping in self._input_groupings:\n",
    "            common_parents = None\n",
    "            group = [e for d, e in trial if d in grouping.group]\n",
    "            for member in group:\n",
    "                p_candidates = set()\n",
    "                for p in member.parents:\n",
    "                    if p == grouping.parent_prototype:\n",
    "                        p_candidates.add(p)\n",
    "                if common_parents is None:\n",
    "                    common_parents = p_candidates\n",
    "                else:\n",
    "                    common_parents = common_parents.intersection(p_candidates)\n",
    "\n",
    "                if len(common_parents) == 0: return False\n",
    "        return True\n",
    "\n",
    "    def Apply(self, have: Iterable[Endpoint], blacklist: Iterable[Application]):\n",
    "        matches: list[list[Endpoint]] = []\n",
    "        _reqs = list(self.requires)\n",
    "        for req in _reqs:\n",
    "            _m = [m for m in have if m == req]\n",
    "            if len(_m) == 0: return []\n",
    "            matches.append(_m)\n",
    "\n",
    "        trails: list[list[int]] = [] # trials is exponential!\n",
    "        for candidates in matches:\n",
    "            if len(trails) == 0:\n",
    "                trails = [[i] for i, c in enumerate(candidates)]\n",
    "                continue\n",
    "            new = []\n",
    "            for row in trails:\n",
    "                for i, c in enumerate(candidates):\n",
    "                    new.append(row+[i])\n",
    "            trails = new\n",
    "\n",
    "        blacklist_signatures = [a.Signature() for a in blacklist]\n",
    "        applications: list[Application] = []\n",
    "        for trial_indexes in trails:\n",
    "            trial = [(_reqs[i], matches[i][j]) for i, j in enumerate(trial_indexes)]\n",
    "            if not self._valid_trail(trial): continue\n",
    "            sig = Application.CalculateSignature(self, [e for d, e in trial])\n",
    "            if sig in blacklist_signatures: continue\n",
    "            _parents = set()\n",
    "            for req, cand in trial:\n",
    "                _parents = _parents | cand.parents\n",
    "                _parents.add(cand)\n",
    "\n",
    "            produced = [\n",
    "                Endpoint(\n",
    "                    namespace=self._ns,\n",
    "                    properties=out.properties,\n",
    "                    parents=_parents\n",
    "                )\n",
    "            for out in self.produces]\n",
    "            applications.append(Application(\n",
    "                transform= self,\n",
    "                used = [e for d, e in trial],\n",
    "                produced = produced,\n",
    "            ))\n",
    "        return applications\n",
    "    \n",
    "NS = Namespace()\n",
    "def _set(s: str):\n",
    "    return set(s.split(\", \"))\n",
    "\n",
    "asm = Endpoint(NS, _set(\"asm, annable, taxable\"))\n",
    "bin = Endpoint(NS, _set(\"bin, annable, taxable\"))\n",
    "\n",
    "sum_asm = Endpoint(NS, _set(\"sum\"), {asm})\n",
    "sum_bin = Endpoint(NS, _set(\"sum\"), {bin})\n",
    "\n",
    "anner = Transform(NS)\n",
    "anner.AddRequirement(_set(\"annable\"))\n",
    "anner.AddProduct(_set(\"ann\"))\n",
    "\n",
    "taxer = Transform(NS)\n",
    "taxer.AddRequirement(_set(\"taxable\"))\n",
    "taxer.AddProduct(_set(\"tax\"))\n",
    "\n",
    "sumer = Transform(NS)\n",
    "d_ann = sumer.AddRequirement(_set(\"ann\"))\n",
    "d_tax = sumer.AddRequirement(_set(\"tax\"))\n",
    "sumer.AddInputGrouping(\n",
    "    [d_ann, d_tax],\n",
    "    Endpoint(NS, _set(\"annable, taxable\"))\n",
    ")\n",
    "sumer.AddProduct(_set(\"sum\"))\n",
    "\n",
    "def Solve(given: Iterable[Endpoint], targets: Iterable[Endpoint], transforms: Iterable[Transform]):\n",
    "    todo: list[tuple[set[Endpoint], list[Application]]] = [\n",
    "        (set(given), [])\n",
    "    ]\n",
    "\n",
    "    while len(todo) > 0:\n",
    "        _have, _path = todo.pop(0)\n",
    "        if all(any(e == t for e in _have) for t in targets): return _path\n",
    "        for tr in transforms:\n",
    "            applications = tr.Apply(_have, _path)\n",
    "            for appl in applications:\n",
    "                todo.append((_have | set(appl.produced), _path+[appl]))\n",
    "    return False\n",
    "\n",
    "x = Solve([asm, bin], [sum_asm, sum_bin], [anner, taxer, sumer])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _start = Endpoint(namespace=NS, properties=_settify(\"primeable\"))\n",
    "# _target = Endpoint(namespace=NS, properties=_settify(\"starred\"), parents={_start})\n",
    "\n",
    "# primer = Transform(NS)\n",
    "# primer.AddDependency(\n",
    "#     \"req\", _settify(\"primeable\"),\n",
    "# )\n",
    "# primer.AddDependency(\n",
    "#     \"prod\", _settify(\"primed\"),\n",
    "# )\n",
    "\n",
    "# starer = Transform(NS)\n",
    "# starer.AddDependency(\n",
    "#     \"req\", _settify(\"primed\"),\n",
    "# )\n",
    "# starer.AddDependency(\n",
    "#     \"prod\", _settify(\"starred\"),\n",
    "# )\n",
    "\n",
    "# have = {_start}\n",
    "# targets = {_target}\n",
    "\n",
    "# def Solve(have: Iterable[Endpoint], targets: Iterable[Endpoint]):\n",
    "#     todo = [\n",
    "#         (set(have), [])\n",
    "#     ]\n",
    "#     while len(todo)\n",
    "\n",
    "# xs = primer.Apply([_start])\n",
    "# ys = starer.Apply(xs)\n",
    "\n",
    "# for x in ys:\n",
    "#     print(x == _target, _target == x)\n",
    "#     print(x.parents, x.properties)\n",
    "#     print(_target.parents, _target.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# NS = Namespace()\n",
    "# anner = Transform(\"anner\", NS)\n",
    "# anner.AddDependency(\n",
    "#     \"req\", \"a_in\",\n",
    "#     \"annable\".split(\", \"),\n",
    "# )\n",
    "# anner.AddDependency(\n",
    "#     \"prod\", \"a_out\",\n",
    "#     \"ann\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# taxer = Transform(\"taxer\", NS)\n",
    "# taxer.AddDependency(\n",
    "#     \"req\", \"t_in\",\n",
    "#     \"taxable\".split(\", \"),\n",
    "# )\n",
    "# taxer.AddDependency(\n",
    "#     \"prod\", \"t_out\",\n",
    "#     \"tax\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# sumer = Transform(\"sumer\", NS)\n",
    "# sumer.AddDependency(\n",
    "#     \"req\", \"s_in_ann\",\n",
    "#     \"ann\".split(\", \"),\n",
    "# )\n",
    "# sumer.AddDependency(\n",
    "#     \"req\", \"s_in_tax\",\n",
    "#     \"tax\".split(\", \"),\n",
    "# )\n",
    "# sumer.AddDependency(\n",
    "#     \"prod\", \"s_out\",\n",
    "#     \"sum\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# in_asm = Endpoint.New(NS, \"in_asm\", \"asm, annable, taxable\", have=True)\n",
    "# in_bin = Endpoint.New(NS, \"in_bin\", \"bin, annable, taxable\", have=True)\n",
    "\n",
    "# for tr in [anner, taxer, sumer]:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import annotations\n",
    "# from dataclasses import dataclass, field\n",
    "# import os, sys\n",
    "# from typing import Any, Iterable, Literal\n",
    "# import networkx as nx\n",
    "# import hashlib\n",
    "\n",
    "# class Namespace:\n",
    "#     def __init__(self) -> None:\n",
    "#         self.node_hashes: dict[str, int] = {}\n",
    "#         self.properties: dict[str, Property] = {}\n",
    "\n",
    "#     def GetProperty(self, key: str):\n",
    "#         if key not in self.properties:\n",
    "#             new = Property(self, key)\n",
    "#             new.back_links = set()\n",
    "#             self.properties[key] = new\n",
    "#         return self.properties[key]\n",
    "\n",
    "# @dataclass\n",
    "# class Node:\n",
    "#     namespace: Namespace\n",
    "#     key: str\n",
    "\n",
    "#     def __hash__(self) -> int:\n",
    "#         node_hashes = self.namespace.node_hashes\n",
    "#         if self.key not in node_hashes:\n",
    "#             node_hashes[self.key] = int(hashlib.md5(self.key.encode(\"latin1\")).hexdigest(), 16)\n",
    "#         return node_hashes[self.key]\n",
    "    \n",
    "#     def __eq__(self, __value: object) -> bool:\n",
    "#         if not isinstance(__value, type(self)): return False\n",
    "#         return self.key == __value.key\n",
    "\n",
    "# class Linkable:\n",
    "#     back_links: set[HasLinks]\n",
    "\n",
    "# @dataclass\n",
    "# class Haveable:\n",
    "#     have: bool\n",
    "\n",
    "# @dataclass\n",
    "# class HasLinks:\n",
    "#     links: set[Linkable]\n",
    "\n",
    "#     def Enforce_backlinks(self):\n",
    "#         for o in self.links:\n",
    "#             o.back_links.add(self)\n",
    "\n",
    "#     def Link(self, o: Linkable):\n",
    "#         self.links.add(o)\n",
    "#         o.back_links.add(self)\n",
    "\n",
    "#     def Clear(self):\n",
    "#         for o in self.links:\n",
    "#             o.back_links.remove(self)\n",
    "#         self.links.clear()\n",
    "\n",
    "#     def Matches(self, other: HasLinks):\n",
    "#         return all(l in other.links for l in self.links)\n",
    "\n",
    "# @dataclass\n",
    "# class Property(Node, Linkable):\n",
    "#     def __hash__(self) -> int: return Node.__hash__(self)\n",
    "#     def __eq__(self, __value: object) -> bool: return Node.__eq__(self, __value)\n",
    "    \n",
    "# @dataclass\n",
    "# class Template(Node, HasLinks):\n",
    "#     pass\n",
    "\n",
    "# @dataclass\n",
    "# class Dependency(Node, HasLinks, Haveable):\n",
    "#     template: Template\n",
    "#     def __hash__(self) -> int: return Node.__hash__(self)\n",
    "#     def __eq__(self, __value: object) -> bool: return Node.__eq__(self, __value)\n",
    "\n",
    "#     def Reset(self):\n",
    "#         self.Clear()\n",
    "#         self.links = self.template.links.copy()\n",
    "#         self.Enforce_backlinks()\n",
    "\n",
    "# @dataclass\n",
    "# class Endpoint(Node, HasLinks, Linkable, Haveable):\n",
    "#     def __hash__(self) -> int: return Node.__hash__(self)\n",
    "#     def __eq__(self, __value: object) -> bool: return Node.__eq__(self, __value)\n",
    "\n",
    "#     @classmethod\n",
    "#     def New(cls, ns: Namespace, key: str, properties: Iterable[str], parents: set[Linkable]=set(), have=False):\n",
    "#         _links: set[Linkable] = {ns.GetProperty(p) for p in properties}\n",
    "#         _links = _links.union(parents)\n",
    "#         return Endpoint(\n",
    "#             key = key, links = _links,\n",
    "#             have = have, namespace=ns,\n",
    "#         )\n",
    "\n",
    "# class Transform:\n",
    "#     def __init__(self, name: str, namespace: Namespace) -> None:\n",
    "#         self.requires: set[Dependency] = set()\n",
    "#         self.produces: set[Dependency] = set()\n",
    "#         self.raw: bool = True\n",
    "#         self.name = name\n",
    "#         self._ns = namespace\n",
    "\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f\"Tr:{self.name}\"\n",
    "\n",
    "#     def AddDependency(self, role: Literal[\"req\"]|Literal[\"prod\"], key: str, properties: Iterable[str], parents: set[Linkable]=set()):\n",
    "#         _links: set[Linkable] = {self._ns.GetProperty(p) for p in properties}\n",
    "#         _links = _links.union(parents)\n",
    "#         _template = Template(key=f\"T-{key}\", links =_links, namespace=self._ns)\n",
    "#         _dep = Dependency(key=key, links=_links, template=_template, have=False, namespace=self._ns)\n",
    "#         _dep.Enforce_backlinks() # should be in init, but @_dep is dataclass!\n",
    "\n",
    "#         if role == \"req\":\n",
    "#             assert _dep not in self.produces\n",
    "#             self.requires.add(_dep)\n",
    "#         else:\n",
    "#             assert _dep not in self.requires\n",
    "#             self.produces.add(_dep)\n",
    "\n",
    "#     def Reset(self):\n",
    "#         self.raw = True\n",
    "#         for d in self.requires | self.produces:\n",
    "#             d.Reset()\n",
    "        \n",
    "# NS = Namespace()\n",
    "# anner = Transform(\"anner\", NS)\n",
    "# anner.AddDependency(\n",
    "#     \"req\", \"a_in\",\n",
    "#     \"annable\".split(\", \"),\n",
    "# )\n",
    "# anner.AddDependency(\n",
    "#     \"prod\", \"a_out\",\n",
    "#     \"ann\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# taxer = Transform(\"taxer\", NS)\n",
    "# taxer.AddDependency(\n",
    "#     \"req\", \"t_in\",\n",
    "#     \"taxable\".split(\", \"),\n",
    "# )\n",
    "# taxer.AddDependency(\n",
    "#     \"prod\", \"t_out\",\n",
    "#     \"tax\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# sumer = Transform(\"sumer\", NS)\n",
    "# sumer.AddDependency(\n",
    "#     \"req\", \"s_in_ann\",\n",
    "#     \"ann\".split(\", \"),\n",
    "# )\n",
    "# sumer.AddDependency(\n",
    "#     \"req\", \"s_in_tax\",\n",
    "#     \"tax\".split(\", \"),\n",
    "# )\n",
    "# sumer.AddDependency(\n",
    "#     \"prod\", \"s_out\",\n",
    "#     \"sum\".split(\", \"),\n",
    "# )\n",
    "\n",
    "# in_asm = Endpoint.New(NS, \"in_asm\", \"asm, annable, taxable\", have=True)\n",
    "# in_bin = Endpoint.New(NS, \"in_bin\", \"bin, annable, taxable\", have=True)\n",
    "\n",
    "# for tr in [anner, taxer, sumer]:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P:[Dep:7Fvc04hOSij0, Dep:CeaxX8t6TCPk]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from __future__ import annotations\n",
    "# import os, sys\n",
    "# import asyncio\n",
    "# from typing import Iterable, Callable, Any\n",
    "# from pathlib import Path\n",
    "\n",
    "# from limes_x.solver import DependencySolver, Plan, Dependency\n",
    "# from limes_x.persistence import ProjectState, Instance\n",
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# mpath = Path(\"./test_solver/\")\n",
    "# modules = [\n",
    "#     ComputeModule(mpath.joinpath(d)) for d in os.listdir(mpath)\n",
    "# ]\n",
    "# print(modules)\n",
    "\n",
    "# given = [\n",
    "#     (\"a\", \"./test_data/a1\"),\n",
    "#     (\"a\", \"./test_data/a2\"),\n",
    "#     (\"b\", \"./test_data/b1\"),\n",
    "# ]\n",
    "\n",
    "# prj_path = \"./cache/man_test01/\"\n",
    "# state = ProjectState(prj_path, on_exist=\"overwrite\")\n",
    "# for dtype, val in given:\n",
    "#     state.RegisterInstance(Instance.Str(dtype, val))\n",
    "# for m in modules:\n",
    "#     state.RegisterInstance(Instance.ComputeModule(m))\n",
    "\n",
    "# deps = []\n",
    "# for k, inst in state._instances.items():\n",
    "#     if not inst.IsPyType(ComputeModule): continue\n",
    "#     deps.append(Dependency(inst.val.requires, inst.val.produces, k))\n",
    "\n",
    "# solver = DependencySolver(deps)\n",
    "# # plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan = solver.Solve({\"a\"}, {\"branched\"})\n",
    "# assert plan != False\n",
    "# [state.GetInstance(m.ref_key) for m in plan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_dependency(module: ComputeModule):\n",
    "#     return Dependency(module.requires, module.produces, module)\n",
    "\n",
    "# modules = Path(\"./test_solver/\")\n",
    "# solver = Plan([\n",
    "#     make_dependency(ComputeModule(p))\n",
    "# for p in [\n",
    "#     modules.joinpath(p) for p in os.listdir(modules)\n",
    "# ]])\n",
    "# plan = solver.Solve({\"a\"}, {\"reuse\", \"linear\", \"branched\"})\n",
    "# plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from limes_x.compute_module import ComputeModule\n",
    "\n",
    "# a = ComputeModule(\"./test_modules/copy/\")\n",
    "# b = ComputeModule(\"./test_modules/copy2/\")\n",
    "\n",
    "# a.requires, b.requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = ProjectState(\"./cache/test_persist\")\n",
    "# ok = Instance(\"asdf\", 1)\n",
    "# ov = Instance(\"s\", 2)\n",
    "# state._lineage[ok] = [ov]\n",
    "# state.Save()\n",
    "\n",
    "# s2 = ProjectState.Load(\"./cache/test_persist\")\n",
    "# for k, v in s2._lineage.items():\n",
    "#     _te = k.type, k.value, ok == k, [(i.type, i.value, i == ov) for i in v]\n",
    "#     print(_te)\n",
    "\n",
    "# ok._id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = []\n",
    "# for i in range(100000):\n",
    "#     x = Instance(\"asdf\", [\"x\"*150, \"y\"*150])\n",
    "#     # x = 1\n",
    "#     test.append(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
